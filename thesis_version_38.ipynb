{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ggcsweR4bWF9",
      "metadata": {
        "id": "ggcsweR4bWF9"
      },
      "source": [
        "# Thesis pipeline (merged v6 + v3 features)\n",
        "\n",
        "Generated for Google Colab.\n",
        "\n",
        "**Note:** The first install cell ends with a forced runtime restart.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fWpF3g7HbWF_",
      "metadata": {
        "id": "fWpF3g7HbWF_"
      },
      "source": [
        "## -*- coding: utf-8 -*-\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kgJWRh_pbWF_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kgJWRh_pbWF_",
        "outputId": "2eda88e1-c372-48be-9286-681d1b0136f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thesis version 6.ipynb\\n\\nAutomatically generated by Colab.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1KDYPE0MaqlM5-vU6esFgh_a1u1wA9AqB\\n'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"thesis version 6.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1KDYPE0MaqlM5-vU6esFgh_a1u1wA9AqB\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FtZqMH3zbWF_",
      "metadata": {
        "id": "FtZqMH3zbWF_"
      },
      "source": [
        "## 0) CLEAN INSTALL (RUN ONCE) + RESTART\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DtbAhHwrbWGA",
      "metadata": {
        "id": "DtbAhHwrbWGA"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 0) CLEAN INSTALL (RUN ONCE) + RESTART\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i6K9nrw1bWGA",
      "metadata": {
        "id": "i6K9nrw1bWGA"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EZW5Hig4bWGA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZW5Hig4bWGA",
        "outputId": "c83f6202-3658-4c25-e1b6-06df8fa1fc0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch_geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pyg_lib as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch_scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch_sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch_cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch_spline_conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m228.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m324.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m349.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m280.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m173.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m302.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m499.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m264.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m507.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m387.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m476.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m482.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m370.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m459.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m462.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m511.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m464.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.6 requires torch<2.10,>=1.10, which is not installed.\n",
            "fastai 2.8.6 requires torchvision>=0.11, which is not installed.\n",
            "accelerate 1.12.0 requires torch>=2.0.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m213.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m323.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m222.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m148.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m194.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m262.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m150.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m212.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m184.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m301.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m306.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.8/821.8 MB\u001b[0m \u001b[31m739.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hpython: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "torch: 2.8.0+cu126\n",
            "cuda: 12.6 | tag: cu126\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.6/204.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-louvain (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# If you're on Colab: Runtime -> Restart runtime after this cell (we auto-kill too)\n",
        "\n",
        "!pip -q uninstall -y torch torchvision torchaudio torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv || true\n",
        "\n",
        "# --- Fix scientific stack to consistent versions (avoid ABI break + satisfy common deps) ---\n",
        "!pip -q install --no-cache-dir --force-reinstall \\\n",
        "  \"numpy==2.0.2\" \\\n",
        "  \"scipy==1.14.1\" \\\n",
        "  \"scikit-learn==1.6.1\" \\\n",
        "  \"pandas==2.2.2\" \\\n",
        "  \"matplotlib==3.9.2\" \\\n",
        "  \"networkx==3.4.2\" \\\n",
        "  \"pillow==11.3.0\"\n",
        "\n",
        "# --- Install PyTorch CUDA 12.6 build (choose cu126 to match your runtime CUDA 12.6) ---\n",
        "# If this fails in your environment, tell me the exact error text.\n",
        "!pip -q install --index-url https://download.pytorch.org/whl/cu126 \\\n",
        "  \"torch==2.8.0+cu126\" \"torchvision==0.23.0+cu126\" \"torchaudio==2.8.0+cu126\"\n",
        "\n",
        "# --- Install PyG + extensions matching torch/cuda ---\n",
        "import torch, sys\n",
        "TORCH_VER = torch.__version__.split('+')[0]  # e.g. 2.8.0\n",
        "CUDA_VER  = torch.version.cuda              # e.g. 12.6\n",
        "CUDA_TAG  = f\"cu{CUDA_VER.replace('.','')}\" if CUDA_VER else \"cpu\"\n",
        "print(\"python:\", sys.version)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda:\", CUDA_VER, \"| tag:\", CUDA_TAG)\n",
        "\n",
        "!pip -q install -U torch_geometric\n",
        "!pip -q install -U pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv \\\n",
        "  -f https://data.pyg.org/whl/torch-{TORCH_VER}+{CUDA_TAG}.html\n",
        "\n",
        "# --- clustering + GO enrichment ---\n",
        "!pip -q install -U python-louvain gprofiler-official\n",
        "!pip -q install -U igraph leidenalg || true  # optional (if fails, we fallback)\n",
        "\n",
        "# --- hard restart (important after ABI changes) ---\n",
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v_VgfaukbWGB",
      "metadata": {
        "id": "v_VgfaukbWGB"
      },
      "source": [
        "## 1) IMPORTS + SEEDS + DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iHo9QvjIbWGB",
      "metadata": {
        "id": "iHo9QvjIbWGB"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 1) IMPORTS + SEEDS + DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "389c3792",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "389c3792",
        "outputId": "63966be0-557e-435e-8e3e-72a59c366545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN_HEAVY = True\n",
            "RUN_NODE2VEC = True\n",
            "RUN_CLUSTER_SWEEP = True\n",
            "RUN_CLUSTER_COHESION = True\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# GLOBAL RUN FLAGS (paper-friendly)\n",
        "# - Keep heavy steps OFF by default so \"Run all\" doesn't take forever.\n",
        "# =========================\n",
        "RUN_HEAVY = True          # multi-seed training, big sweeps\n",
        "RUN_NODE2VEC = True       # node2vec baseline can be slow\n",
        "RUN_CLUSTER_SWEEP = True  # resolution sweep for Leiden/Louvain\n",
        "RUN_CLUSTER_COHESION = True  # per-cluster cohesion + correlations (sampling-heavy)\n",
        "\n",
        "print(\"RUN_HEAVY =\", RUN_HEAVY)\n",
        "print(\"RUN_NODE2VEC =\", RUN_NODE2VEC)\n",
        "print(\"RUN_CLUSTER_SWEEP =\", RUN_CLUSTER_SWEEP)\n",
        "print(\"RUN_CLUSTER_COHESION =\", RUN_CLUSTER_COHESION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ho7jCChbbWGB",
      "metadata": {
        "id": "ho7jCChbbWGB"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aMDoIzCEbWGB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDoIzCEbWGB",
        "outputId": "202c38e6-ed9f-4e8a-c0c5-5f0c66ab5e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "numpy: 2.0.2\n",
            "scipy: 1.14.1\n",
            "sklearn: 1.6.1\n",
            "torch: 2.8.0+cu126\n",
            "pyg ok\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "SEED = 0\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# quick ABI sanity:\n",
        "import scipy, sklearn\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"pyg ok\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cWLzYWmbWGC",
      "metadata": {
        "id": "2cWLzYWmbWGC"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Rb9F7vq_bWGC",
      "metadata": {
        "id": "Rb9F7vq_bWGC"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 1b) PREPROCESSING OPTIONS (merge from version 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oxdmw9ZhbWGC",
      "metadata": {
        "id": "oxdmw9ZhbWGC"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0Pg8vOZEbWGC",
      "metadata": {
        "id": "0Pg8vOZEbWGC"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# If True, we filter STRING edges by combined_score and keep only the Largest Connected Component (LCC).\n",
        "# This reduces noise/islands and usually improves both link prediction stability and community structure.\n",
        "USE_THRESHOLD = True\n",
        "MIN_SCORE = 700            # STRING combined_score threshold (0..1000). 700 = high-confidence.\n",
        "USE_LCC = True             # keep largest connected component after thresholding\n",
        "DO_BASIC_PLOTS = True     # set True if you want extra data distribution plots (degree, edge weights, CC sizes)\n",
        "\n",
        "# If you want to reproduce version-6 behavior (no threshold/LCC), set:\n",
        "# USE_THRESHOLD=False; USE_LCC=False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Oq6M8-onbWGC",
      "metadata": {
        "id": "Oq6M8-onbWGC"
      },
      "source": [
        "## 2) DOWNLOAD STRING (v11.5) + UNZIP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8iZTyRfXbWGC",
      "metadata": {
        "id": "8iZTyRfXbWGC"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 2) DOWNLOAD STRING (v11.5) + UNZIP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LkN5xn40bWGD",
      "metadata": {
        "id": "LkN5xn40bWGD"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "mJ8N0KyHbWGD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ8N0KyHbWGD",
        "outputId": "205dc82a-8fcc-4340-a378-a190726107d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 9606.protein.info.v11.5.txt.gz\n",
            "Saved: data/9606.protein.info.v11.5.txt.gz\n",
            "Downloading: 9606.protein.links.detailed.v11.5.txt.gz\n",
            "Saved: data/9606.protein.links.detailed.v11.5.txt.gz\n",
            "Unzipping: 9606.protein.links.detailed.v11.5.txt.gz\n",
            "OK: data/9606.protein.links.detailed.v11.5.txt\n",
            "Unzipping: 9606.protein.info.v11.5.txt.gz\n",
            "OK: data/9606.protein.info.v11.5.txt\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "import pathlib, gzip, shutil\n",
        "\n",
        "data_dir = pathlib.Path(\"data\")\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "def maybe_download(url, out_path):\n",
        "    out_path = pathlib.Path(out_path)\n",
        "    if out_path.exists():\n",
        "        print(\"OK (exists):\", out_path)\n",
        "        return\n",
        "    print(\"Downloading:\", out_path.name)\n",
        "    !wget -q -O \"{out_path}\" \"{url}\"\n",
        "    print(\"Saved:\", out_path)\n",
        "\n",
        "maybe_download(\n",
        "    \"https://stringdb-static.org/download/protein.info.v11.5/9606.protein.info.v11.5.txt.gz\",\n",
        "    data_dir / \"9606.protein.info.v11.5.txt.gz\"\n",
        ")\n",
        "maybe_download(\n",
        "    \"https://stringdb-static.org/download/protein.links.detailed.v11.5/9606.protein.links.detailed.v11.5.txt.gz\",\n",
        "    data_dir / \"9606.protein.links.detailed.v11.5.txt.gz\"\n",
        ")\n",
        "\n",
        "for gz in data_dir.glob(\"*.gz\"):\n",
        "    out = gz.with_suffix(\"\")\n",
        "    if not out.exists():\n",
        "        print(\"Unzipping:\", gz.name)\n",
        "        with gzip.open(gz, \"rb\") as f_in, open(out, \"wb\") as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "        print(\"OK:\", out)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fwa6QQjlbWGD",
      "metadata": {
        "id": "fwa6QQjlbWGD"
      },
      "source": [
        "## 3) LOAD STRING GRAPH -> PyG Data + nodes_annot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6_qgR1jlbWGD",
      "metadata": {
        "id": "6_qgR1jlbWGD"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 3) LOAD STRING GRAPH -> PyG Data + nodes_annot\n",
        "#     (merged improvements: optional MIN_SCORE threshold + LCC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kKl71UZ7bWGD",
      "metadata": {
        "id": "kKl71UZ7bWGD"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Pg-skn2GbWGD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pg-skn2GbWGD",
        "outputId": "bdece3cd-601f-48e6-dd2c-588cbcc0f90d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Config] USE_THRESHOLD=True MIN_SCORE=700 USE_LCC=True DO_BASIC_PLOTS=True\n",
            "Applied MIN_SCORE=700: edges 11938498 -> 505968\n",
            "Kept LCC: nodes=16584 edges=505666\n",
            "data_full: Data(x=[16584, 4], edge_index=[2, 252833], edge_weight=[252833], num_nodes=16584)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   node             string_id preferred_name  \\\n",
              "0     0  9606.ENSP00000000233           ARF5   \n",
              "1     1  9606.ENSP00000000412           M6PR   \n",
              "2     2  9606.ENSP00000001008          FKBP4   \n",
              "3     3  9606.ENSP00000001146        CYP26B1   \n",
              "4     4  9606.ENSP00000002125        NDUFAF7   \n",
              "\n",
              "                                          annotation gene_final  \n",
              "0  ADP-ribosylation factor 5; GTP-binding protein...       ARF5  \n",
              "1  Cation-dependent mannose-6-phosphate receptor;...       M6PR  \n",
              "2  Peptidyl-prolyl cis-trans isomerase FKBP4; Imm...      FKBP4  \n",
              "3  Cytochrome P450 26B1; Involved in the metaboli...    CYP26B1  \n",
              "4  Protein arginine methyltransferase NDUFAF7, mi...    NDUFAF7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c245cc9c-ecea-4adb-b77c-e142026c8e2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node</th>\n",
              "      <th>string_id</th>\n",
              "      <th>preferred_name</th>\n",
              "      <th>annotation</th>\n",
              "      <th>gene_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>9606.ENSP00000000233</td>\n",
              "      <td>ARF5</td>\n",
              "      <td>ADP-ribosylation factor 5; GTP-binding protein...</td>\n",
              "      <td>ARF5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9606.ENSP00000000412</td>\n",
              "      <td>M6PR</td>\n",
              "      <td>Cation-dependent mannose-6-phosphate receptor;...</td>\n",
              "      <td>M6PR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9606.ENSP00000001008</td>\n",
              "      <td>FKBP4</td>\n",
              "      <td>Peptidyl-prolyl cis-trans isomerase FKBP4; Imm...</td>\n",
              "      <td>FKBP4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>9606.ENSP00000001146</td>\n",
              "      <td>CYP26B1</td>\n",
              "      <td>Cytochrome P450 26B1; Involved in the metaboli...</td>\n",
              "      <td>CYP26B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9606.ENSP00000002125</td>\n",
              "      <td>NDUFAF7</td>\n",
              "      <td>Protein arginine methyltransferase NDUFAF7, mi...</td>\n",
              "      <td>NDUFAF7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c245cc9c-ecea-4adb-b77c-e142026c8e2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c245cc9c-ecea-4adb-b77c-e142026c8e2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c245cc9c-ecea-4adb-b77c-e142026c8e2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    plt\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"node\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"string_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"9606.ENSP00000000412\",\n          \"9606.ENSP00000002125\",\n          \"9606.ENSP00000001008\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preferred_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"M6PR\",\n          \"NDUFAF7\",\n          \"FKBP4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cation-dependent mannose-6-phosphate receptor; Transport of phosphorylated lysosomal enzymes from the Golgi complex and the cell surface to lysosomes. Lysosomal enzymes bearing phosphomannosyl residues bind specifically to mannose-6- phosphate receptors in the Golgi apparatus and the resulting receptor-ligand complex is transported to an acidic prelyosomal compartment where the low pH mediates the dissociation of the complex; MRH domain containing \",\n          \"Protein arginine methyltransferase NDUFAF7, mitochondrial; Arginine methyltransferase involved in the assembly or stability of mitochondrial NADH:ubiquinone oxidoreductase complex (complex I). Acts by mediating symmetric dimethylation of 'Arg-118' of NDUFS2 after it assembles into the complex I, stabilizing the early intermediate complex; Belongs to the NDUFAF7 family\",\n          \"Peptidyl-prolyl cis-trans isomerase FKBP4; Immunophilin protein with PPIase and co-chaperone activities. Component of steroid receptors heterocomplexes through interaction with heat-shock protein 90 (HSP90). May play a role in the intracellular trafficking of heterooligomeric forms of steroid hormone receptors between cytoplasm and nuclear compartments. The isomerase activity controls neuronal growth cones via regulation of TRPC1 channel opening. Acts also as a regulator of microtubule dynamics by inhibiting MAPT/TAU ability to promote microtubule assembly. May have a protective role a [...] \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gene_final\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"M6PR\",\n          \"NDUFAF7\",\n          \"FKBP4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =========================\n",
        "# DATA LOADING + FILTERS (safe defaults)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# ---- SAFE DEFAULTS (αν δεν υπάρχουν ήδη ορισμένες τιμές) ----\n",
        "USE_THRESHOLD = globals().get(\"USE_THRESHOLD\", False)   # True/False\n",
        "MIN_SCORE     = globals().get(\"MIN_SCORE\", 700)         # 0..1000 for STRING combined_score\n",
        "USE_LCC       = globals().get(\"USE_LCC\", True)          # True/False\n",
        "DO_BASIC_PLOTS= globals().get(\"DO_BASIC_PLOTS\", False)  # True/False\n",
        "\n",
        "print(f\"[Config] USE_THRESHOLD={USE_THRESHOLD} MIN_SCORE={MIN_SCORE} USE_LCC={USE_LCC} DO_BASIC_PLOTS={DO_BASIC_PLOTS}\")\n",
        "\n",
        "info = pd.read_csv(\"data/9606.protein.info.v11.5.txt\", sep=\"\\t\")\n",
        "info = info.rename(columns={\"#string_protein_id\": \"string_id\"})\n",
        "\n",
        "links = pd.read_csv(\"data/9606.protein.links.detailed.v11.5.txt\", sep=\" \")\n",
        "\n",
        "# --- choose / build a weight column in [0,1] ---\n",
        "if \"combined_score\" in links.columns:\n",
        "    links[\"combined_score\"] = links[\"combined_score\"].astype(float)\n",
        "    links[\"w\"] = links[\"combined_score\"] / 1000.0\n",
        "else:\n",
        "    score_col = [c for c in links.columns if c not in [\"protein1\", \"protein2\"]][0]\n",
        "    links[\"w\"] = links[score_col].astype(float)\n",
        "    links[\"w\"] = (links[\"w\"] - links[\"w\"].min()) / (links[\"w\"].max() - links[\"w\"].min() + 1e-9)\n",
        "\n",
        "# --- optional thresholding ---\n",
        "if USE_THRESHOLD and \"combined_score\" in links.columns:\n",
        "    before = len(links)\n",
        "    links = links[links[\"combined_score\"] >= float(MIN_SCORE)].copy()\n",
        "    print(f\"Applied MIN_SCORE={MIN_SCORE}: edges {before} -> {len(links)}\")\n",
        "\n",
        "# --- optional LCC (largest connected component) ---\n",
        "if USE_LCC:\n",
        "    import networkx as nx\n",
        "    G_tmp = nx.from_pandas_edgelist(\n",
        "        links, \"protein1\", \"protein2\", edge_attr=\"w\", create_using=nx.Graph\n",
        "    )\n",
        "    if G_tmp.number_of_nodes() > 0 and G_tmp.number_of_edges() > 0:\n",
        "        lcc_nodes = max(nx.connected_components(G_tmp), key=len)\n",
        "        links = links[links[\"protein1\"].isin(lcc_nodes) & links[\"protein2\"].isin(lcc_nodes)].copy()\n",
        "        print(f\"Kept LCC: nodes={len(lcc_nodes)} edges={len(links)}\")\n",
        "    else:\n",
        "        print(\"Warning: empty graph after filtering; disabling LCC for this run.\")\n",
        "        USE_LCC = False\n",
        "\n",
        "# --- map string ids -> 0..N-1 ---\n",
        "ids = pd.unique(links[[\"protein1\", \"protein2\"]].values.ravel(\"K\"))\n",
        "string_ids = ids.astype(str).tolist()\n",
        "id2idx = {sid: i for i, sid in enumerate(string_ids)}\n",
        "\n",
        "u = links[\"protein1\"].map(id2idx).to_numpy()\n",
        "v = links[\"protein2\"].map(id2idx).to_numpy()\n",
        "w = links[\"w\"].to_numpy().astype(np.float32)\n",
        "\n",
        "# unique undirected edges, keep max weight\n",
        "a = np.minimum(u, v)\n",
        "b = np.maximum(u, v)\n",
        "df_e = (\n",
        "    pd.DataFrame({\"a\": a, \"b\": b, \"w\": w})\n",
        "    .groupby([\"a\", \"b\"], as_index=False)[\"w\"]\n",
        "    .max()\n",
        ")\n",
        "\n",
        "edge_index = torch.tensor(df_e[[\"a\", \"b\"]].to_numpy().T, dtype=torch.long)\n",
        "edge_weight = torch.tensor(df_e[\"w\"].to_numpy(), dtype=torch.float32)\n",
        "\n",
        "# weight lookup dict (for recovering weights after RandomLinkSplit)\n",
        "w_dict = {(int(r.a), int(r.b)): float(r.w) for r in df_e.itertuples(index=False)}\n",
        "\n",
        "nodes_annot = (\n",
        "    pd.DataFrame({\"node\": np.arange(len(string_ids)), \"string_id\": string_ids})\n",
        "    .merge(info[[\"string_id\", \"preferred_name\", \"annotation\"]], on=\"string_id\", how=\"left\")\n",
        ")\n",
        "nodes_annot[\"gene_final\"] = nodes_annot[\"preferred_name\"]\n",
        "\n",
        "# ---- Node features (stronger than degree-only; still cheap) ----\n",
        "# We build a small structural feature vector per node:\n",
        "# 1) log(1+degree)\n",
        "# 2) degree normalized\n",
        "# 3) weighted degree (strength) normalized\n",
        "# 4) mean incident edge weight\n",
        "num_nodes = len(string_ids)\n",
        "a_np = df_e[\"a\"].to_numpy()\n",
        "b_np = df_e[\"b\"].to_numpy()\n",
        "w_np = df_e[\"w\"].to_numpy().astype(np.float32)\n",
        "\n",
        "deg = np.zeros(num_nodes, dtype=np.float32)\n",
        "strength = np.zeros(num_nodes, dtype=np.float32)\n",
        "\n",
        "# undirected: add to both endpoints\n",
        "np.add.at(deg, a_np, 1.0); np.add.at(deg, b_np, 1.0)\n",
        "np.add.at(strength, a_np, w_np); np.add.at(strength, b_np, w_np)\n",
        "\n",
        "deg_max = float(deg.max() + 1e-9)\n",
        "str_max = float(strength.max() + 1e-9)\n",
        "mean_w = strength / (deg + 1e-9)\n",
        "\n",
        "X = np.vstack([\n",
        "    np.log1p(deg),\n",
        "    deg / deg_max,\n",
        "    strength / str_max,\n",
        "    mean_w,\n",
        "]).T.astype(np.float32)\n",
        "\n",
        "# z-score each feature dim (helps GCN/SAGE)\n",
        "X = (X - X.mean(axis=0, keepdims=True)) / (X.std(axis=0, keepdims=True) + 1e-6)\n",
        "\n",
        "x = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "data_full = Data(x=x, edge_index=edge_index, edge_weight=edge_weight, num_nodes=num_nodes)\n",
        "\n",
        "print(\"data_full:\", data_full)\n",
        "display(nodes_annot.head())\n",
        "\n",
        "# --- optional basic plots (paper-friendly) ---\n",
        "if DO_BASIC_PLOTS:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import networkx as nx\n",
        "\n",
        "    deg_np = deg.reshape(-1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(deg_np, bins=50)\n",
        "    plt.xlabel(\"Node degree\"); plt.ylabel(\"Count\")\n",
        "    plt.title(\"Degree distribution\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(df_e[\"w\"].to_numpy(), bins=50)\n",
        "    plt.xlabel(\"Edge weight (w)\"); plt.ylabel(\"Count\")\n",
        "    plt.title(\"Edge weight distribution\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    G_tmp = nx.Graph()\n",
        "    G_tmp.add_edges_from(df_e[[\"a\",\"b\"]].to_numpy())\n",
        "    cc_sizes = sorted([len(c) for c in nx.connected_components(G_tmp)], reverse=True)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(cc_sizes[:20], marker=\"o\")\n",
        "    plt.xlabel(\"Component rank\"); plt.ylabel(\"Size\")\n",
        "    plt.title(\"Top connected component sizes\")\n",
        "    plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6YLFF0NCbWGD",
      "metadata": {
        "id": "6YLFF0NCbWGD"
      },
      "source": [
        "## 4) RandomLinkSplit + edge_weight recovery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbCEX4TmbWGE",
      "metadata": {
        "id": "cbCEX4TmbWGE"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 4) RandomLinkSplit + edge_weight recovery\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YMO5UID_bWGE",
      "metadata": {
        "id": "YMO5UID_bWGE"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0bf04lXYbWGE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bf04lXYbWGE",
        "outputId": "e1501129-fcb4-458f-a91b-6446b05337e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train graph edges: 404534\n",
            "Val keys: ['edge_weight', 'edge_label_index', 'edge_label', 'edge_index', 'x', 'num_nodes']\n",
            "Test keys: ['edge_weight', 'edge_label_index', 'edge_label', 'edge_index', 'x', 'num_nodes']\n",
            "✅ Recovered edge_weight for train/val/test\n",
            "✅ Saved cached splits: data_splits_randomlinksplit.pt\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 4) RandomLinkSplit + edge_weight recovery + SPLIT CACHING (reproducible)\n",
        "# Fix for PyTorch>=2.6 weights_only default + robust cache fallback\n",
        "# =========================\n",
        "import os\n",
        "import inspect\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "# ---- Reproducible split seed ----\n",
        "SPLIT_SEED = 42\n",
        "torch.manual_seed(SPLIT_SEED)\n",
        "np.random.seed(SPLIT_SEED)\n",
        "\n",
        "SPLIT_CACHE_PATH = \"data_splits_randomlinksplit.pt\"\n",
        "\n",
        "def _torch_load_compat(path):\n",
        "    \"\"\"torch.load that works across torch versions; disables weights_only when supported.\"\"\"\n",
        "    kw = {\"map_location\": \"cpu\"}\n",
        "    sig = inspect.signature(torch.load)\n",
        "    if \"weights_only\" in sig.parameters:\n",
        "        kw[\"weights_only\"] = False  # IMPORTANT for PyG Data objects in torch>=2.6\n",
        "    return torch.load(path, **kw)\n",
        "\n",
        "def edge_weight_from_dict(edge_index, w_dict, default_w=1.0):\n",
        "    ei = edge_index.detach().cpu().numpy()\n",
        "    ws = np.zeros(ei.shape[1], dtype=np.float32)\n",
        "    for i in range(ei.shape[1]):\n",
        "        u, v = int(ei[0, i]), int(ei[1, i])\n",
        "        a, b = (u, v) if u < v else (v, u)\n",
        "        ws[i] = float(w_dict.get((a, b), default_w))\n",
        "    return torch.tensor(ws, dtype=torch.float32)\n",
        "\n",
        "# ---- Try load cached splits ----\n",
        "loaded = False\n",
        "if os.path.exists(SPLIT_CACHE_PATH):\n",
        "    try:\n",
        "        data_train, data_val, data_test = _torch_load_compat(SPLIT_CACHE_PATH)\n",
        "        print(\"✅ Loaded cached splits:\", SPLIT_CACHE_PATH)\n",
        "        loaded = True\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Cache load failed (will recreate splits):\", repr(e))\n",
        "        try:\n",
        "            os.remove(SPLIT_CACHE_PATH)\n",
        "            print(\"🗑️ Deleted broken/old cache:\", SPLIT_CACHE_PATH)\n",
        "        except Exception as e2:\n",
        "            print(\"⚠️ Could not delete cache:\", repr(e2))\n",
        "\n",
        "if not loaded:\n",
        "    # Build a Data object for splitting\n",
        "    data_lp = Data(\n",
        "        x=data_full.x,\n",
        "        edge_index=data_full.edge_index,\n",
        "        edge_weight=(data_full.edge_weight if hasattr(data_full, \"edge_weight\") else None),\n",
        "        num_nodes=data_full.num_nodes,\n",
        "    )\n",
        "\n",
        "    split = RandomLinkSplit(\n",
        "        num_val=0.10,\n",
        "        num_test=0.10,\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=True,\n",
        "        neg_sampling_ratio=1.0,\n",
        "    )\n",
        "    data_train, data_val, data_test = split(data_lp)\n",
        "\n",
        "    print(\"Train graph edges:\", data_train.edge_index.size(1))\n",
        "    print(\"Val keys:\", list(data_val.keys()))\n",
        "    print(\"Test keys:\", list(data_test.keys()))\n",
        "\n",
        "    # recover weights for the split graphs (only if you had original weights + w_dict)\n",
        "    if hasattr(data_full, \"edge_weight\") and data_full.edge_weight is not None and \"w_dict\" in globals():\n",
        "        data_train.edge_weight = edge_weight_from_dict(data_train.edge_index, w_dict)\n",
        "        data_val.edge_weight   = edge_weight_from_dict(data_val.edge_index, w_dict)\n",
        "        data_test.edge_weight  = edge_weight_from_dict(data_test.edge_index, w_dict)\n",
        "        print(\"✅ Recovered edge_weight for train/val/test\")\n",
        "    else:\n",
        "        print(\"ℹ️ No edge_weight recovery (graph unweighted or w_dict missing).\")\n",
        "\n",
        "    torch.save((data_train, data_val, data_test), SPLIT_CACHE_PATH)\n",
        "    print(\"✅ Saved cached splits:\", SPLIT_CACHE_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef2c7a4",
      "metadata": {
        "id": "bef2c7a4"
      },
      "source": [
        "## 4B) Structural node features from TRAIN graph (no leakage)\n",
        "\n",
        "This section builds **graph-theoretic node features** from the **TRAIN graph only** (from `data_train.edge_index`) and uses them as `x` for the GNN.\n",
        "This is useful when the original graph has no informative node attributes (common in PPI).\n",
        "\n",
        "Core features:\n",
        "- degree\n",
        "- log1p(degree)\n",
        "- local clustering coefficient\n",
        "- k-core index (core number)\n",
        "\n",
        "Optional:\n",
        "- PageRank\n",
        "- Eigenvector centrality (can be slow; auto-skips on failure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8528f181",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8528f181",
        "outputId": "bfe5fcbe-3773-4adb-a435-827535120e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Backed up original x to X_BASE: (16584, 4)\n",
            "✅ PageRank computed.\n",
            "✅ Eigenvector centrality computed.\n",
            "Built structural X: (16584, 6) | features: ['degree', 'log1p_degree', 'clustering_coeff', 'kcore', 'pagerank', 'eigenvector']\n",
            "✅ Saved structural features cache: node_features_struct_train.npy\n",
            "✅ Replaced x in data_train/val/test with structural features: (16584, 6)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 4B) STRUCTURAL NODE FEATURES (train-only, no leakage)\n",
        "# - Builds node features from TRAIN graph only: data_train.edge_index\n",
        "# - Replaces data_train.x / data_val.x / data_test.x with structural features\n",
        "# - Keeps a backup of original x as X_BASE (so you can revert)\n",
        "# - Caches to disk for faster re-runs\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import networkx as nx\n",
        "\n",
        "assert \"data_train\" in globals() and \"data_val\" in globals() and \"data_test\" in globals(), \"Run Section 4 (RandomLinkSplit) first.\"\n",
        "\n",
        "USE_STRUCT_FEATURES = True   # <- set False to keep the original x\n",
        "ADD_PAGERANK = True\n",
        "ADD_EIGENVECTOR = True      # <- set True if you want to try (may be slower)\n",
        "\n",
        "CACHE_FEATS_PATH = \"node_features_struct_train.npy\"\n",
        "\n",
        "N = int(data_train.num_nodes)\n",
        "\n",
        "# --- Backup original x (only once) ---\n",
        "if \"X_BASE\" not in globals():\n",
        "    try:\n",
        "        X_BASE = data_train.x.detach().cpu().clone()\n",
        "        print(\"✅ Backed up original x to X_BASE:\", tuple(X_BASE.shape))\n",
        "    except Exception:\n",
        "        X_BASE = None\n",
        "        print(\"ℹ️ Could not backup original x (maybe x not set).\")\n",
        "\n",
        "if not USE_STRUCT_FEATURES:\n",
        "    print(\"USE_STRUCT_FEATURES=False -> keeping original x (no changes).\")\n",
        "else:\n",
        "    # --- Load from cache if available ---\n",
        "    if os.path.exists(CACHE_FEATS_PATH):\n",
        "        X = np.load(CACHE_FEATS_PATH)\n",
        "        assert X.shape[0] == N, f\"Cached X rows {X.shape[0]} != N {N}\"\n",
        "        print(\"✅ Loaded cached structural features:\", CACHE_FEATS_PATH, X.shape)\n",
        "    else:\n",
        "        # --- Build TRAIN graph (undirected) ---\n",
        "        ei = data_train.edge_index.detach().cpu().numpy()\n",
        "        Gtr = nx.Graph()\n",
        "        Gtr.add_nodes_from(range(N))\n",
        "        Gtr.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "\n",
        "        # --- Core features ---\n",
        "        deg = np.array([d for _, d in Gtr.degree()], dtype=np.float32)\n",
        "        logdeg = np.log1p(deg).astype(np.float32)\n",
        "\n",
        "        # local clustering coefficient\n",
        "        # (returns dict: node -> coeff)\n",
        "        clust = nx.clustering(Gtr)\n",
        "        clust = np.array([clust[i] for i in range(N)], dtype=np.float32)\n",
        "\n",
        "        # k-core index (core number)\n",
        "        core = nx.core_number(Gtr)\n",
        "        core = np.array([core[i] for i in range(N)], dtype=np.float32)\n",
        "\n",
        "        feats = [\n",
        "            (\"degree\", deg),\n",
        "            (\"log1p_degree\", logdeg),\n",
        "            (\"clustering_coeff\", clust),\n",
        "            (\"kcore\", core),\n",
        "        ]\n",
        "\n",
        "        # --- Optional: PageRank ---\n",
        "        if ADD_PAGERANK:\n",
        "            try:\n",
        "                pr = nx.pagerank(Gtr, alpha=0.85, max_iter=200, tol=1e-06)\n",
        "                pr = np.array([pr[i] for i in range(N)], dtype=np.float32)\n",
        "                feats.append((\"pagerank\", pr))\n",
        "                print(\"✅ PageRank computed.\")\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ PageRank failed -> skipping:\", repr(e))\n",
        "\n",
        "        # --- Optional: Eigenvector centrality ---\n",
        "        if ADD_EIGENVECTOR:\n",
        "            try:\n",
        "                # Use numpy-based if possible (faster), else power iteration\n",
        "                try:\n",
        "                    ev = nx.eigenvector_centrality_numpy(Gtr)\n",
        "                except Exception:\n",
        "                    ev = nx.eigenvector_centrality(Gtr, max_iter=500, tol=1e-06)\n",
        "                ev = np.array([ev[i] for i in range(N)], dtype=np.float32)\n",
        "                feats.append((\"eigenvector\", ev))\n",
        "                print(\"✅ Eigenvector centrality computed.\")\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ Eigenvector centrality failed -> skipping:\", repr(e))\n",
        "\n",
        "        # Stack\n",
        "        X = np.stack([v for _, v in feats], axis=1).astype(np.float32)\n",
        "        feat_names = [k for k, _ in feats]\n",
        "        print(\"Built structural X:\", X.shape, \"| features:\", feat_names)\n",
        "\n",
        "        # Normalize (z-score) for stable GNN training\n",
        "        mu = X.mean(axis=0, keepdims=True)\n",
        "        sd = X.std(axis=0, keepdims=True) + 1e-8\n",
        "        X = (X - mu) / sd\n",
        "\n",
        "        np.save(CACHE_FEATS_PATH, X)\n",
        "        print(\"✅ Saved structural features cache:\", CACHE_FEATS_PATH)\n",
        "\n",
        "    # Convert to torch\n",
        "    X_t = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "    # Assign to all splits (same x for all, derived from TRAIN graph only)\n",
        "    data_train.x = X_t\n",
        "    data_val.x   = X_t\n",
        "    data_test.x  = X_t\n",
        "\n",
        "    print(\"✅ Replaced x in data_train/val/test with structural features:\", tuple(X_t.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AZKXLqa3bWGE",
      "metadata": {
        "id": "AZKXLqa3bWGE"
      },
      "source": [
        "## 5) Robust edge label getters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "Gy6Op-Y-bWGE",
      "metadata": {
        "id": "Gy6Op-Y-bWGE"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 5) Robust edge label getters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1WpWdDI5bWGE",
      "metadata": {
        "id": "1WpWdDI5bWGE"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "qEXIv6twbWGE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEXIv6twbWGE",
        "outputId": "ed437361-4f97-4b82-fa68-e015aed03cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val pos/neg: 25283 25283\n",
            "Test pos/neg: 25283 25283\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "def has_edge_label_format(d):\n",
        "    return (\"edge_label_index\" in d.keys()) and (\"edge_label\" in d.keys())\n",
        "\n",
        "def has_posneg_format(d):\n",
        "    return (\"pos_edge_label_index\" in d.keys()) and (\"neg_edge_label_index\" in d.keys())\n",
        "\n",
        "def get_eval_edges(data_split):\n",
        "    if has_edge_label_format(data_split):\n",
        "        eidx = data_split.edge_label_index\n",
        "        y = data_split.edge_label.detach().cpu().numpy().astype(int)\n",
        "        return eidx, y\n",
        "    if has_posneg_format(data_split):\n",
        "        pos = data_split.pos_edge_label_index\n",
        "        neg = data_split.neg_edge_label_index\n",
        "        eidx = torch.cat([pos, neg], dim=1)\n",
        "        y = np.concatenate([np.ones(pos.size(1), dtype=int), np.zeros(neg.size(1), dtype=int)])\n",
        "        return eidx, y\n",
        "    raise RuntimeError(f\"Unknown split format. Keys: {data_split.keys()}\")\n",
        "\n",
        "def get_train_edges_and_labels(data_train):\n",
        "    if has_edge_label_format(data_train):\n",
        "        return data_train.edge_label_index, data_train.edge_label.float()\n",
        "    if has_posneg_format(data_train):\n",
        "        pos = data_train.pos_edge_label_index\n",
        "        neg = data_train.neg_edge_label_index\n",
        "        eidx = torch.cat([pos, neg], dim=1)\n",
        "        y = torch.cat([torch.ones(pos.size(1)), torch.zeros(neg.size(1))], dim=0).float()\n",
        "        return eidx, y\n",
        "    raise RuntimeError(f\"Unknown train format. Keys: {data_train.keys()}\")\n",
        "\n",
        "def eval_scores_to_metrics(y_true, y_score):\n",
        "    return roc_auc_score(y_true, y_score), average_precision_score(y_true, y_score)\n",
        "\n",
        "_, yv = get_eval_edges(data_val)\n",
        "_, yt = get_eval_edges(data_test)\n",
        "print(\"Val pos/neg:\", int(yv.sum()), int((yv == 0).sum()))\n",
        "print(\"Test pos/neg:\", int(yt.sum()), int((yt == 0).sum()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1jBaUzGxbWGF",
      "metadata": {
        "id": "1jBaUzGxbWGF"
      },
      "source": [
        "## 6) Baselines on TRAIN graph (CN / Adamic-Adar / Jaccard / Preferential Attachment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Lkn0foombWGF",
      "metadata": {
        "id": "Lkn0foombWGF"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 6) Baselines on TRAIN graph (CN / Adamic-Adar / Jaccard / Preferential Attachment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mvyJAH1abWGF",
      "metadata": {
        "id": "mvyJAH1abWGF"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ba8212",
      "metadata": {
        "id": "03ba8212"
      },
      "source": [
        "### 6B) OPTIONAL: Node2Vec baseline (structure-only)  \n",
        "Runs only if `RUN_NODE2VEC=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "17f1bbd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17f1bbd2",
        "outputId": "fdd88a74-7036-4973-d43c-5a7ad263f72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using existing Gtr: 16584 nodes, 202267 edges\n",
            "NetworkX Node2Vec not available or failed: No module named 'networkx.algorithms.node2vec'\n",
            "node2vec package not available/failed: No module named 'node2vec'\n",
            "❌ Could not compute Node2Vec embeddings. (OK to skip.)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 6B) OPTIONAL: Node2Vec baseline (structure-only)  [paper add-on]\n",
        "# - Trains node embeddings from TRAIN graph only (no leakage)\n",
        "# - Scores edges by cosine similarity\n",
        "# - Evaluates on TEST edges/labels (same as other baselines)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "if not RUN_NODE2VEC:\n",
        "    print(\"RUN_NODE2VEC=False (skip). Set RUN_NODE2VEC=True to run Node2Vec baseline.\")\n",
        "else:\n",
        "    assert \"data_train\" in globals(), \"Need data_train (RandomLinkSplit).\"\n",
        "    assert \"data_test\" in globals(), \"Need data_test (RandomLinkSplit).\"\n",
        "    assert \"get_eval_edges\" in globals(), \"Need get_eval_edges() (from evaluation helper section).\"\n",
        "\n",
        "    # ---- Build TRAIN graph (no leakage) if missing ----\n",
        "    if \"Gtr\" not in globals():\n",
        "        N = int(data_train.num_nodes)\n",
        "        ei = data_train.edge_index.detach().cpu().numpy()\n",
        "        Gtr = nx.Graph()\n",
        "        Gtr.add_nodes_from(range(N))\n",
        "        Gtr.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "        print(\"✅ Auto-built Gtr from data_train:\", Gtr.number_of_nodes(), \"nodes,\", Gtr.number_of_edges(), \"edges\")\n",
        "    else:\n",
        "        print(\"✅ Using existing Gtr:\", Gtr.number_of_nodes(), \"nodes,\", Gtr.number_of_edges(), \"edges\")\n",
        "\n",
        "    # ---- Get TEST edges + labels ----\n",
        "    eidx_test, y_test_n2v = get_eval_edges(data_test)\n",
        "    y_test_n2v = np.array(y_test_n2v).astype(int)\n",
        "\n",
        "    # ---- Compute Node2Vec embeddings ----\n",
        "    emb = None\n",
        "    seed0 = int(SEED) if \"SEED\" in globals() else 0\n",
        "\n",
        "    # Try NetworkX implementation (if present)\n",
        "    try:\n",
        "        from networkx.algorithms.node2vec import Node2Vec\n",
        "        print(\"Using NetworkX Node2Vec\")\n",
        "\n",
        "        n2v = Node2Vec(\n",
        "            Gtr,\n",
        "            dimensions=64,\n",
        "            walk_length=30,\n",
        "            num_walks=10,\n",
        "            p=1.0,\n",
        "            q=1.0,\n",
        "            workers=2,\n",
        "            seed=seed0,\n",
        "        )\n",
        "        w2v = n2v.fit(window=10, min_count=1, batch_words=128)\n",
        "        emb = {int(n): w2v.wv[str(n)] for n in Gtr.nodes()}\n",
        "\n",
        "    except Exception as e1:\n",
        "        print(\"NetworkX Node2Vec not available or failed:\", e1)\n",
        "        # Try node2vec package\n",
        "        try:\n",
        "            from node2vec import Node2Vec\n",
        "            print(\"Using node2vec package\")\n",
        "\n",
        "            n2v = Node2Vec(\n",
        "                Gtr,\n",
        "                dimensions=64,\n",
        "                walk_length=30,\n",
        "                num_walks=10,\n",
        "                p=1.0,\n",
        "                q=1.0,\n",
        "                workers=2,\n",
        "                seed=seed0,\n",
        "            )\n",
        "            w2v = n2v.fit(window=10, min_count=1, batch_words=128)\n",
        "            emb = {int(n): w2v.wv[str(n)] for n in Gtr.nodes()}\n",
        "        except Exception as e2:\n",
        "            print(\"node2vec package not available/failed:\", e2)\n",
        "            emb = None\n",
        "\n",
        "    if emb is None:\n",
        "        print(\"❌ Could not compute Node2Vec embeddings. (OK to skip.)\")\n",
        "    else:\n",
        "        # ---- Score edges by cosine similarity ----\n",
        "        def cos_sim(a, b, eps=1e-12):\n",
        "            a = np.asarray(a); b = np.asarray(b)\n",
        "            return float(np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b) + eps))\n",
        "\n",
        "        u = eidx_test[0].detach().cpu().numpy()\n",
        "        v = eidx_test[1].detach().cpu().numpy()\n",
        "        s = np.array([cos_sim(emb[int(uu)], emb[int(vv)]) for uu, vv in zip(u, v)], dtype=float)\n",
        "\n",
        "        # normalize to [0,1]\n",
        "        s_n2v = (s - s.min()) / (s.max() - s.min() + 1e-12)\n",
        "\n",
        "        from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "        roc = roc_auc_score(y_test_n2v, s_n2v)\n",
        "        ap  = average_precision_score(y_test_n2v, s_n2v)\n",
        "        print(f\"[Node2Vec] TEST ROC-AUC={roc:.4f} | AP={ap:.4f}\")\n",
        "\n",
        "        # expose for later plots/tables\n",
        "        s_n2v_n = s_n2v\n",
        "        y_test_node2vec = y_test_n2v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "94Ut-44VbWGF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Ut-44VbWGF",
        "outputId": "3f461aee-5635-4269-9d26-510bb3d4d80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CN]        ROC-AUC=0.9572  PR-AUC=0.9561\n",
            "[AdamicAA]  ROC-AUC=0.9580  PR-AUC=0.9580\n",
            "[Jaccard]   ROC-AUC=0.9573 PR-AUC=0.9572\n",
            "[PrefAttach]ROC-AUC=0.8747 PR-AUC=0.8821\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "Gtr = nx.Graph()\n",
        "ei = data_train.edge_index.detach().cpu().numpy()\n",
        "Gtr.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "\n",
        "adj = {u: set(Gtr.neighbors(u)) for u in Gtr.nodes()}\n",
        "deg = {u: len(adj[u]) for u in adj}\n",
        "\n",
        "def common_neighbors_score(u, v):\n",
        "    nu = adj.get(int(u), set())\n",
        "    nv = adj.get(int(v), set())\n",
        "    return float(len(nu.intersection(nv)))\n",
        "\n",
        "def adamic_adar_score(u, v):\n",
        "    nu = adj.get(int(u), set())\n",
        "    nv = adj.get(int(v), set())\n",
        "    cn = nu.intersection(nv)\n",
        "    s = 0.0\n",
        "    for w in cn:\n",
        "        dw = deg.get(w, 0)\n",
        "        if dw > 1:\n",
        "            s += 1.0 / np.log(dw)\n",
        "    return float(s)\n",
        "\n",
        "def jaccard_score(u, v):\n",
        "    nu = adj.get(int(u), set())\n",
        "    nv = adj.get(int(v), set())\n",
        "    inter = len(nu.intersection(nv))\n",
        "    union = len(nu.union(nv))\n",
        "    return float(inter / (union + 1e-9))\n",
        "\n",
        "def preferential_attachment_score(u, v):\n",
        "    return float(deg.get(int(u), 0) * deg.get(int(v), 0))\n",
        "\n",
        "def baseline_scores_for_split(data_split, scorer_fn):\n",
        "    eidx, y = get_eval_edges(data_split)\n",
        "    e = eidx.detach().cpu().numpy()\n",
        "    scores = np.zeros(e.shape[1], dtype=np.float32)\n",
        "    for i in range(e.shape[1]):\n",
        "        scores[i] = scorer_fn(int(e[0, i]), int(e[1, i]))\n",
        "    return y, scores\n",
        "\n",
        "def minmax01(x):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    mn, mx = float(x.min()), float(x.max())\n",
        "    if mx <= mn + 1e-12:\n",
        "        return np.zeros_like(x)\n",
        "    return (x - mn) / (mx - mn)\n",
        "\n",
        "y_test, s_cn  = baseline_scores_for_split(data_test, common_neighbors_score)\n",
        "y_test, s_aa  = baseline_scores_for_split(data_test, adamic_adar_score)\n",
        "y_test, s_jac = baseline_scores_for_split(data_test, jaccard_score)\n",
        "y_test, s_pa  = baseline_scores_for_split(data_test, preferential_attachment_score)\n",
        "\n",
        "# normalize for nicer PR/ROC overlays (ranking is preserved)\n",
        "s_cn_n  = minmax01(s_cn)\n",
        "s_aa_n  = minmax01(s_aa)\n",
        "s_jac_n = minmax01(s_jac)\n",
        "s_pa_n  = minmax01(s_pa)\n",
        "\n",
        "roc_cn, ap_cn   = eval_scores_to_metrics(y_test, s_cn_n)\n",
        "roc_aa, ap_aa   = eval_scores_to_metrics(y_test, s_aa_n)\n",
        "roc_jac, ap_jac = eval_scores_to_metrics(y_test, s_jac_n)\n",
        "roc_pa, ap_pa   = eval_scores_to_metrics(y_test, s_pa_n)\n",
        "\n",
        "print(f\"[CN]        ROC-AUC={roc_cn:.4f}  PR-AUC={ap_cn:.4f}\")\n",
        "print(f\"[AdamicAA]  ROC-AUC={roc_aa:.4f}  PR-AUC={ap_aa:.4f}\")\n",
        "print(f\"[Jaccard]   ROC-AUC={roc_jac:.4f} PR-AUC={ap_jac:.4f}\")\n",
        "print(f\"[PrefAttach]ROC-AUC={roc_pa:.4f} PR-AUC={ap_pa:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZK-F3pYubWGF",
      "metadata": {
        "id": "ZK-F3pYubWGF"
      },
      "source": [
        "## 7) APPNP (GNN) link prediction model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8klKEFSMbWGF",
      "metadata": {
        "id": "8klKEFSMbWGF"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 7) APPNP (GNN) link prediction model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u4Z0ZZ1AbWGG",
      "metadata": {
        "id": "u4Z0ZZ1AbWGG"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5KD-66A1bWGG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KD-66A1bWGG",
        "outputId": "5bec9245-b995-4f22-ba58-1bbaac13bd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "✅ Link prediction utilities ready (dot baselines + GAT + Edge-MLP + VGAE hook).\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 4) GNN Link Prediction (APPNP / GCN / GraphSAGE / GAT) + (V)GAE  [PAPER-READY]\n",
        "# - dot-product decoders for fair baselines\n",
        "# - one stronger decoder baseline: GCN + Edge-MLP\n",
        "# - optional VGAE unsupervised baseline (inner-product)\n",
        "# =========================\n",
        "import os, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import APPNP, GCNConv, SAGEConv, GATConv, VGAE\n",
        "from torch_geometric.utils import negative_sampling, dropout_edge\n",
        "\n",
        "# -------------------------\n",
        "# Reproducibility + device\n",
        "# -------------------------\n",
        "def set_seed(seed: int = 0):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# Helpers: train/eval edges\n",
        "# -------------------------\n",
        "def _get_pos_edges(data_split):\n",
        "    # Works with RandomLinkSplit outputs and \"plain\" Data\n",
        "    if hasattr(data_split, \"pos_edge_label_index\") and data_split.pos_edge_label_index is not None:\n",
        "        return data_split.pos_edge_label_index\n",
        "    if hasattr(data_split, \"edge_label_index\") and hasattr(data_split, \"edge_label\"):\n",
        "        ei = data_split.edge_label_index\n",
        "        y = data_split.edge_label\n",
        "        if ei is not None and y is not None:\n",
        "            mask = (y == 1)\n",
        "            return ei[:, mask]\n",
        "    return data_split.edge_index\n",
        "\n",
        "def get_train_edges_and_labels(data_train, neg_ratio=1.0):\n",
        "    pos = _get_pos_edges(data_train)\n",
        "    num_pos = pos.size(1)\n",
        "    num_neg = int(num_pos * float(neg_ratio))\n",
        "\n",
        "    neg = negative_sampling(\n",
        "        edge_index=data_train.edge_index,\n",
        "        num_nodes=data_train.num_nodes,\n",
        "        num_neg_samples=num_neg,\n",
        "        method=\"sparse\",\n",
        "    )\n",
        "\n",
        "    edge_label_index = torch.cat([pos, neg], dim=1)\n",
        "    edge_label = torch.cat(\n",
        "        [torch.ones(num_pos, dtype=torch.float32), torch.zeros(num_neg, dtype=torch.float32)],\n",
        "        dim=0\n",
        "    )\n",
        "    return edge_label_index, edge_label\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_eval_edges_and_labels(data_split):\n",
        "    # Prefer fixed eval labels from RandomLinkSplit\n",
        "    if hasattr(data_split, \"edge_label_index\") and hasattr(data_split, \"edge_label\") and data_split.edge_label_index is not None:\n",
        "        return data_split.edge_label_index, data_split.edge_label.float()\n",
        "\n",
        "    pos = _get_pos_edges(data_split)\n",
        "    num_pos = pos.size(1)\n",
        "    neg = negative_sampling(\n",
        "        edge_index=data_split.edge_index,\n",
        "        num_nodes=data_split.num_nodes,\n",
        "        num_neg_samples=num_pos,\n",
        "        method=\"sparse\",\n",
        "    )\n",
        "    edge_label_index = torch.cat([pos, neg], dim=1)\n",
        "    edge_label = torch.cat([torch.ones(num_pos), torch.zeros(num_pos)], dim=0).float()\n",
        "    return edge_label_index, edge_label\n",
        "\n",
        "def eval_scores_to_metrics(y_true, y_score):\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_score = np.asarray(y_score).astype(float)\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return float(\"nan\"), float(\"nan\")\n",
        "    return float(roc_auc_score(y_true, y_score)), float(average_precision_score(y_true, y_score))\n",
        "\n",
        "# -------------------------\n",
        "# Decoders\n",
        "# -------------------------\n",
        "class DotProductDecoder(torch.nn.Module):\n",
        "    # Inner-product decoder: score(u,v) = <z_u, z_v>\n",
        "    def forward(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "class HadamardMLPDecoder(torch.nn.Module):\n",
        "    # MLP on Hadamard product z_u * z_v\n",
        "    def __init__(self, emb_dim=64, hidden=64, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(emb_dim, hidden)\n",
        "        self.lin2 = torch.nn.Linear(hidden, 1)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, z, edge_label_index):\n",
        "        h = z[edge_label_index[0]] * z[edge_label_index[1]]\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        h = F.relu(self.lin1(h))\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        return self.lin2(h).view(-1)\n",
        "\n",
        "class EdgeMLPDecoder(torch.nn.Module):\n",
        "    # Edge-MLP over [z_u, z_v, |z_u - z_v|, z_u * z_v]\n",
        "    def __init__(self, emb_dim=64, hidden=128, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(emb_dim * 4, hidden),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, edge_label_index):\n",
        "        u = edge_label_index[0]\n",
        "        v = edge_label_index[1]\n",
        "        zu = z[u]\n",
        "        zv = z[v]\n",
        "        feat = torch.cat([zu, zv, torch.abs(zu - zv), zu * zv], dim=-1)\n",
        "        return self.net(feat).view(-1)\n",
        "\n",
        "# -------------------------\n",
        "# Encoders\n",
        "# -------------------------\n",
        "class APPNPEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden=128, out_dim=64, K=10, alpha=0.1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(in_dim, hidden)\n",
        "        self.lin2 = torch.nn.Linear(hidden, out_dim)\n",
        "        self.prop = APPNP(K=K, alpha=alpha, dropout=dropout)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        try:\n",
        "            x = self.prop(x, edge_index, edge_weight=edge_weight)\n",
        "        except TypeError:\n",
        "            x = self.prop(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden=128, out_dim=64, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden, add_self_loops=True, normalize=True)\n",
        "        self.conv2 = GCNConv(hidden, out_dim, add_self_loops=True, normalize=True)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        try:\n",
        "            x = self.conv1(x, edge_index, edge_weight=edge_weight) if edge_weight is not None else self.conv1(x, edge_index)\n",
        "        except TypeError:\n",
        "            x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        try:\n",
        "            x = self.conv2(x, edge_index, edge_weight=edge_weight) if edge_weight is not None else self.conv2(x, edge_index)\n",
        "        except TypeError:\n",
        "            x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGEEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden=128, out_dim=64, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_dim, hidden)\n",
        "        self.conv2 = SAGEConv(hidden, out_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GATEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden=128, out_dim=64, heads=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.gat1 = GATConv(in_dim, hidden, heads=heads, dropout=dropout, add_self_loops=True)\n",
        "        self.gat2 = GATConv(hidden * heads, out_dim, heads=1, concat=False, dropout=dropout, add_self_loops=True)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# Link prediction wrapper\n",
        "# -------------------------\n",
        "class LinkPredModel(torch.nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.enc = encoder\n",
        "        self.dec = decoder\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight, edge_label_index):\n",
        "        z = self.enc(x, edge_index, edge_weight=edge_weight)\n",
        "        logits = self.dec(z, edge_label_index)\n",
        "        return logits, z\n",
        "\n",
        "def build_lp_model(encoder_name, in_dim, hidden=128, emb_dim=64, dropout=0.2, appnp_K=10, appnp_alpha=0.1,\n",
        "                   gat_heads=4, decoder_name=\"dot\", dec_hidden=128):\n",
        "    enc_name = str(encoder_name).lower()\n",
        "    if enc_name == \"appnp\":\n",
        "        enc = APPNPEncoder(in_dim, hidden=hidden, out_dim=emb_dim, K=appnp_K, alpha=appnp_alpha, dropout=dropout)\n",
        "    elif enc_name == \"gcn\":\n",
        "        enc = GCNEncoder(in_dim, hidden=hidden, out_dim=emb_dim, dropout=dropout)\n",
        "    elif enc_name in [\"graphsage\", \"sage\"]:\n",
        "        enc = GraphSAGEEncoder(in_dim, hidden=hidden, out_dim=emb_dim, dropout=dropout)\n",
        "    elif enc_name == \"gat\":\n",
        "        enc = GATEncoder(in_dim, hidden=hidden, out_dim=emb_dim, heads=gat_heads, dropout=dropout)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown encoder_name: \" + str(encoder_name))\n",
        "\n",
        "    dec_name = str(decoder_name).lower()\n",
        "    if dec_name in [\"dot\", \"inner\", \"innerproduct\"]:\n",
        "        dec = DotProductDecoder()\n",
        "    elif dec_name in [\"mlp\", \"hadamard_mlp\"]:\n",
        "        dec = HadamardMLPDecoder(emb_dim=emb_dim, hidden=dec_hidden, dropout=dropout)\n",
        "    elif dec_name in [\"edge_mlp\", \"edgemlp\"]:\n",
        "        dec = EdgeMLPDecoder(emb_dim=emb_dim, hidden=dec_hidden, dropout=dropout)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown decoder_name: \" + str(decoder_name))\n",
        "\n",
        "    return LinkPredModel(enc, dec)\n",
        "\n",
        "# -------------------------\n",
        "# Training loop (AMP + early stopping + DropEdge)\n",
        "# -------------------------\n",
        "def _autocast_ctx(use_amp: bool):\n",
        "    if device.type != \"cuda\":\n",
        "        return torch.cuda.amp.autocast(enabled=False)\n",
        "    if hasattr(torch, \"amp\") and hasattr(torch.amp, \"autocast\"):\n",
        "        return torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp)\n",
        "    return torch.cuda.amp.autocast(enabled=use_amp)\n",
        "\n",
        "def train_linkpred(\n",
        "    model_name,\n",
        "    model,\n",
        "    data_train,\n",
        "    data_val,\n",
        "    data_test,\n",
        "    epochs=200,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    neg_ratio=1.0,\n",
        "    patience=30,\n",
        "    grad_clip=1.0,\n",
        "    use_amp=True,\n",
        "    edge_dropout=0.0,\n",
        "):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=8)\n",
        "\n",
        "    if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n",
        "        scaler = torch.amp.GradScaler(enabled=(use_amp and device.type == \"cuda\"))\n",
        "    else:\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type == \"cuda\"))\n",
        "\n",
        "    # cache train graph tensors on device once\n",
        "    x = data_train.x.to(device)\n",
        "    ei_base = data_train.edge_index.to(device)\n",
        "    ew_base = getattr(data_train, \"edge_weight\", None)\n",
        "    ew_base = ew_base.to(device) if ew_base is not None else None\n",
        "\n",
        "    eidx_val, y_val = get_eval_edges_and_labels(data_val)\n",
        "    eidx_test, y_test = get_eval_edges_and_labels(data_test)\n",
        "    eidx_val, y_val = eidx_val.to(device), y_val.to(device)\n",
        "    eidx_test, y_test = eidx_test.to(device), y_test.to(device)\n",
        "\n",
        "    best_state = None\n",
        "    best_val_ap = -1.0\n",
        "    best_epoch = -1\n",
        "    bad = 0\n",
        "\n",
        "    log = {\"epoch\": [], \"loss\": [], \"val_roc\": [], \"val_ap\": [], \"lr\": []}\n",
        "\n",
        "    def _eval(eidx, y):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            with _autocast_ctx(use_amp):\n",
        "                logits, _ = model(x, ei_base, ew_base, eidx)\n",
        "            p = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            y_np = y.detach().cpu().numpy()\n",
        "            roc, ap = eval_scores_to_metrics(y_np, p)\n",
        "        return roc, ap\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        eidx_tr, y_tr = get_train_edges_and_labels(data_train, neg_ratio=neg_ratio)\n",
        "        eidx_tr, y_tr = eidx_tr.to(device), y_tr.to(device)\n",
        "\n",
        "        if edge_dropout is not None and float(edge_dropout) > 0.0:\n",
        "            ei_use, keep_mask = dropout_edge(ei_base, p=float(edge_dropout), training=True)\n",
        "            ew_use = ew_base[keep_mask] if ew_base is not None else None\n",
        "        else:\n",
        "            ei_use, ew_use = ei_base, ew_base\n",
        "\n",
        "        with _autocast_ctx(use_amp):\n",
        "            logits, _ = model(x, ei_use, ew_use, eidx_tr)\n",
        "            n_pos = float((y_tr == 1).sum().item() + 1e-9)\n",
        "            n_neg = float((y_tr == 0).sum().item() + 1e-9)\n",
        "            pos_w = torch.tensor([n_neg / n_pos], device=y_tr.device)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y_tr, pos_weight=pos_w)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if grad_clip is not None:\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), float(grad_clip))\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        if (ep % 10 == 0) or (ep == 1):\n",
        "            roc_v, ap_v = _eval(eidx_val, y_val)\n",
        "            scheduler.step(ap_v if not np.isnan(ap_v) else -1.0)\n",
        "\n",
        "            cur_lr = float(opt.param_groups[0][\"lr\"])\n",
        "            print(f\"[{model_name}] ep {ep:03d} | loss={loss.item():.4f} | val ROC={roc_v:.4f} | val AP={ap_v:.4f} | lr={cur_lr:.2e}\")\n",
        "\n",
        "            log[\"epoch\"].append(ep)\n",
        "            log[\"loss\"].append(float(loss.item()))\n",
        "            log[\"val_roc\"].append(float(roc_v))\n",
        "            log[\"val_ap\"].append(float(ap_v))\n",
        "            log[\"lr\"].append(cur_lr)\n",
        "\n",
        "            if ap_v > best_val_ap:\n",
        "                best_val_ap = ap_v\n",
        "                best_epoch = ep\n",
        "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= patience:\n",
        "                    print(f\"[{model_name}] Early stop at ep={ep} (best ep={best_epoch}, best val AP={best_val_ap:.4f})\")\n",
        "                    break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    roc_t, ap_t = _eval(eidx_test, y_test)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with _autocast_ctx(use_amp):\n",
        "            z_train = model.enc(x, ei_base, edge_weight=ew_base)\n",
        "    z_train = z_train.detach().cpu().numpy()\n",
        "\n",
        "    print(f\"[{model_name} TEST] ROC-AUC={roc_t:.4f} PR-AUC={ap_t:.4f}\")\n",
        "    return model, z_train, {\"test_roc_auc\": roc_t, \"test_ap\": ap_t, \"best_val_ap\": best_val_ap, \"best_epoch\": best_epoch}, pd.DataFrame(log)\n",
        "\n",
        "print(\"✅ Link prediction utilities ready (dot baselines + GAT + Edge-MLP + VGAE hook).\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Backward-compatibility aliases (older cells may call build_model)\n",
        "# Default now is DOT decoder for fair baselines.\n",
        "# -------------------------\n",
        "def build_model(model_name, in_dim, hidden=128, emb_dim=64, dropout=0.2, appnp_K=10, appnp_alpha=0.1):\n",
        "    return build_lp_model(\n",
        "        encoder_name=model_name,\n",
        "        in_dim=in_dim,\n",
        "        hidden=hidden,\n",
        "        emb_dim=emb_dim,\n",
        "        dropout=dropout,\n",
        "        appnp_K=appnp_K,\n",
        "        appnp_alpha=appnp_alpha,\n",
        "        decoder_name=\"dot\",\n",
        "        dec_hidden=hidden,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Na_dYqpV24hN",
      "metadata": {
        "id": "Na_dYqpV24hN"
      },
      "source": [
        "## 7B) Additional GNN baselines (GCN, GraphSAGE) + embedding extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "si6bmIct24hN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "si6bmIct24hN",
        "outputId": "b0a7ced2-eda6-4e9c-fe3f-b5913d5625b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "MODEL: GCN (dot)  (key=gcn_dot)\n",
            "==========================================================================================\n",
            "  seed=0 -> training GCN (dot) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 001 | loss=0.6143 | val ROC=0.8715 | val AP=0.8788 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 010 | loss=0.5237 | val ROC=0.8920 | val AP=0.9027 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 020 | loss=0.5125 | val ROC=0.8873 | val AP=0.9000 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 030 | loss=0.5076 | val ROC=0.8911 | val AP=0.9034 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 040 | loss=0.5046 | val ROC=0.8953 | val AP=0.9073 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 050 | loss=0.5009 | val ROC=0.8974 | val AP=0.9096 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 060 | loss=0.4957 | val ROC=0.9004 | val AP=0.9125 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 070 | loss=0.4926 | val ROC=0.9043 | val AP=0.9162 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 080 | loss=0.4884 | val ROC=0.9072 | val AP=0.9191 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 090 | loss=0.4837 | val ROC=0.9103 | val AP=0.9222 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 100 | loss=0.4812 | val ROC=0.9130 | val AP=0.9249 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 110 | loss=0.4785 | val ROC=0.9149 | val AP=0.9267 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 120 | loss=0.4758 | val ROC=0.9162 | val AP=0.9280 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 130 | loss=0.4745 | val ROC=0.9172 | val AP=0.9291 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 140 | loss=0.4723 | val ROC=0.9178 | val AP=0.9298 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 150 | loss=0.4708 | val ROC=0.9185 | val AP=0.9305 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 160 | loss=0.4708 | val ROC=0.9189 | val AP=0.9310 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 170 | loss=0.4691 | val ROC=0.9191 | val AP=0.9313 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 180 | loss=0.4697 | val ROC=0.9203 | val AP=0.9322 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 190 | loss=0.4678 | val ROC=0.9212 | val AP=0.9330 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=0] ep 200 | loss=0.4660 | val ROC=0.9211 | val AP=0.9330 | lr=1.00e-03\n",
            "[GCN (dot) | seed=0 TEST] ROC-AUC=0.9204 PR-AUC=0.9317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=1 -> training GCN (dot) ...\n",
            "[GCN (dot) | seed=1] ep 001 | loss=0.6466 | val ROC=0.8611 | val AP=0.8681 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 010 | loss=0.5438 | val ROC=0.8794 | val AP=0.8891 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 020 | loss=0.5155 | val ROC=0.8877 | val AP=0.8998 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 030 | loss=0.5140 | val ROC=0.8838 | val AP=0.8974 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 040 | loss=0.5091 | val ROC=0.8912 | val AP=0.9034 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 050 | loss=0.5045 | val ROC=0.8948 | val AP=0.9067 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 060 | loss=0.5028 | val ROC=0.8961 | val AP=0.9079 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 070 | loss=0.4987 | val ROC=0.8987 | val AP=0.9103 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 080 | loss=0.4970 | val ROC=0.9015 | val AP=0.9131 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 090 | loss=0.4938 | val ROC=0.9039 | val AP=0.9157 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 100 | loss=0.4898 | val ROC=0.9069 | val AP=0.9186 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 110 | loss=0.4856 | val ROC=0.9103 | val AP=0.9220 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 120 | loss=0.4823 | val ROC=0.9129 | val AP=0.9246 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 130 | loss=0.4787 | val ROC=0.9144 | val AP=0.9263 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 140 | loss=0.4783 | val ROC=0.9152 | val AP=0.9272 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 150 | loss=0.4757 | val ROC=0.9161 | val AP=0.9282 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 160 | loss=0.4738 | val ROC=0.9169 | val AP=0.9289 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 170 | loss=0.4721 | val ROC=0.9177 | val AP=0.9297 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 180 | loss=0.4709 | val ROC=0.9180 | val AP=0.9302 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 190 | loss=0.4699 | val ROC=0.9187 | val AP=0.9308 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=1] ep 200 | loss=0.4693 | val ROC=0.9191 | val AP=0.9313 | lr=1.00e-03\n",
            "[GCN (dot) | seed=1 TEST] ROC-AUC=0.9188 PR-AUC=0.9303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=2 -> training GCN (dot) ...\n",
            "[GCN (dot) | seed=2] ep 001 | loss=0.6414 | val ROC=0.8671 | val AP=0.8779 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 010 | loss=0.5258 | val ROC=0.8864 | val AP=0.8985 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 020 | loss=0.5133 | val ROC=0.8884 | val AP=0.9010 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 030 | loss=0.5103 | val ROC=0.8905 | val AP=0.9030 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 040 | loss=0.5056 | val ROC=0.8951 | val AP=0.9073 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 050 | loss=0.5001 | val ROC=0.8989 | val AP=0.9108 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 060 | loss=0.4966 | val ROC=0.9025 | val AP=0.9144 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 070 | loss=0.4923 | val ROC=0.9068 | val AP=0.9184 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 080 | loss=0.4873 | val ROC=0.9097 | val AP=0.9213 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 090 | loss=0.4826 | val ROC=0.9124 | val AP=0.9239 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 100 | loss=0.4809 | val ROC=0.9139 | val AP=0.9256 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 110 | loss=0.4783 | val ROC=0.9146 | val AP=0.9264 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 120 | loss=0.4765 | val ROC=0.9155 | val AP=0.9274 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 130 | loss=0.4760 | val ROC=0.9162 | val AP=0.9282 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 140 | loss=0.4720 | val ROC=0.9167 | val AP=0.9288 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 150 | loss=0.4721 | val ROC=0.9171 | val AP=0.9292 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 160 | loss=0.4706 | val ROC=0.9174 | val AP=0.9297 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 170 | loss=0.4704 | val ROC=0.9181 | val AP=0.9303 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 180 | loss=0.4695 | val ROC=0.9184 | val AP=0.9307 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 190 | loss=0.4681 | val ROC=0.9191 | val AP=0.9312 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=2] ep 200 | loss=0.4684 | val ROC=0.9198 | val AP=0.9319 | lr=1.00e-03\n",
            "[GCN (dot) | seed=2 TEST] ROC-AUC=0.9192 PR-AUC=0.9307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=3 -> training GCN (dot) ...\n",
            "[GCN (dot) | seed=3] ep 001 | loss=0.6354 | val ROC=0.8707 | val AP=0.8798 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 010 | loss=0.5248 | val ROC=0.8903 | val AP=0.9019 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 020 | loss=0.5133 | val ROC=0.8874 | val AP=0.9006 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 030 | loss=0.5100 | val ROC=0.8894 | val AP=0.9021 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 040 | loss=0.5046 | val ROC=0.8941 | val AP=0.9065 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 050 | loss=0.5006 | val ROC=0.8977 | val AP=0.9100 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 060 | loss=0.4969 | val ROC=0.9007 | val AP=0.9128 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 070 | loss=0.4938 | val ROC=0.9039 | val AP=0.9158 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 080 | loss=0.4889 | val ROC=0.9071 | val AP=0.9186 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 090 | loss=0.4865 | val ROC=0.9100 | val AP=0.9214 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 100 | loss=0.4821 | val ROC=0.9124 | val AP=0.9237 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 110 | loss=0.4810 | val ROC=0.9137 | val AP=0.9252 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 120 | loss=0.4782 | val ROC=0.9150 | val AP=0.9266 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 130 | loss=0.4772 | val ROC=0.9157 | val AP=0.9275 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 140 | loss=0.4755 | val ROC=0.9163 | val AP=0.9282 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 150 | loss=0.4739 | val ROC=0.9171 | val AP=0.9291 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 160 | loss=0.4727 | val ROC=0.9178 | val AP=0.9299 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 170 | loss=0.4719 | val ROC=0.9180 | val AP=0.9302 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 180 | loss=0.4708 | val ROC=0.9182 | val AP=0.9305 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 190 | loss=0.4690 | val ROC=0.9189 | val AP=0.9311 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=3] ep 200 | loss=0.4691 | val ROC=0.9196 | val AP=0.9317 | lr=1.00e-03\n",
            "[GCN (dot) | seed=3 TEST] ROC-AUC=0.9192 PR-AUC=0.9307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=4 -> training GCN (dot) ...\n",
            "[GCN (dot) | seed=4] ep 001 | loss=0.6426 | val ROC=0.8703 | val AP=0.8776 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 010 | loss=0.5370 | val ROC=0.8815 | val AP=0.8925 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 020 | loss=0.5173 | val ROC=0.8891 | val AP=0.9011 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 030 | loss=0.5106 | val ROC=0.8857 | val AP=0.8990 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 040 | loss=0.5071 | val ROC=0.8912 | val AP=0.9036 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 050 | loss=0.5035 | val ROC=0.8955 | val AP=0.9073 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 060 | loss=0.4997 | val ROC=0.8981 | val AP=0.9098 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 070 | loss=0.4978 | val ROC=0.9001 | val AP=0.9120 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 080 | loss=0.4948 | val ROC=0.9029 | val AP=0.9147 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 090 | loss=0.4919 | val ROC=0.9060 | val AP=0.9178 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 100 | loss=0.4871 | val ROC=0.9091 | val AP=0.9208 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 110 | loss=0.4841 | val ROC=0.9125 | val AP=0.9240 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 120 | loss=0.4800 | val ROC=0.9147 | val AP=0.9262 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 130 | loss=0.4769 | val ROC=0.9160 | val AP=0.9276 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 140 | loss=0.4762 | val ROC=0.9167 | val AP=0.9284 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 150 | loss=0.4747 | val ROC=0.9174 | val AP=0.9292 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 160 | loss=0.4727 | val ROC=0.9181 | val AP=0.9299 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 170 | loss=0.4713 | val ROC=0.9185 | val AP=0.9303 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 180 | loss=0.4713 | val ROC=0.9190 | val AP=0.9309 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 190 | loss=0.4693 | val ROC=0.9193 | val AP=0.9311 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN (dot) | seed=4] ep 200 | loss=0.4696 | val ROC=0.9198 | val AP=0.9316 | lr=1.00e-03\n",
            "[GCN (dot) | seed=4 TEST] ROC-AUC=0.9194 PR-AUC=0.9306\n",
            "\n",
            "==========================================================================================\n",
            "MODEL: GraphSAGE (dot)  (key=graphsage_dot)\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=0 -> training GraphSAGE (dot) ...\n",
            "[GraphSAGE (dot) | seed=0] ep 001 | loss=2.7765 | val ROC=0.8151 | val AP=0.8180 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 010 | loss=0.6031 | val ROC=0.8823 | val AP=0.8886 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 020 | loss=0.5327 | val ROC=0.8969 | val AP=0.9063 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 030 | loss=0.5082 | val ROC=0.9052 | val AP=0.9150 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 040 | loss=0.4974 | val ROC=0.9119 | val AP=0.9209 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 050 | loss=0.4913 | val ROC=0.9143 | val AP=0.9240 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 060 | loss=0.4866 | val ROC=0.9174 | val AP=0.9267 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 070 | loss=0.4844 | val ROC=0.9170 | val AP=0.9270 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 080 | loss=0.4813 | val ROC=0.9199 | val AP=0.9295 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 090 | loss=0.4794 | val ROC=0.9192 | val AP=0.9294 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 100 | loss=0.4759 | val ROC=0.9210 | val AP=0.9309 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 110 | loss=0.4754 | val ROC=0.9215 | val AP=0.9316 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 120 | loss=0.4728 | val ROC=0.9217 | val AP=0.9320 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 130 | loss=0.4717 | val ROC=0.9232 | val AP=0.9333 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 140 | loss=0.4713 | val ROC=0.9237 | val AP=0.9339 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 150 | loss=0.4697 | val ROC=0.9240 | val AP=0.9342 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 160 | loss=0.4689 | val ROC=0.9244 | val AP=0.9347 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 170 | loss=0.4676 | val ROC=0.9248 | val AP=0.9351 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 180 | loss=0.4666 | val ROC=0.9253 | val AP=0.9356 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 190 | loss=0.4655 | val ROC=0.9251 | val AP=0.9357 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=0] ep 200 | loss=0.4656 | val ROC=0.9267 | val AP=0.9369 | lr=1.00e-03\n",
            "[GraphSAGE (dot) | seed=0 TEST] ROC-AUC=0.9265 PR-AUC=0.9363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=1 -> training GraphSAGE (dot) ...\n",
            "[GraphSAGE (dot) | seed=1] ep 001 | loss=3.1925 | val ROC=0.8067 | val AP=0.8062 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 010 | loss=0.6197 | val ROC=0.8605 | val AP=0.8715 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 020 | loss=0.5421 | val ROC=0.8909 | val AP=0.9009 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 030 | loss=0.5172 | val ROC=0.8971 | val AP=0.9077 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 040 | loss=0.5035 | val ROC=0.9080 | val AP=0.9176 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 050 | loss=0.4956 | val ROC=0.9103 | val AP=0.9202 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 060 | loss=0.4912 | val ROC=0.9139 | val AP=0.9235 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 070 | loss=0.4861 | val ROC=0.9146 | val AP=0.9247 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 080 | loss=0.4836 | val ROC=0.9161 | val AP=0.9262 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 090 | loss=0.4817 | val ROC=0.9166 | val AP=0.9270 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 100 | loss=0.4795 | val ROC=0.9183 | val AP=0.9286 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 110 | loss=0.4788 | val ROC=0.9177 | val AP=0.9285 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 120 | loss=0.4761 | val ROC=0.9199 | val AP=0.9304 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 130 | loss=0.4756 | val ROC=0.9203 | val AP=0.9310 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 140 | loss=0.4735 | val ROC=0.9215 | val AP=0.9321 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 150 | loss=0.4723 | val ROC=0.9211 | val AP=0.9318 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 160 | loss=0.4718 | val ROC=0.9227 | val AP=0.9333 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 170 | loss=0.4692 | val ROC=0.9234 | val AP=0.9339 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 180 | loss=0.4699 | val ROC=0.9226 | val AP=0.9335 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 190 | loss=0.4687 | val ROC=0.9246 | val AP=0.9351 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=1] ep 200 | loss=0.4668 | val ROC=0.9242 | val AP=0.9350 | lr=1.00e-03\n",
            "[GraphSAGE (dot) | seed=1 TEST] ROC-AUC=0.9243 PR-AUC=0.9346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=2 -> training GraphSAGE (dot) ...\n",
            "[GraphSAGE (dot) | seed=2] ep 001 | loss=3.2836 | val ROC=0.8252 | val AP=0.8265 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 010 | loss=0.6590 | val ROC=0.8493 | val AP=0.8644 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 020 | loss=0.5423 | val ROC=0.8916 | val AP=0.9023 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 030 | loss=0.5181 | val ROC=0.9053 | val AP=0.9149 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 040 | loss=0.5035 | val ROC=0.9091 | val AP=0.9187 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 050 | loss=0.4962 | val ROC=0.9135 | val AP=0.9232 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 060 | loss=0.4910 | val ROC=0.9154 | val AP=0.9251 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 070 | loss=0.4855 | val ROC=0.9168 | val AP=0.9267 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 080 | loss=0.4841 | val ROC=0.9181 | val AP=0.9282 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 090 | loss=0.4807 | val ROC=0.9199 | val AP=0.9298 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 100 | loss=0.4807 | val ROC=0.9196 | val AP=0.9300 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 110 | loss=0.4777 | val ROC=0.9209 | val AP=0.9311 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 120 | loss=0.4763 | val ROC=0.9216 | val AP=0.9318 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 130 | loss=0.4732 | val ROC=0.9220 | val AP=0.9323 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 140 | loss=0.4732 | val ROC=0.9229 | val AP=0.9331 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 150 | loss=0.4723 | val ROC=0.9222 | val AP=0.9329 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 160 | loss=0.4705 | val ROC=0.9232 | val AP=0.9337 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 170 | loss=0.4693 | val ROC=0.9242 | val AP=0.9345 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 180 | loss=0.4678 | val ROC=0.9244 | val AP=0.9348 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 190 | loss=0.4675 | val ROC=0.9249 | val AP=0.9353 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=2] ep 200 | loss=0.4676 | val ROC=0.9244 | val AP=0.9351 | lr=1.00e-03\n",
            "[GraphSAGE (dot) | seed=2 TEST] ROC-AUC=0.9244 PR-AUC=0.9345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=3 -> training GraphSAGE (dot) ...\n",
            "[GraphSAGE (dot) | seed=3] ep 001 | loss=5.0344 | val ROC=0.7879 | val AP=0.7850 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 010 | loss=0.6963 | val ROC=0.8602 | val AP=0.8690 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 020 | loss=0.5562 | val ROC=0.8893 | val AP=0.8989 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 030 | loss=0.5242 | val ROC=0.8966 | val AP=0.9075 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 040 | loss=0.5061 | val ROC=0.9063 | val AP=0.9164 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 050 | loss=0.4986 | val ROC=0.9109 | val AP=0.9209 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 060 | loss=0.4898 | val ROC=0.9151 | val AP=0.9249 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 070 | loss=0.4859 | val ROC=0.9160 | val AP=0.9263 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 080 | loss=0.4832 | val ROC=0.9186 | val AP=0.9287 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 090 | loss=0.4808 | val ROC=0.9187 | val AP=0.9292 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 100 | loss=0.4792 | val ROC=0.9200 | val AP=0.9306 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 110 | loss=0.4772 | val ROC=0.9207 | val AP=0.9314 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 120 | loss=0.4744 | val ROC=0.9206 | val AP=0.9316 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 130 | loss=0.4736 | val ROC=0.9224 | val AP=0.9329 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 140 | loss=0.4715 | val ROC=0.9228 | val AP=0.9337 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 150 | loss=0.4705 | val ROC=0.9233 | val AP=0.9340 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 160 | loss=0.4705 | val ROC=0.9238 | val AP=0.9345 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 170 | loss=0.4677 | val ROC=0.9238 | val AP=0.9348 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 180 | loss=0.4667 | val ROC=0.9242 | val AP=0.9350 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 190 | loss=0.4656 | val ROC=0.9256 | val AP=0.9362 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=3] ep 200 | loss=0.4646 | val ROC=0.9246 | val AP=0.9356 | lr=1.00e-03\n",
            "[GraphSAGE (dot) | seed=3 TEST] ROC-AUC=0.9250 PR-AUC=0.9352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=4 -> training GraphSAGE (dot) ...\n",
            "[GraphSAGE (dot) | seed=4] ep 001 | loss=4.9377 | val ROC=0.7923 | val AP=0.7740 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 010 | loss=0.6825 | val ROC=0.8537 | val AP=0.8626 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 020 | loss=0.5532 | val ROC=0.8870 | val AP=0.8973 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 030 | loss=0.5203 | val ROC=0.9024 | val AP=0.9113 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 040 | loss=0.5050 | val ROC=0.9086 | val AP=0.9174 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 050 | loss=0.4943 | val ROC=0.9123 | val AP=0.9212 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 060 | loss=0.4886 | val ROC=0.9158 | val AP=0.9250 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 070 | loss=0.4863 | val ROC=0.9176 | val AP=0.9270 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 080 | loss=0.4836 | val ROC=0.9192 | val AP=0.9286 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 090 | loss=0.4803 | val ROC=0.9194 | val AP=0.9292 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 100 | loss=0.4785 | val ROC=0.9188 | val AP=0.9291 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 110 | loss=0.4771 | val ROC=0.9203 | val AP=0.9304 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 120 | loss=0.4759 | val ROC=0.9211 | val AP=0.9315 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 130 | loss=0.4737 | val ROC=0.9213 | val AP=0.9318 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 140 | loss=0.4732 | val ROC=0.9218 | val AP=0.9322 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 150 | loss=0.4730 | val ROC=0.9228 | val AP=0.9333 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 160 | loss=0.4711 | val ROC=0.9229 | val AP=0.9334 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 170 | loss=0.4694 | val ROC=0.9244 | val AP=0.9348 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 180 | loss=0.4689 | val ROC=0.9232 | val AP=0.9341 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 190 | loss=0.4676 | val ROC=0.9246 | val AP=0.9352 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GraphSAGE (dot) | seed=4] ep 200 | loss=0.4666 | val ROC=0.9245 | val AP=0.9353 | lr=1.00e-03\n",
            "[GraphSAGE (dot) | seed=4 TEST] ROC-AUC=0.9245 PR-AUC=0.9347\n",
            "\n",
            "==========================================================================================\n",
            "MODEL: APPNP (dot)  (key=appnp_dot)\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=0 -> training APPNP (dot) ...\n",
            "[APPNP (dot) | seed=0] ep 001 | loss=8018.0474 | val ROC=0.8731 | val AP=0.8800 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 010 | loss=424.7022 | val ROC=0.8717 | val AP=0.8806 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 020 | loss=326.5559 | val ROC=0.8698 | val AP=0.8787 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 030 | loss=499.9337 | val ROC=0.8725 | val AP=0.8813 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 040 | loss=1456.2151 | val ROC=0.8705 | val AP=0.8797 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 050 | loss=806.1251 | val ROC=0.8702 | val AP=0.8799 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 060 | loss=1469.2302 | val ROC=0.8712 | val AP=0.8807 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 070 | loss=208.9833 | val ROC=0.8703 | val AP=0.8799 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 080 | loss=4936.4907 | val ROC=0.8712 | val AP=0.8808 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 090 | loss=167.1012 | val ROC=0.8707 | val AP=0.8804 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 100 | loss=15765.8994 | val ROC=0.8685 | val AP=0.8789 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 110 | loss=5654.3428 | val ROC=0.8688 | val AP=0.8789 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 120 | loss=373.7977 | val ROC=0.8698 | val AP=0.8800 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 130 | loss=14962.4023 | val ROC=0.8699 | val AP=0.8804 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 140 | loss=6593.8159 | val ROC=0.8696 | val AP=0.8800 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 150 | loss=2705.6096 | val ROC=0.8696 | val AP=0.8801 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 160 | loss=10913.1211 | val ROC=0.8704 | val AP=0.8807 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 170 | loss=303.1852 | val ROC=0.8699 | val AP=0.8805 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 180 | loss=7426.8579 | val ROC=0.8710 | val AP=0.8814 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 190 | loss=80.1567 | val ROC=0.8700 | val AP=0.8806 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0] ep 200 | loss=7211.1406 | val ROC=0.8704 | val AP=0.8808 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=0 TEST] ROC-AUC=0.8706 PR-AUC=0.8803\n",
            "  seed=1 -> training APPNP (dot) ...\n",
            "[APPNP (dot) | seed=1] ep 001 | loss=338708.9062 | val ROC=0.8747 | val AP=0.8810 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 010 | loss=14907.9033 | val ROC=0.8693 | val AP=0.8747 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 020 | loss=494.8586 | val ROC=0.8688 | val AP=0.8740 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 030 | loss=16545.1777 | val ROC=0.8690 | val AP=0.8751 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 040 | loss=4225.5718 | val ROC=0.8697 | val AP=0.8767 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 050 | loss=28542.5078 | val ROC=0.8704 | val AP=0.8776 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 060 | loss=314.3428 | val ROC=0.8682 | val AP=0.8757 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 070 | loss=9695.9111 | val ROC=0.8676 | val AP=0.8749 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 080 | loss=199.0252 | val ROC=0.8663 | val AP=0.8735 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 090 | loss=6955.0347 | val ROC=0.8650 | val AP=0.8724 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 100 | loss=2605.8933 | val ROC=0.8657 | val AP=0.8732 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 110 | loss=100.7572 | val ROC=0.8663 | val AP=0.8741 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 120 | loss=7837.8940 | val ROC=0.8664 | val AP=0.8744 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 130 | loss=4002.6770 | val ROC=0.8665 | val AP=0.8746 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 140 | loss=3979.7432 | val ROC=0.8664 | val AP=0.8746 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 150 | loss=72.7077 | val ROC=0.8666 | val AP=0.8750 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 160 | loss=168.0715 | val ROC=0.8659 | val AP=0.8746 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 170 | loss=6111.4165 | val ROC=0.8663 | val AP=0.8749 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 180 | loss=11179.0977 | val ROC=0.8656 | val AP=0.8744 | lr=2.50e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 190 | loss=1980.0376 | val ROC=0.8656 | val AP=0.8745 | lr=2.50e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1] ep 200 | loss=112.7010 | val ROC=0.8656 | val AP=0.8745 | lr=2.50e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=1 TEST] ROC-AUC=0.8728 PR-AUC=0.8793\n",
            "  seed=2 -> training APPNP (dot) ...\n",
            "[APPNP (dot) | seed=2] ep 001 | loss=471879.4062 | val ROC=0.8690 | val AP=0.8796 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 010 | loss=7473.7754 | val ROC=0.8728 | val AP=0.8819 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 020 | loss=13880.1445 | val ROC=0.8708 | val AP=0.8801 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 030 | loss=28242.9863 | val ROC=0.8738 | val AP=0.8823 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 040 | loss=11829.3135 | val ROC=0.8701 | val AP=0.8792 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 050 | loss=234.2010 | val ROC=0.8706 | val AP=0.8798 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 060 | loss=3112.9307 | val ROC=0.8722 | val AP=0.8812 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 070 | loss=6805.8672 | val ROC=0.8683 | val AP=0.8785 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 080 | loss=193.5666 | val ROC=0.8703 | val AP=0.8806 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 090 | loss=291.8642 | val ROC=0.8713 | val AP=0.8816 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 100 | loss=13493.6406 | val ROC=0.8685 | val AP=0.8793 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 110 | loss=10388.2158 | val ROC=0.8714 | val AP=0.8816 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 120 | loss=7476.9570 | val ROC=0.8697 | val AP=0.8808 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 130 | loss=189.4683 | val ROC=0.8702 | val AP=0.8811 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 140 | loss=13985.2852 | val ROC=0.8700 | val AP=0.8809 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 150 | loss=103.8845 | val ROC=0.8698 | val AP=0.8809 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 160 | loss=4837.7822 | val ROC=0.8702 | val AP=0.8814 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 170 | loss=7535.7114 | val ROC=0.8709 | val AP=0.8821 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 180 | loss=16956.8105 | val ROC=0.8701 | val AP=0.8815 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 190 | loss=3048.7791 | val ROC=0.8702 | val AP=0.8816 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2] ep 200 | loss=2811.5974 | val ROC=0.8706 | val AP=0.8820 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=2 TEST] ROC-AUC=0.8731 PR-AUC=0.8809\n",
            "  seed=3 -> training APPNP (dot) ...\n",
            "[APPNP (dot) | seed=3] ep 001 | loss=137351.2969 | val ROC=0.8749 | val AP=0.8797 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 010 | loss=20688.3301 | val ROC=0.8705 | val AP=0.8771 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 020 | loss=8668.9844 | val ROC=0.8720 | val AP=0.8787 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 030 | loss=620.9701 | val ROC=0.8727 | val AP=0.8795 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 040 | loss=10120.3486 | val ROC=0.8703 | val AP=0.8780 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 050 | loss=335.1751 | val ROC=0.8708 | val AP=0.8787 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 060 | loss=12533.3027 | val ROC=0.8719 | val AP=0.8796 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 070 | loss=6393.6548 | val ROC=0.8714 | val AP=0.8794 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 080 | loss=178.3317 | val ROC=0.8705 | val AP=0.8788 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 090 | loss=5969.2422 | val ROC=0.8715 | val AP=0.8801 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 100 | loss=28138.4199 | val ROC=0.8700 | val AP=0.8791 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 110 | loss=1113.7988 | val ROC=0.8706 | val AP=0.8796 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 120 | loss=11159.9697 | val ROC=0.8709 | val AP=0.8799 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 130 | loss=678.1384 | val ROC=0.8705 | val AP=0.8799 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 140 | loss=5111.3179 | val ROC=0.8694 | val AP=0.8790 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 150 | loss=8192.0244 | val ROC=0.8701 | val AP=0.8795 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 160 | loss=122.2291 | val ROC=0.8686 | val AP=0.8782 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 170 | loss=2998.6772 | val ROC=0.8706 | val AP=0.8799 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 180 | loss=1059.7612 | val ROC=0.8696 | val AP=0.8790 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 190 | loss=1445.3685 | val ROC=0.8692 | val AP=0.8788 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3] ep 200 | loss=14121.0742 | val ROC=0.8704 | val AP=0.8799 | lr=5.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=3 TEST] ROC-AUC=0.8711 PR-AUC=0.8787\n",
            "  seed=4 -> training APPNP (dot) ...\n",
            "[APPNP (dot) | seed=4] ep 001 | loss=191480.9688 | val ROC=0.8728 | val AP=0.8782 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 010 | loss=22700.5332 | val ROC=0.8674 | val AP=0.8714 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 020 | loss=17338.7383 | val ROC=0.8670 | val AP=0.8707 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 030 | loss=16350.6377 | val ROC=0.8670 | val AP=0.8714 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 040 | loss=786.3231 | val ROC=0.8675 | val AP=0.8725 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 050 | loss=4634.7554 | val ROC=0.8662 | val AP=0.8710 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 060 | loss=1509.5148 | val ROC=0.8673 | val AP=0.8737 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 070 | loss=4061.7058 | val ROC=0.8684 | val AP=0.8763 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 080 | loss=227.0126 | val ROC=0.8694 | val AP=0.8782 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 090 | loss=8792.2139 | val ROC=0.8692 | val AP=0.8787 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 100 | loss=9922.3789 | val ROC=0.8711 | val AP=0.8805 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 110 | loss=128.5694 | val ROC=0.8696 | val AP=0.8789 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 120 | loss=9879.0078 | val ROC=0.8700 | val AP=0.8792 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 130 | loss=199.7632 | val ROC=0.8702 | val AP=0.8797 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 140 | loss=715.4421 | val ROC=0.8700 | val AP=0.8802 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 150 | loss=13890.0547 | val ROC=0.8700 | val AP=0.8800 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 160 | loss=5356.8081 | val ROC=0.8701 | val AP=0.8800 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 170 | loss=673.1001 | val ROC=0.8697 | val AP=0.8798 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 180 | loss=18777.5586 | val ROC=0.8712 | val AP=0.8816 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 190 | loss=3111.5759 | val ROC=0.8708 | val AP=0.8817 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4] ep 200 | loss=133.8427 | val ROC=0.8701 | val AP=0.8810 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[APPNP (dot) | seed=4 TEST] ROC-AUC=0.8705 PR-AUC=0.8805\n",
            "\n",
            "==========================================================================================\n",
            "MODEL: GAT (dot)  (key=gat_dot)\n",
            "==========================================================================================\n",
            "  seed=0 -> training GAT (dot) ...\n",
            "[GAT (dot) | seed=0] ep 001 | loss=1.2377 | val ROC=0.8259 | val AP=0.8305 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 010 | loss=0.5589 | val ROC=0.8689 | val AP=0.8748 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 020 | loss=0.5390 | val ROC=0.8653 | val AP=0.8724 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 030 | loss=0.5330 | val ROC=0.8702 | val AP=0.8773 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 040 | loss=0.5305 | val ROC=0.8761 | val AP=0.8822 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 050 | loss=0.5276 | val ROC=0.8797 | val AP=0.8854 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 060 | loss=0.5229 | val ROC=0.8834 | val AP=0.8890 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 070 | loss=0.5244 | val ROC=0.8876 | val AP=0.8928 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 080 | loss=0.5211 | val ROC=0.8914 | val AP=0.8963 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 090 | loss=0.5182 | val ROC=0.8923 | val AP=0.8973 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 100 | loss=0.5172 | val ROC=0.8952 | val AP=0.9001 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 110 | loss=0.5196 | val ROC=0.8961 | val AP=0.9010 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 120 | loss=0.5171 | val ROC=0.8986 | val AP=0.9045 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 130 | loss=0.5152 | val ROC=0.9000 | val AP=0.9058 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 140 | loss=0.5158 | val ROC=0.8963 | val AP=0.9025 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 150 | loss=0.5125 | val ROC=0.9034 | val AP=0.9097 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 160 | loss=0.5152 | val ROC=0.9039 | val AP=0.9097 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 170 | loss=0.5054 | val ROC=0.9048 | val AP=0.9116 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 180 | loss=0.5077 | val ROC=0.9045 | val AP=0.9110 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 190 | loss=0.5112 | val ROC=0.9054 | val AP=0.9134 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0] ep 200 | loss=0.5050 | val ROC=0.9036 | val AP=0.9105 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=0 TEST] ROC-AUC=0.9051 PR-AUC=0.9132\n",
            "  seed=1 -> training GAT (dot) ...\n",
            "[GAT (dot) | seed=1] ep 001 | loss=2.0708 | val ROC=0.8204 | val AP=0.8289 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 010 | loss=0.5582 | val ROC=0.8700 | val AP=0.8762 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 020 | loss=0.5421 | val ROC=0.8623 | val AP=0.8701 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 030 | loss=0.5355 | val ROC=0.8706 | val AP=0.8780 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 040 | loss=0.5296 | val ROC=0.8770 | val AP=0.8835 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 050 | loss=0.5282 | val ROC=0.8815 | val AP=0.8875 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 060 | loss=0.5250 | val ROC=0.8854 | val AP=0.8910 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 070 | loss=0.5219 | val ROC=0.8894 | val AP=0.8947 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 080 | loss=0.5199 | val ROC=0.8913 | val AP=0.8964 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 090 | loss=0.5195 | val ROC=0.8897 | val AP=0.8951 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 100 | loss=0.5205 | val ROC=0.8946 | val AP=0.9000 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 110 | loss=0.5203 | val ROC=0.8951 | val AP=0.9003 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 120 | loss=0.5161 | val ROC=0.8950 | val AP=0.9005 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 130 | loss=0.5177 | val ROC=0.8963 | val AP=0.9019 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 140 | loss=0.5209 | val ROC=0.8976 | val AP=0.9033 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 150 | loss=0.5112 | val ROC=0.8998 | val AP=0.9054 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 160 | loss=0.5138 | val ROC=0.9014 | val AP=0.9075 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 170 | loss=0.5123 | val ROC=0.8989 | val AP=0.9052 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 180 | loss=0.5122 | val ROC=0.9011 | val AP=0.9074 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 190 | loss=0.5096 | val ROC=0.8982 | val AP=0.9045 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1] ep 200 | loss=0.5101 | val ROC=0.9009 | val AP=0.9071 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=1 TEST] ROC-AUC=0.9016 PR-AUC=0.9076\n",
            "  seed=2 -> training GAT (dot) ...\n",
            "[GAT (dot) | seed=2] ep 001 | loss=1.0649 | val ROC=0.8338 | val AP=0.8424 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 010 | loss=0.5594 | val ROC=0.8667 | val AP=0.8732 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 020 | loss=0.5424 | val ROC=0.8628 | val AP=0.8700 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 030 | loss=0.5350 | val ROC=0.8704 | val AP=0.8778 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 040 | loss=0.5292 | val ROC=0.8772 | val AP=0.8834 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 050 | loss=0.5249 | val ROC=0.8824 | val AP=0.8881 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 060 | loss=0.5242 | val ROC=0.8890 | val AP=0.8944 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 070 | loss=0.5186 | val ROC=0.8923 | val AP=0.8974 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 080 | loss=0.5177 | val ROC=0.8960 | val AP=0.9011 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 090 | loss=0.5165 | val ROC=0.8944 | val AP=0.8997 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 100 | loss=0.5179 | val ROC=0.8979 | val AP=0.9034 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 110 | loss=0.5148 | val ROC=0.8998 | val AP=0.9051 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 120 | loss=0.5158 | val ROC=0.9000 | val AP=0.9059 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 130 | loss=0.5137 | val ROC=0.8996 | val AP=0.9057 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 140 | loss=0.5122 | val ROC=0.9002 | val AP=0.9068 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 150 | loss=0.5100 | val ROC=0.9008 | val AP=0.9067 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 160 | loss=0.5166 | val ROC=0.9026 | val AP=0.9088 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 170 | loss=0.5080 | val ROC=0.9035 | val AP=0.9103 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 180 | loss=0.5136 | val ROC=0.9036 | val AP=0.9108 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 190 | loss=0.5078 | val ROC=0.9014 | val AP=0.9084 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2] ep 200 | loss=0.5068 | val ROC=0.9036 | val AP=0.9107 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=2 TEST] ROC-AUC=0.9036 PR-AUC=0.9107\n",
            "  seed=3 -> training GAT (dot) ...\n",
            "[GAT (dot) | seed=3] ep 001 | loss=0.8906 | val ROC=0.8368 | val AP=0.8448 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 010 | loss=0.5570 | val ROC=0.8626 | val AP=0.8696 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 020 | loss=0.5396 | val ROC=0.8646 | val AP=0.8722 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 030 | loss=0.5336 | val ROC=0.8717 | val AP=0.8783 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 040 | loss=0.5287 | val ROC=0.8779 | val AP=0.8836 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 050 | loss=0.5277 | val ROC=0.8823 | val AP=0.8876 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 060 | loss=0.5231 | val ROC=0.8866 | val AP=0.8912 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 070 | loss=0.5238 | val ROC=0.8893 | val AP=0.8940 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 080 | loss=0.5200 | val ROC=0.8912 | val AP=0.8957 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 090 | loss=0.5201 | val ROC=0.8927 | val AP=0.8971 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 100 | loss=0.5192 | val ROC=0.8947 | val AP=0.8993 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 110 | loss=0.5183 | val ROC=0.8961 | val AP=0.9005 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 120 | loss=0.5204 | val ROC=0.8940 | val AP=0.8989 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 130 | loss=0.5188 | val ROC=0.8971 | val AP=0.9019 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 140 | loss=0.5151 | val ROC=0.8982 | val AP=0.9027 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 150 | loss=0.5161 | val ROC=0.8982 | val AP=0.9024 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 160 | loss=0.5175 | val ROC=0.9000 | val AP=0.9052 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 170 | loss=0.5246 | val ROC=0.8990 | val AP=0.9041 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 180 | loss=0.5206 | val ROC=0.8968 | val AP=0.9024 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 190 | loss=0.5133 | val ROC=0.8977 | val AP=0.9033 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3] ep 200 | loss=0.5147 | val ROC=0.8983 | val AP=0.9039 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=3 TEST] ROC-AUC=0.9003 PR-AUC=0.9057\n",
            "  seed=4 -> training GAT (dot) ...\n",
            "[GAT (dot) | seed=4] ep 001 | loss=1.0675 | val ROC=0.8300 | val AP=0.8339 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 010 | loss=0.5585 | val ROC=0.8649 | val AP=0.8712 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 020 | loss=0.5385 | val ROC=0.8656 | val AP=0.8730 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 030 | loss=0.5330 | val ROC=0.8710 | val AP=0.8776 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 040 | loss=0.5302 | val ROC=0.8764 | val AP=0.8825 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 050 | loss=0.5261 | val ROC=0.8805 | val AP=0.8865 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 060 | loss=0.5219 | val ROC=0.8842 | val AP=0.8900 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 070 | loss=0.5227 | val ROC=0.8904 | val AP=0.8956 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 080 | loss=0.5200 | val ROC=0.8927 | val AP=0.8976 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 090 | loss=0.5207 | val ROC=0.8933 | val AP=0.8979 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 100 | loss=0.5171 | val ROC=0.8949 | val AP=0.8993 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 110 | loss=0.5135 | val ROC=0.8943 | val AP=0.9000 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 120 | loss=0.5128 | val ROC=0.8995 | val AP=0.9053 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 130 | loss=0.5114 | val ROC=0.9023 | val AP=0.9080 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 140 | loss=0.5111 | val ROC=0.9011 | val AP=0.9070 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 150 | loss=0.5184 | val ROC=0.8996 | val AP=0.9064 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 160 | loss=0.5078 | val ROC=0.9006 | val AP=0.9074 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 170 | loss=0.5211 | val ROC=0.9035 | val AP=0.9102 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 180 | loss=0.5074 | val ROC=0.9025 | val AP=0.9092 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 190 | loss=0.5054 | val ROC=0.9043 | val AP=0.9108 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4] ep 200 | loss=0.5138 | val ROC=0.9057 | val AP=0.9126 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GAT (dot) | seed=4 TEST] ROC-AUC=0.9048 PR-AUC=0.9120\n",
            "\n",
            "==========================================================================================\n",
            "MODEL: GCN + EdgeMLP  (key=gcn_edgemlp)\n",
            "==========================================================================================\n",
            "  seed=0 -> training GCN + EdgeMLP ...\n",
            "[GCN + EdgeMLP | seed=0] ep 001 | loss=0.6780 | val ROC=0.8313 | val AP=0.8321 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 010 | loss=0.5128 | val ROC=0.8827 | val AP=0.8944 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 020 | loss=0.4190 | val ROC=0.8781 | val AP=0.8933 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 030 | loss=0.4057 | val ROC=0.8858 | val AP=0.9009 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 040 | loss=0.3868 | val ROC=0.8965 | val AP=0.9100 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 050 | loss=0.3632 | val ROC=0.9072 | val AP=0.9188 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 060 | loss=0.3342 | val ROC=0.9176 | val AP=0.9282 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 070 | loss=0.3122 | val ROC=0.9244 | val AP=0.9342 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 080 | loss=0.2996 | val ROC=0.9278 | val AP=0.9373 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 090 | loss=0.2886 | val ROC=0.9307 | val AP=0.9398 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 100 | loss=0.2818 | val ROC=0.9330 | val AP=0.9415 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 110 | loss=0.2752 | val ROC=0.9347 | val AP=0.9430 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 120 | loss=0.2670 | val ROC=0.9362 | val AP=0.9443 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 130 | loss=0.2630 | val ROC=0.9377 | val AP=0.9457 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 140 | loss=0.2573 | val ROC=0.9391 | val AP=0.9470 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 150 | loss=0.2518 | val ROC=0.9404 | val AP=0.9482 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 160 | loss=0.2482 | val ROC=0.9414 | val AP=0.9492 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 170 | loss=0.2442 | val ROC=0.9423 | val AP=0.9501 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 180 | loss=0.2421 | val ROC=0.9430 | val AP=0.9507 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 190 | loss=0.2397 | val ROC=0.9436 | val AP=0.9513 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=0] ep 200 | loss=0.2363 | val ROC=0.9441 | val AP=0.9518 | lr=1.00e-03\n",
            "[GCN + EdgeMLP | seed=0 TEST] ROC-AUC=0.9432 PR-AUC=0.9505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=1 -> training GCN + EdgeMLP ...\n",
            "[GCN + EdgeMLP | seed=1] ep 001 | loss=0.6893 | val ROC=0.8794 | val AP=0.8900 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 010 | loss=0.5315 | val ROC=0.8799 | val AP=0.8896 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 020 | loss=0.4271 | val ROC=0.8745 | val AP=0.8888 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 030 | loss=0.4150 | val ROC=0.8821 | val AP=0.8959 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 040 | loss=0.3973 | val ROC=0.8910 | val AP=0.9046 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 050 | loss=0.3750 | val ROC=0.9015 | val AP=0.9132 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 060 | loss=0.3479 | val ROC=0.9129 | val AP=0.9238 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 070 | loss=0.3222 | val ROC=0.9215 | val AP=0.9318 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 080 | loss=0.3097 | val ROC=0.9254 | val AP=0.9352 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 090 | loss=0.2979 | val ROC=0.9288 | val AP=0.9380 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 100 | loss=0.2893 | val ROC=0.9311 | val AP=0.9399 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 110 | loss=0.2825 | val ROC=0.9328 | val AP=0.9413 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 120 | loss=0.2749 | val ROC=0.9344 | val AP=0.9426 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 130 | loss=0.2701 | val ROC=0.9359 | val AP=0.9440 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 140 | loss=0.2632 | val ROC=0.9374 | val AP=0.9453 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 150 | loss=0.2580 | val ROC=0.9388 | val AP=0.9465 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 160 | loss=0.2540 | val ROC=0.9399 | val AP=0.9477 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 170 | loss=0.2493 | val ROC=0.9409 | val AP=0.9486 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 180 | loss=0.2456 | val ROC=0.9416 | val AP=0.9493 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 190 | loss=0.2423 | val ROC=0.9422 | val AP=0.9500 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=1] ep 200 | loss=0.2414 | val ROC=0.9429 | val AP=0.9506 | lr=1.00e-03\n",
            "[GCN + EdgeMLP | seed=1 TEST] ROC-AUC=0.9420 PR-AUC=0.9493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=2 -> training GCN + EdgeMLP ...\n",
            "[GCN + EdgeMLP | seed=2] ep 001 | loss=0.7116 | val ROC=0.5593 | val AP=0.6235 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 010 | loss=0.5583 | val ROC=0.8791 | val AP=0.8913 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 020 | loss=0.4240 | val ROC=0.8779 | val AP=0.8921 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 030 | loss=0.4182 | val ROC=0.8820 | val AP=0.8965 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 040 | loss=0.3944 | val ROC=0.8923 | val AP=0.9056 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 050 | loss=0.3770 | val ROC=0.9018 | val AP=0.9137 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 060 | loss=0.3498 | val ROC=0.9115 | val AP=0.9224 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 070 | loss=0.3239 | val ROC=0.9226 | val AP=0.9324 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 080 | loss=0.3043 | val ROC=0.9270 | val AP=0.9364 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 090 | loss=0.2948 | val ROC=0.9297 | val AP=0.9385 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 100 | loss=0.2857 | val ROC=0.9322 | val AP=0.9405 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 110 | loss=0.2785 | val ROC=0.9340 | val AP=0.9421 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 120 | loss=0.2719 | val ROC=0.9355 | val AP=0.9434 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 130 | loss=0.2665 | val ROC=0.9370 | val AP=0.9448 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 140 | loss=0.2610 | val ROC=0.9384 | val AP=0.9461 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 150 | loss=0.2560 | val ROC=0.9397 | val AP=0.9472 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 160 | loss=0.2524 | val ROC=0.9406 | val AP=0.9481 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 170 | loss=0.2491 | val ROC=0.9415 | val AP=0.9489 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 180 | loss=0.2453 | val ROC=0.9421 | val AP=0.9495 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 190 | loss=0.2432 | val ROC=0.9427 | val AP=0.9501 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2] ep 200 | loss=0.2416 | val ROC=0.9432 | val AP=0.9506 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=2 TEST] ROC-AUC=0.9423 PR-AUC=0.9494\n",
            "  seed=3 -> training GCN + EdgeMLP ...\n",
            "[GCN + EdgeMLP | seed=3] ep 001 | loss=0.6793 | val ROC=0.8136 | val AP=0.8100 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 010 | loss=0.5190 | val ROC=0.8780 | val AP=0.8896 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 020 | loss=0.4263 | val ROC=0.8763 | val AP=0.8916 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 030 | loss=0.4125 | val ROC=0.8832 | val AP=0.8983 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 040 | loss=0.3917 | val ROC=0.8931 | val AP=0.9064 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 050 | loss=0.3712 | val ROC=0.9035 | val AP=0.9151 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 060 | loss=0.3459 | val ROC=0.9136 | val AP=0.9243 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 070 | loss=0.3200 | val ROC=0.9226 | val AP=0.9325 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 080 | loss=0.3056 | val ROC=0.9261 | val AP=0.9358 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 090 | loss=0.2940 | val ROC=0.9290 | val AP=0.9384 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 100 | loss=0.2845 | val ROC=0.9317 | val AP=0.9406 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 110 | loss=0.2775 | val ROC=0.9338 | val AP=0.9423 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 120 | loss=0.2705 | val ROC=0.9357 | val AP=0.9439 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 130 | loss=0.2644 | val ROC=0.9373 | val AP=0.9454 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 140 | loss=0.2588 | val ROC=0.9388 | val AP=0.9467 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 150 | loss=0.2534 | val ROC=0.9401 | val AP=0.9479 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 160 | loss=0.2498 | val ROC=0.9411 | val AP=0.9489 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 170 | loss=0.2457 | val ROC=0.9420 | val AP=0.9497 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 180 | loss=0.2429 | val ROC=0.9427 | val AP=0.9504 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 190 | loss=0.2413 | val ROC=0.9433 | val AP=0.9510 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3] ep 200 | loss=0.2379 | val ROC=0.9439 | val AP=0.9515 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=3 TEST] ROC-AUC=0.9428 PR-AUC=0.9501\n",
            "  seed=4 -> training GCN + EdgeMLP ...\n",
            "[GCN + EdgeMLP | seed=4] ep 001 | loss=0.6929 | val ROC=0.8381 | val AP=0.8419 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 010 | loss=0.5336 | val ROC=0.8816 | val AP=0.8916 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 020 | loss=0.4291 | val ROC=0.8754 | val AP=0.8894 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 030 | loss=0.4139 | val ROC=0.8827 | val AP=0.8961 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 040 | loss=0.3967 | val ROC=0.8906 | val AP=0.9041 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 050 | loss=0.3788 | val ROC=0.8989 | val AP=0.9114 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 060 | loss=0.3529 | val ROC=0.9096 | val AP=0.9215 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 070 | loss=0.3292 | val ROC=0.9183 | val AP=0.9294 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 080 | loss=0.3135 | val ROC=0.9230 | val AP=0.9335 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 090 | loss=0.2998 | val ROC=0.9273 | val AP=0.9370 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 100 | loss=0.2914 | val ROC=0.9307 | val AP=0.9398 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 110 | loss=0.2825 | val ROC=0.9332 | val AP=0.9417 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 120 | loss=0.2751 | val ROC=0.9350 | val AP=0.9432 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 130 | loss=0.2682 | val ROC=0.9368 | val AP=0.9447 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 140 | loss=0.2621 | val ROC=0.9383 | val AP=0.9462 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 150 | loss=0.2560 | val ROC=0.9397 | val AP=0.9475 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 160 | loss=0.2509 | val ROC=0.9407 | val AP=0.9485 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 170 | loss=0.2455 | val ROC=0.9418 | val AP=0.9494 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 180 | loss=0.2435 | val ROC=0.9426 | val AP=0.9502 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 190 | loss=0.2415 | val ROC=0.9430 | val AP=0.9507 | lr=1.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN + EdgeMLP | seed=4] ep 200 | loss=0.2388 | val ROC=0.9436 | val AP=0.9512 | lr=1.00e-03\n",
            "[GCN + EdgeMLP | seed=4 TEST] ROC-AUC=0.9426 PR-AUC=0.9498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "MODEL: VGAE (inner)  (key=vgae)\n",
            "==========================================================================================\n",
            "  seed=0 -> training VGAE ...\n",
            "[VGAE] ep 001 | loss=6.4575 | val ROC=0.8709 | val AP=0.8772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 010 | loss=4.7798 | val ROC=0.8727 | val AP=0.8773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 020 | loss=3.8717 | val ROC=0.8660 | val AP=0.8738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 030 | loss=3.0752 | val ROC=0.8573 | val AP=0.8689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 040 | loss=2.4585 | val ROC=0.8727 | val AP=0.8851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 050 | loss=1.9877 | val ROC=0.8874 | val AP=0.8999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 060 | loss=1.6779 | val ROC=0.8907 | val AP=0.9035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 070 | loss=1.4612 | val ROC=0.8955 | val AP=0.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 080 | loss=1.3215 | val ROC=0.8969 | val AP=0.9089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 090 | loss=1.2371 | val ROC=0.8979 | val AP=0.9101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 100 | loss=1.1750 | val ROC=0.9001 | val AP=0.9123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 110 | loss=1.1334 | val ROC=0.9021 | val AP=0.9142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 120 | loss=1.1085 | val ROC=0.9034 | val AP=0.9155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 130 | loss=1.0863 | val ROC=0.9053 | val AP=0.9173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 140 | loss=1.0671 | val ROC=0.9063 | val AP=0.9183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 150 | loss=1.0523 | val ROC=0.9078 | val AP=0.9196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 160 | loss=1.0410 | val ROC=0.9081 | val AP=0.9201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 170 | loss=1.0376 | val ROC=0.9096 | val AP=0.9215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 180 | loss=1.0287 | val ROC=0.9114 | val AP=0.9230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 190 | loss=1.0187 | val ROC=0.9115 | val AP=0.9233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 200 | loss=1.0175 | val ROC=0.9123 | val AP=0.9241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=1 -> training VGAE ...\n",
            "[VGAE] ep 001 | loss=7.4966 | val ROC=0.8636 | val AP=0.8738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 010 | loss=5.1396 | val ROC=0.8721 | val AP=0.8767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 020 | loss=4.1737 | val ROC=0.8707 | val AP=0.8770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 030 | loss=3.3253 | val ROC=0.8615 | val AP=0.8726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 040 | loss=2.6823 | val ROC=0.8674 | val AP=0.8799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 050 | loss=2.1599 | val ROC=0.8840 | val AP=0.8971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 060 | loss=1.8098 | val ROC=0.8881 | val AP=0.9017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 070 | loss=1.5777 | val ROC=0.8949 | val AP=0.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 080 | loss=1.4027 | val ROC=0.8993 | val AP=0.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 090 | loss=1.2862 | val ROC=0.8998 | val AP=0.9119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 100 | loss=1.2183 | val ROC=0.9006 | val AP=0.9127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 110 | loss=1.1693 | val ROC=0.9028 | val AP=0.9146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 120 | loss=1.1352 | val ROC=0.9029 | val AP=0.9148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 130 | loss=1.1086 | val ROC=0.9044 | val AP=0.9162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 140 | loss=1.0882 | val ROC=0.9066 | val AP=0.9181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 150 | loss=1.0711 | val ROC=0.9080 | val AP=0.9193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 160 | loss=1.0559 | val ROC=0.9088 | val AP=0.9201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 170 | loss=1.0467 | val ROC=0.9102 | val AP=0.9214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 180 | loss=1.0386 | val ROC=0.9103 | val AP=0.9217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 190 | loss=1.0352 | val ROC=0.9117 | val AP=0.9230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 200 | loss=1.0249 | val ROC=0.9119 | val AP=0.9233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=2 -> training VGAE ...\n",
            "[VGAE] ep 001 | loss=8.2963 | val ROC=0.8644 | val AP=0.8737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 010 | loss=5.4237 | val ROC=0.8695 | val AP=0.8717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 020 | loss=4.4400 | val ROC=0.8675 | val AP=0.8719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 030 | loss=3.4767 | val ROC=0.8603 | val AP=0.8692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 040 | loss=2.7739 | val ROC=0.8677 | val AP=0.8789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 050 | loss=2.2620 | val ROC=0.8818 | val AP=0.8943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 060 | loss=1.9053 | val ROC=0.8872 | val AP=0.9002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 070 | loss=1.6496 | val ROC=0.8942 | val AP=0.9066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 080 | loss=1.4677 | val ROC=0.8974 | val AP=0.9094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 090 | loss=1.3408 | val ROC=0.8971 | val AP=0.9093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 100 | loss=1.2571 | val ROC=0.8971 | val AP=0.9097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 110 | loss=1.2035 | val ROC=0.8977 | val AP=0.9104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 120 | loss=1.1635 | val ROC=0.8984 | val AP=0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 130 | loss=1.1318 | val ROC=0.8979 | val AP=0.9108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 140 | loss=1.1094 | val ROC=0.8986 | val AP=0.9115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 150 | loss=1.0939 | val ROC=0.8995 | val AP=0.9123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 160 | loss=1.0785 | val ROC=0.8995 | val AP=0.9124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 170 | loss=1.0687 | val ROC=0.9007 | val AP=0.9135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 180 | loss=1.0596 | val ROC=0.9022 | val AP=0.9147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 190 | loss=1.0474 | val ROC=0.9032 | val AP=0.9156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 200 | loss=1.0433 | val ROC=0.9048 | val AP=0.9170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=3 -> training VGAE ...\n",
            "[VGAE] ep 001 | loss=7.3343 | val ROC=0.8680 | val AP=0.8749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 010 | loss=5.1544 | val ROC=0.8702 | val AP=0.8735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 020 | loss=4.1367 | val ROC=0.8682 | val AP=0.8745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 030 | loss=3.2390 | val ROC=0.8626 | val AP=0.8729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 040 | loss=2.6029 | val ROC=0.8727 | val AP=0.8844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 050 | loss=2.1108 | val ROC=0.8828 | val AP=0.8955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 060 | loss=1.7921 | val ROC=0.8868 | val AP=0.9001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 070 | loss=1.5601 | val ROC=0.8941 | val AP=0.9066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 080 | loss=1.4055 | val ROC=0.8978 | val AP=0.9098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 090 | loss=1.2941 | val ROC=0.8980 | val AP=0.9102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 100 | loss=1.2281 | val ROC=0.8992 | val AP=0.9115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 110 | loss=1.1775 | val ROC=0.9014 | val AP=0.9134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 120 | loss=1.1393 | val ROC=0.9035 | val AP=0.9153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 130 | loss=1.1112 | val ROC=0.9040 | val AP=0.9159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 140 | loss=1.0946 | val ROC=0.9052 | val AP=0.9170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 150 | loss=1.0729 | val ROC=0.9073 | val AP=0.9189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 160 | loss=1.0635 | val ROC=0.9080 | val AP=0.9195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 170 | loss=1.0488 | val ROC=0.9089 | val AP=0.9203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 180 | loss=1.0430 | val ROC=0.9095 | val AP=0.9209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 190 | loss=1.0348 | val ROC=0.9109 | val AP=0.9223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 200 | loss=1.0293 | val ROC=0.9112 | val AP=0.9227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed=4 -> training VGAE ...\n",
            "[VGAE] ep 001 | loss=7.5567 | val ROC=0.8695 | val AP=0.8806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 010 | loss=5.1254 | val ROC=0.8724 | val AP=0.8799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 020 | loss=4.2126 | val ROC=0.8692 | val AP=0.8777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 030 | loss=3.4390 | val ROC=0.8599 | val AP=0.8723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 040 | loss=2.8058 | val ROC=0.8639 | val AP=0.8774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 050 | loss=2.2814 | val ROC=0.8797 | val AP=0.8927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 060 | loss=1.9105 | val ROC=0.8877 | val AP=0.9004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 070 | loss=1.6277 | val ROC=0.8927 | val AP=0.9050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 080 | loss=1.4279 | val ROC=0.8960 | val AP=0.9077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 090 | loss=1.3197 | val ROC=0.8966 | val AP=0.9083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 100 | loss=1.2230 | val ROC=0.8968 | val AP=0.9088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 110 | loss=1.1787 | val ROC=0.9000 | val AP=0.9118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 120 | loss=1.1408 | val ROC=0.9002 | val AP=0.9122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 130 | loss=1.1096 | val ROC=0.9022 | val AP=0.9142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 140 | loss=1.0923 | val ROC=0.9038 | val AP=0.9156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 150 | loss=1.0750 | val ROC=0.9052 | val AP=0.9169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 160 | loss=1.0598 | val ROC=0.9064 | val AP=0.9182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 170 | loss=1.0490 | val ROC=0.9075 | val AP=0.9192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 180 | loss=1.0379 | val ROC=0.9084 | val AP=0.9200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 190 | loss=1.0310 | val ROC=0.9093 | val AP=0.9209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VGAE] ep 200 | loss=1.0240 | val ROC=0.9097 | val AP=0.9214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       model model_key  seed  test_roc_auc   test_ap  best_val_ap  best_epoch  \\\n",
              "0  GCN (dot)   gcn_dot     0      0.920354  0.931712     0.932977         200   \n",
              "1  GCN (dot)   gcn_dot     1      0.918805  0.930306     0.931269         200   \n",
              "2  GCN (dot)   gcn_dot     2      0.919188  0.930664     0.931878         200   \n",
              "3  GCN (dot)   gcn_dot     3      0.919226  0.930652     0.931685         200   \n",
              "4  GCN (dot)   gcn_dot     4      0.919439  0.930550     0.931578         200   \n",
              "\n",
              "   hidden  emb_dim  dropout     lr  weight_decay  neg_ratio  epochs  patience  \\\n",
              "0     128       64      0.2  0.001        0.0001        1.0     200        25   \n",
              "1     128       64      0.2  0.001        0.0001        1.0     200        25   \n",
              "2     128       64      0.2  0.001        0.0001        1.0     200        25   \n",
              "3     128       64      0.2  0.001        0.0001        1.0     200        25   \n",
              "4     128       64      0.2  0.001        0.0001        1.0     200        25   \n",
              "\n",
              "   edge_dropout  \n",
              "0           0.1  \n",
              "1           0.1  \n",
              "2           0.1  \n",
              "3           0.1  \n",
              "4           0.1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6454ad81-fe35-4067-8ba9-5fbe40242c59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>model_key</th>\n",
              "      <th>seed</th>\n",
              "      <th>test_roc_auc</th>\n",
              "      <th>test_ap</th>\n",
              "      <th>best_val_ap</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>hidden</th>\n",
              "      <th>emb_dim</th>\n",
              "      <th>dropout</th>\n",
              "      <th>lr</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>neg_ratio</th>\n",
              "      <th>epochs</th>\n",
              "      <th>patience</th>\n",
              "      <th>edge_dropout</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>0</td>\n",
              "      <td>0.920354</td>\n",
              "      <td>0.931712</td>\n",
              "      <td>0.932977</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>25</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>1</td>\n",
              "      <td>0.918805</td>\n",
              "      <td>0.930306</td>\n",
              "      <td>0.931269</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>25</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>2</td>\n",
              "      <td>0.919188</td>\n",
              "      <td>0.930664</td>\n",
              "      <td>0.931878</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>25</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>3</td>\n",
              "      <td>0.919226</td>\n",
              "      <td>0.930652</td>\n",
              "      <td>0.931685</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>25</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>4</td>\n",
              "      <td>0.919439</td>\n",
              "      <td>0.930550</td>\n",
              "      <td>0.931578</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>25</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6454ad81-fe35-4067-8ba9-5fbe40242c59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6454ad81-fe35-4067-8ba9-5fbe40242c59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6454ad81-fe35-4067-8ba9-5fbe40242c59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Ready for downstream pipeline (clustering, CORUM validation, disease enrichment, etc\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GCN (dot)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_key\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gcn_dot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005788481249144137,\n        \"min\": 0.9188051244878117,\n        \"max\": 0.9203538266171948,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9188051244878117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005421971421548585,\n        \"min\": 0.9303056169817315,\n        \"max\": 0.9317118779754698,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9303056169817315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_val_ap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006530754230056797,\n        \"min\": 0.9312691246882088,\n        \"max\": 0.9329769911671992,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9312691246882088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 200,\n        \"max\": 200,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hidden\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 128,\n        \"max\": 128,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emb_dim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 64,\n        \"max\": 64,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.001,\n        \"max\": 0.001,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight_decay\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0001,\n        \"max\": 0.0001,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 200,\n        \"max\": 200,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 25,\n        \"max\": 25,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edge_dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.1,\n        \"max\": 0.1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             model      model_key  val_ap_mean  val_ap_std  test_ap_mean  \\\n",
              "0    GCN + EdgeMLP    gcn_edgemlp     0.951159    0.000544      0.949813   \n",
              "1  GraphSAGE (dot)  graphsage_dot     0.935760    0.000778      0.935077   \n",
              "2        GCN (dot)        gcn_dot     0.931877    0.000653      0.930777   \n",
              "3     VGAE (inner)           vgae     0.921694    0.002831      0.921082   \n",
              "4        GAT (dot)        gat_dot     0.909866    0.003461      0.909836   \n",
              "5      APPNP (dot)      appnp_dot     0.881316    0.000812      0.879929   \n",
              "\n",
              "   test_ap_std  test_roc_mean  test_roc_std  \n",
              "0     0.000486       0.942580      0.000472  \n",
              "1     0.000765       0.924948      0.000897  \n",
              "2     0.000542       0.919402      0.000579  \n",
              "3     0.002779       0.910082      0.003057  \n",
              "4     0.003120       0.903072      0.002059  \n",
              "5     0.000894       0.871633      0.001242  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2104ebb3-771b-4edc-b5b9-11201ed982c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>model_key</th>\n",
              "      <th>val_ap_mean</th>\n",
              "      <th>val_ap_std</th>\n",
              "      <th>test_ap_mean</th>\n",
              "      <th>test_ap_std</th>\n",
              "      <th>test_roc_mean</th>\n",
              "      <th>test_roc_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GCN + EdgeMLP</td>\n",
              "      <td>gcn_edgemlp</td>\n",
              "      <td>0.951159</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.949813</td>\n",
              "      <td>0.000486</td>\n",
              "      <td>0.942580</td>\n",
              "      <td>0.000472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GraphSAGE (dot)</td>\n",
              "      <td>graphsage_dot</td>\n",
              "      <td>0.935760</td>\n",
              "      <td>0.000778</td>\n",
              "      <td>0.935077</td>\n",
              "      <td>0.000765</td>\n",
              "      <td>0.924948</td>\n",
              "      <td>0.000897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GCN (dot)</td>\n",
              "      <td>gcn_dot</td>\n",
              "      <td>0.931877</td>\n",
              "      <td>0.000653</td>\n",
              "      <td>0.930777</td>\n",
              "      <td>0.000542</td>\n",
              "      <td>0.919402</td>\n",
              "      <td>0.000579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VGAE (inner)</td>\n",
              "      <td>vgae</td>\n",
              "      <td>0.921694</td>\n",
              "      <td>0.002831</td>\n",
              "      <td>0.921082</td>\n",
              "      <td>0.002779</td>\n",
              "      <td>0.910082</td>\n",
              "      <td>0.003057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GAT (dot)</td>\n",
              "      <td>gat_dot</td>\n",
              "      <td>0.909866</td>\n",
              "      <td>0.003461</td>\n",
              "      <td>0.909836</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.903072</td>\n",
              "      <td>0.002059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>APPNP (dot)</td>\n",
              "      <td>appnp_dot</td>\n",
              "      <td>0.881316</td>\n",
              "      <td>0.000812</td>\n",
              "      <td>0.879929</td>\n",
              "      <td>0.000894</td>\n",
              "      <td>0.871633</td>\n",
              "      <td>0.001242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2104ebb3-771b-4edc-b5b9-11201ed982c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2104ebb3-771b-4edc-b5b9-11201ed982c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2104ebb3-771b-4edc-b5b9-11201ed982c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fcd69109-f0c4-4bdd-ba63-587240a169a3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('agg')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fcd69109-f0c4-4bdd-ba63-587240a169a3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('agg');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "agg",
              "summary": "{\n  \"name\": \"agg\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"GCN + EdgeMLP\",\n          \"GraphSAGE (dot)\",\n          \"APPNP (dot)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"gcn_edgemlp\",\n          \"graphsage_dot\",\n          \"appnp_dot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ap_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024247192356133505,\n        \"min\": 0.8813163714379927,\n        \"max\": 0.951159406523268,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.951159406523268,\n          0.9357595330605484,\n          0.8813163714379927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ap_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0012838447153308082,\n        \"min\": 0.0005437949063708078,\n        \"max\": 0.003460894915941002,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0005437949063708078,\n          0.0007781157166068061,\n          0.0008115065877440457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ap_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02422968392035307,\n        \"min\": 0.8799286930242568,\n        \"max\": 0.9498126819034741,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9498126819034741,\n          0.9350774156890816,\n          0.8799286930242568\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ap_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0011903491268197858,\n        \"min\": 0.0004860708888059577,\n        \"max\": 0.0031200077156533375,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0004860708888059577,\n          0.0007652934644925766,\n          0.0008936682487146034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_roc_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023960074216243958,\n        \"min\": 0.8716330178881802,\n        \"max\": 0.9425795928076222,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9425795928076222,\n          0.9249480085096558,\n          0.8716330178881802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_roc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009992207327029668,\n        \"min\": 0.0004716548379232038,\n        \"max\": 0.0030569447669680223,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0004716548379232038,\n          0.0008972064670726315,\n          0.0012415409155998934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: gnn_linkpred_multiseed_summary.csv\n",
            "Saved: gnn_linkpred_multiseed_trials.csv\n",
            "\n",
            "✅ Best model by VAL (mean AP): GCN + EdgeMLP (key=gcn_edgemlp)\n",
            "✅ Best seed for downstream embeddings (highest VAL AP within best model): 0\n",
            "Saved: embeddings_train_gcn_edgemlp.npy (16584, 64) (seed=0)\n",
            "Saved: embeddings_train_graphsage_dot.npy (16584, 64) (seed=0)\n",
            "Saved: embeddings_train_gcn_dot.npy (16584, 64) (seed=0)\n",
            "Saved: embeddings_train_vgae.npy (16584, 64) (seed=0)\n",
            "Saved: embeddings_train_gat_dot.npy (16584, 64) (seed=0)\n",
            "Saved: embeddings_train_appnp_dot.npy (16584, 64) (seed=2)\n",
            "✅ Ready for downstream pipeline (clustering, CORUM validation, disease enrichment, etc.)\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# 4B) Train + compare GNNs (APPNP/GCN/GraphSAGE/GAT) with DOT decoder + GCN+EdgeMLP + VGAE\n",
        "# - Multi-seed mean±std (paper-ready)\n",
        "# - Model selection by VAL (NO test leakage)\n",
        "# - Exports embeddings for downstream clustering\n",
        "# =========================\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "assert \"data_train\" in globals() and \"data_val\" in globals() and \"data_test\" in globals(), \"Missing train/val/test graph splits.\"\n",
        "assert hasattr(data_train, \"x\") and hasattr(data_train, \"edge_index\"), \"data_train must be a PyG Data object.\"\n",
        "assert \"build_lp_model\" in globals(), \"Missing build_lp_model(). Run the utilities cell first.\"\n",
        "assert \"train_linkpred\" in globals(), \"Missing train_linkpred(). Run the utilities cell first.\"\n",
        "assert \"get_eval_edges_and_labels\" in globals(), \"Missing get_eval_edges_and_labels(). Run the utilities cell first.\"\n",
        "assert \"set_seed\" in globals(), \"Missing set_seed(). Run the utilities cell first.\"\n",
        "\n",
        "# ---- Paper-friendly default hyperparams ----\n",
        "EPOCHS = 200\n",
        "PATIENCE = 25\n",
        "NEG_RATIO = 1.0\n",
        "HIDDEN = 128\n",
        "EMB_DIM = 64\n",
        "DROPOUT = 0.2\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "USE_AMP = True\n",
        "EDGE_DROPOUT = 0.1\n",
        "\n",
        "# APPNP-specific\n",
        "APPNP_K = 10\n",
        "APPNP_ALPHA = 0.1\n",
        "\n",
        "# GAT-specific\n",
        "GAT_HEADS = 4\n",
        "\n",
        "# Multi-seed evaluation (set to 5 for paper; 3 for faster dev)\n",
        "SEEDS = [0, 1, 2, 3, 4]\n",
        "\n",
        "# Models:\n",
        "# - DOT decoder baselines (fair)\n",
        "# - one stronger decoder baseline (GCN + Edge-MLP)\n",
        "# - VGAE baseline (unsupervised; inner product)\n",
        "MODELS_TO_RUN = [\n",
        "    {\"key\": \"gcn_dot\",       \"encoder\": \"gcn\",       \"decoder\": \"dot\",      \"name\": \"GCN (dot)\"},\n",
        "    {\"key\": \"graphsage_dot\", \"encoder\": \"graphsage\", \"decoder\": \"dot\",      \"name\": \"GraphSAGE (dot)\"},\n",
        "    {\"key\": \"appnp_dot\",     \"encoder\": \"appnp\",     \"decoder\": \"dot\",      \"name\": \"APPNP (dot)\"},\n",
        "    {\"key\": \"gat_dot\",       \"encoder\": \"gat\",       \"decoder\": \"dot\",      \"name\": \"GAT (dot)\"},\n",
        "    {\"key\": \"gcn_edgemlp\",   \"encoder\": \"gcn\",       \"decoder\": \"edge_mlp\", \"name\": \"GCN + EdgeMLP\"},\n",
        "    {\"key\": \"vgae\",          \"encoder\": \"vgae\",      \"decoder\": \"inner\",    \"name\": \"VGAE (inner)\"},\n",
        "]\n",
        "\n",
        "def _cleanup():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ------------------------------------------\n",
        "# VGAE baseline (unsupervised reconstruction)\n",
        "# ------------------------------------------\n",
        "from torch_geometric.nn import VGAE\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class VariationalGCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv_mu = GCNConv(hidden_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "@torch.no_grad()\n",
        "def _score_edges_inner(z, edge_index):\n",
        "    # edge_index: [2, E]\n",
        "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
        "\n",
        "def train_vgae(data_train, data_val, data_test, epochs=200, lr=1e-3, weight_decay=1e-4,\n",
        "               patience=25, use_amp=True, dropout=0.0):\n",
        "    x = data_train.x.to(device)\n",
        "    ei = data_train.edge_index.to(device)\n",
        "\n",
        "    enc = VariationalGCNEncoder(data_train.num_node_features, HIDDEN, EMB_DIM, dropout=dropout).to(device)\n",
        "    model = VGAE(enc).to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    eidx_val, y_val = get_eval_edges_and_labels(data_val)\n",
        "    eidx_test, y_test = get_eval_edges_and_labels(data_test)\n",
        "    eidx_val, y_val = eidx_val.to(device), y_val.to(device)\n",
        "    eidx_test, y_test = eidx_test.to(device), y_test.to(device)\n",
        "\n",
        "    best_state = None\n",
        "    best_val_ap = -1.0\n",
        "    best_epoch = -1\n",
        "    bad = 0\n",
        "\n",
        "    def _eval(split_eidx, split_y):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            with _autocast_ctx(use_amp):\n",
        "                z = model.encode(x, ei)  # use TRAIN graph for embeddings\n",
        "                logits = _score_edges_inner(z, split_eidx)\n",
        "            p = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            y_np = split_y.detach().cpu().numpy()\n",
        "            roc, ap = eval_scores_to_metrics(y_np, p)\n",
        "        return roc, ap\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        with _autocast_ctx(use_amp):\n",
        "            z = model.encode(x, ei)\n",
        "            pos = _get_pos_edges(data_train).to(device)\n",
        "            loss = model.recon_loss(z, pos) + (1.0 / data_train.num_nodes) * model.kl_loss()\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if (ep % 10 == 0) or (ep == 1):\n",
        "            roc_v, ap_v = _eval(eidx_val, y_val)\n",
        "            print(f\"[VGAE] ep {ep:03d} | loss={loss.item():.4f} | val ROC={roc_v:.4f} | val AP={ap_v:.4f}\")\n",
        "\n",
        "            if ap_v > best_val_ap:\n",
        "                best_val_ap = ap_v\n",
        "                best_epoch = ep\n",
        "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "                bad = 0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= patience:\n",
        "                    print(f\"[VGAE] Early stop at ep={ep} (best ep={best_epoch}, best val AP={best_val_ap:.4f})\")\n",
        "                    break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    roc_t, ap_t = _eval(eidx_test, y_test)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with _autocast_ctx(use_amp):\n",
        "            z_train = model.encode(x, ei).detach().cpu().numpy()\n",
        "\n",
        "    return model, z_train, {\"test_roc_auc\": roc_t, \"test_ap\": ap_t, \"best_val_ap\": best_val_ap, \"best_epoch\": best_epoch}\n",
        "\n",
        "# -------------------------\n",
        "# Run multi-seed benchmark\n",
        "# -------------------------\n",
        "all_rows = []\n",
        "per_seed_models = {}      # (model_key, seed) -> trained model\n",
        "per_seed_embeddings = {}  # (model_key, seed) -> np.ndarray\n",
        "\n",
        "for spec in MODELS_TO_RUN:\n",
        "    key = spec[\"key\"]\n",
        "    name = spec[\"name\"]\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(f\"MODEL: {name}  (key={key})\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    for seed in SEEDS:\n",
        "        _cleanup()\n",
        "        set_seed(seed)\n",
        "\n",
        "        if key == \"vgae\":\n",
        "            print(f\"  seed={seed} -> training VGAE ...\")\n",
        "            m, z_tr, metrics = train_vgae(\n",
        "                data_train=data_train,\n",
        "                data_val=data_val,\n",
        "                data_test=data_test,\n",
        "                epochs=EPOCHS,\n",
        "                lr=LR,\n",
        "                weight_decay=WEIGHT_DECAY,\n",
        "                patience=PATIENCE,\n",
        "                use_amp=USE_AMP,\n",
        "                dropout=DROPOUT,\n",
        "            )\n",
        "            per_seed_models[(key, seed)] = m\n",
        "            per_seed_embeddings[(key, seed)] = z_tr\n",
        "        else:\n",
        "            encoder = spec[\"encoder\"]\n",
        "            decoder = spec[\"decoder\"]\n",
        "            print(f\"  seed={seed} -> training {name} ...\")\n",
        "\n",
        "            model_cur = build_lp_model(\n",
        "                encoder_name=encoder,\n",
        "                in_dim=data_train.num_node_features,\n",
        "                hidden=HIDDEN,\n",
        "                emb_dim=EMB_DIM,\n",
        "                dropout=DROPOUT,\n",
        "                appnp_K=APPNP_K,\n",
        "                appnp_alpha=APPNP_ALPHA,\n",
        "                gat_heads=GAT_HEADS,\n",
        "                decoder_name=decoder,\n",
        "                dec_hidden=HIDDEN,\n",
        "            )\n",
        "\n",
        "            model_cur, z_tr, metrics, _df_log = train_linkpred(\n",
        "                model_name=f\"{name} | seed={seed}\",\n",
        "                model=model_cur,\n",
        "                data_train=data_train,\n",
        "                data_val=data_val,\n",
        "                data_test=data_test,\n",
        "                epochs=EPOCHS,\n",
        "                lr=LR,\n",
        "                weight_decay=WEIGHT_DECAY,\n",
        "                neg_ratio=NEG_RATIO,\n",
        "                patience=PATIENCE,\n",
        "                grad_clip=1.0,\n",
        "                use_amp=USE_AMP,\n",
        "                edge_dropout=EDGE_DROPOUT,\n",
        "            )\n",
        "\n",
        "            per_seed_models[(key, seed)] = model_cur\n",
        "            per_seed_embeddings[(key, seed)] = z_tr\n",
        "\n",
        "        all_rows.append({\n",
        "            \"model\": name,\n",
        "            \"model_key\": key,\n",
        "            \"seed\": seed,\n",
        "            \"test_roc_auc\": float(metrics[\"test_roc_auc\"]),\n",
        "            \"test_ap\": float(metrics[\"test_ap\"]),\n",
        "            \"best_val_ap\": float(metrics[\"best_val_ap\"]),\n",
        "            \"best_epoch\": int(metrics[\"best_epoch\"]) if metrics[\"best_epoch\"] is not None else -1,\n",
        "            \"hidden\": HIDDEN,\n",
        "            \"emb_dim\": EMB_DIM,\n",
        "            \"dropout\": DROPOUT,\n",
        "            \"lr\": LR,\n",
        "            \"weight_decay\": WEIGHT_DECAY,\n",
        "            \"neg_ratio\": NEG_RATIO,\n",
        "            \"epochs\": EPOCHS,\n",
        "            \"patience\": PATIENCE,\n",
        "            \"edge_dropout\": EDGE_DROPOUT,\n",
        "        })\n",
        "\n",
        "df_trials = pd.DataFrame(all_rows)\n",
        "display(df_trials.head())\n",
        "\n",
        "# Aggregate: mean±std per model\n",
        "agg = df_trials.groupby([\"model\", \"model_key\"]).agg(\n",
        "    val_ap_mean=(\"best_val_ap\", \"mean\"),\n",
        "    val_ap_std=(\"best_val_ap\", \"std\"),\n",
        "    test_ap_mean=(\"test_ap\", \"mean\"),\n",
        "    test_ap_std=(\"test_ap\", \"std\"),\n",
        "    test_roc_mean=(\"test_roc_auc\", \"mean\"),\n",
        "    test_roc_std=(\"test_roc_auc\", \"std\"),\n",
        ").reset_index()\n",
        "\n",
        "# Model selection strictly by VAL mean (paper-correct)\n",
        "agg = agg.sort_values([\"val_ap_mean\", \"test_roc_mean\"], ascending=False).reset_index(drop=True)\n",
        "display(agg)\n",
        "\n",
        "agg.to_csv(\"gnn_linkpred_multiseed_summary.csv\", index=False)\n",
        "df_trials.to_csv(\"gnn_linkpred_multiseed_trials.csv\", index=False)\n",
        "print(\"Saved: gnn_linkpred_multiseed_summary.csv\")\n",
        "print(\"Saved: gnn_linkpred_multiseed_trials.csv\")\n",
        "\n",
        "BEST_MODEL_KEY = agg.iloc[0][\"model_key\"]\n",
        "BEST_MODEL_NAME = agg.iloc[0][\"model\"]\n",
        "print(\"\\n✅ Best model by VAL (mean AP):\", BEST_MODEL_NAME, f\"(key={BEST_MODEL_KEY})\")\n",
        "\n",
        "# Pick the seed with highest VAL AP for the best model (for embeddings downstream)\n",
        "best_seed_row = df_trials[df_trials[\"model_key\"] == BEST_MODEL_KEY].sort_values(\"best_val_ap\", ascending=False).iloc[0]\n",
        "BEST_SEED = int(best_seed_row[\"seed\"])\n",
        "print(\"✅ Best seed for downstream embeddings (highest VAL AP within best model):\", BEST_SEED)\n",
        "\n",
        "model_best = per_seed_models[(BEST_MODEL_KEY, BEST_SEED)]\n",
        "z_train_best = per_seed_embeddings[(BEST_MODEL_KEY, BEST_SEED)]\n",
        "\n",
        "# Backward-compatibility (later cells often use `model` and `z_train`)\n",
        "model = model_best\n",
        "z_train = z_train_best\n",
        "\n",
        "# Save embeddings for downstream clustering / plots (one file per model, using best seed for that model)\n",
        "for mk in agg[\"model_key\"].tolist():\n",
        "    dfm = df_trials[df_trials[\"model_key\"] == mk].sort_values(\"best_val_ap\", ascending=False)\n",
        "    seed_m = int(dfm.iloc[0][\"seed\"])\n",
        "    z = per_seed_embeddings[(mk, seed_m)]\n",
        "    out = f\"embeddings_train_{mk}.npy\"\n",
        "    np.save(out, z)\n",
        "    print(f\"Saved: {out} {z.shape} (seed={seed_m})\")\n",
        "\n",
        "print(\"✅ Ready for downstream pipeline (clustering, CORUM validation, disease enrichment, etc.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wXjuSW8TQ-p",
        "outputId": "95920a06-b25d-4901-cc51-53d77716234e"
      },
      "source": [
        "# =========================\n",
        "# 4B.1) PAPER PLAN: Clustering on embeddings for EVERY LP model (+ tuned GCN+EdgeMLP)\n",
        "# - Creates df_clusters columns like: lp_gcn_dot_kmeans, lp_gat_dot_kmeans, ...\n",
        "# - Optional: Louvain/Leiden on kNN graph built from embeddings\n",
        "# - Uses K_FINAL if defined; else chooses a reasonable default\n",
        "# =========================\n",
        "import os, re, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---- toggles ----\n",
        "RUN_EMB_KMEANS  = True\n",
        "RUN_EMB_LOUVAIN = True     # runs Louvain on kNN graph in embedding space (no igraph required)\n",
        "RUN_EMB_LEIDEN  = False    # requires igraph + leidenalg; optional\n",
        "\n",
        "KNN_K = 15                 # neighbors for kNN graph in embedding space\n",
        "KMEANS_N_INIT = 20\n",
        "EMB_WHITEN = True          # Standardize embeddings before KMeans / kNN\n",
        "DEFAULT_K = 50             # if K_FINAL not defined\n",
        "\n",
        "# ---- figure out K ----\n",
        "K_USE = int(globals().get(\"K_FINAL\", DEFAULT_K) or DEFAULT_K)\n",
        "print(\"K_USE:\", K_USE)\n",
        "\n",
        "# ---- get / create df_clusters ----\n",
        "if \"df_clusters\" not in globals() or df_clusters is None or not isinstance(df_clusters, pd.DataFrame):\n",
        "    df_clusters = pd.DataFrame({\"node\": np.arange(int(data_train.num_nodes))})\n",
        "    print(\"Created df_clusters with 'node' only. (gene/protein mapping will be handled by later bio2 cells.)\")\n",
        "\n",
        "# Ensure node index alignment\n",
        "if \"node\" not in df_clusters.columns:\n",
        "    df_clusters[\"node\"] = np.arange(int(data_train.num_nodes))\n",
        "df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "# ---- collect embeddings from files created by 4B ----\n",
        "emb_files = sorted(glob.glob(\"embeddings_train_*.npy\"))\n",
        "emb_map = {}\n",
        "for f in emb_files:\n",
        "    key = os.path.basename(f).replace(\"embeddings_train_\", \"\").replace(\".npy\",\"\")\n",
        "    try:\n",
        "        emb_map[key] = np.load(f)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ could not load\", f, \"->\", e)\n",
        "\n",
        "# also add tuned GCN+EdgeMLP if present\n",
        "if os.path.exists(\"embeddings_train_gcn_edgemlp_tuned.npy\"):\n",
        "    emb_map[\"gcn_edgemlp_tuned\"] = np.load(\"embeddings_train_gcn_edgemlp_tuned.npy\")\n",
        "\n",
        "print(\"Embeddings loaded:\", list(emb_map.keys()))\n",
        "\n",
        "# ---- optional: build Louvain / Leiden on kNN graph ----\n",
        "def _knn_graph_from_emb(Z, k=15, metric=\"cosine\"):\n",
        "    from sklearn.neighbors import NearestNeighbors\n",
        "    import networkx as nx\n",
        "\n",
        "    nbrs = NearestNeighbors(n_neighbors=int(k)+1, metric=metric, n_jobs=-1)\n",
        "    nbrs.fit(Z)\n",
        "    dists, idxs = nbrs.kneighbors(Z)\n",
        "    # drop self neighbor at position 0\n",
        "    idxs = idxs[:, 1:]\n",
        "    dists = dists[:, 1:]\n",
        "\n",
        "    G = nx.Graph()\n",
        "    n = Z.shape[0]\n",
        "    G.add_nodes_from(range(n))\n",
        "    for i in range(n):\n",
        "        for j, dist in zip(idxs[i], dists[i]):\n",
        "            if i == int(j):\n",
        "                continue\n",
        "            # convert distance to similarity weight (monotonic)\n",
        "            w = 1.0 / (1.0 + float(dist))\n",
        "            if G.has_edge(i, int(j)):\n",
        "                # keep max weight\n",
        "                if w > G[i][int(j)][\"weight\"]:\n",
        "                    G[i][int(j)][\"weight\"] = w\n",
        "            else:\n",
        "                G.add_edge(i, int(j), weight=w)\n",
        "    return G\n",
        "\n",
        "def _louvain_labels(G):\n",
        "    import networkx as nx\n",
        "    # Prefer nx built-in louvain if available; else fallback to greedy modularity\n",
        "    if hasattr(nx.algorithms.community, \"louvain_communities\"):\n",
        "        comms = nx.algorithms.community.louvain_communities(G, weight=\"weight\", seed=0)\n",
        "    else:\n",
        "        comms = nx.algorithms.community.greedy_modularity_communities(G, weight=\"weight\")\n",
        "    labels = np.full(G.number_of_nodes(), -1, dtype=int)\n",
        "    for cid, C in enumerate(comms):\n",
        "        for u in C:\n",
        "            labels[int(u)] = cid\n",
        "    return labels\n",
        "\n",
        "def _leiden_labels(G):\n",
        "    import igraph as ig\n",
        "    import leidenalg\n",
        "    # build igraph\n",
        "    edges = list(G.edges())\n",
        "    weights = [float(G[u][v].get(\"weight\", 1.0)) for (u,v) in edges]\n",
        "    igg = ig.Graph(n=G.number_of_nodes(), edges=edges, directed=False)\n",
        "    part = leidenalg.find_partition(igg, leidenalg.RBConfigurationVertexPartition, weights=weights)\n",
        "    labels = np.array(part.membership, dtype=int)\n",
        "    return labels\n",
        "\n",
        "# ---- run clustering per embedding ----\n",
        "for key, Z in emb_map.items():\n",
        "    print(\"\\n=== Clustering embeddings:\", key, \"Z shape:\", Z.shape, \"===\")\n",
        "    Z_use = Z.astype(np.float32, copy=False)\n",
        "\n",
        "    if EMB_WHITEN:\n",
        "        Z_use = StandardScaler(with_mean=True, with_std=True).fit_transform(Z_use)\n",
        "\n",
        "    # 1) KMeans\n",
        "    if RUN_EMB_KMEANS:\n",
        "        km = KMeans(n_clusters=int(K_USE), n_init=int(KMEANS_N_INIT), random_state=0)\n",
        "        lab = km.fit_predict(Z_use)\n",
        "        col = f\"lp_{key}_kmeans\"\n",
        "        df_clusters[col] = lab\n",
        "        print(\"  saved:\", col, \"unique:\", len(np.unique(lab)))\n",
        "\n",
        "    # 2) Louvain on kNN graph\n",
        "    if RUN_EMB_LOUVAIN:\n",
        "        try:\n",
        "            Gk = _knn_graph_from_emb(Z_use, k=KNN_K, metric=\"cosine\")\n",
        "            lab = _louvain_labels(Gk)\n",
        "            col = f\"lp_{key}_knn_louvain\"\n",
        "            df_clusters[col] = lab\n",
        "            print(\"  saved:\", col, \"unique:\", len(np.unique(lab)))\n",
        "        except Exception as e:\n",
        "            print(\"  ⚠️ Louvain failed for\", key, \"->\", e)\n",
        "\n",
        "    # 3) Leiden on kNN graph (optional)\n",
        "    if RUN_EMB_LEIDEN:\n",
        "        try:\n",
        "            Gk = _knn_graph_from_emb(Z_use, k=KNN_K, metric=\"cosine\")\n",
        "            lab = _leiden_labels(Gk)\n",
        "            col = f\"lp_{key}_knn_leiden\"\n",
        "            df_clusters[col] = lab\n",
        "            print(\"  saved:\", col, \"unique:\", len(np.unique(lab)))\n",
        "        except Exception as e:\n",
        "            print(\"  ⚠️ Leiden failed for\", key, \"->\", e)\n",
        "\n",
        "print(\"\\n✅ df_clusters updated with LP-embedding clustering columns.\")\n",
        "print(\"Tip: Now re-run CORUM / disease / GO cells; they will include new columns if configured to auto-detect.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K_USE: 50\n",
            "Created df_clusters with 'node' only. (gene/protein mapping will be handled by later bio2 cells.)\n",
            "Embeddings loaded: ['appnp_dot', 'gat_dot', 'gcn_dot', 'gcn_edgemlp', 'graphsage_dot', 'vgae']\n",
            "\n",
            "=== Clustering embeddings: appnp_dot Z shape: (16584, 64) ===\n",
            "  saved: lp_appnp_dot_kmeans unique: 50\n",
            "  saved: lp_appnp_dot_knn_louvain unique: 24\n",
            "\n",
            "=== Clustering embeddings: gat_dot Z shape: (16584, 64) ===\n",
            "  saved: lp_gat_dot_kmeans unique: 50\n",
            "  saved: lp_gat_dot_knn_louvain unique: 27\n",
            "\n",
            "=== Clustering embeddings: gcn_dot Z shape: (16584, 64) ===\n",
            "  saved: lp_gcn_dot_kmeans unique: 50\n",
            "  saved: lp_gcn_dot_knn_louvain unique: 25\n",
            "\n",
            "=== Clustering embeddings: gcn_edgemlp Z shape: (16584, 64) ===\n",
            "  saved: lp_gcn_edgemlp_kmeans unique: 50\n",
            "  saved: lp_gcn_edgemlp_knn_louvain unique: 27\n",
            "\n",
            "=== Clustering embeddings: graphsage_dot Z shape: (16584, 64) ===\n",
            "  saved: lp_graphsage_dot_kmeans unique: 50\n",
            "  saved: lp_graphsage_dot_knn_louvain unique: 25\n",
            "\n",
            "=== Clustering embeddings: vgae Z shape: (16584, 64) ===\n",
            "  saved: lp_vgae_kmeans unique: 50\n",
            "  saved: lp_vgae_knn_louvain unique: 22\n",
            "\n",
            "✅ df_clusters updated with LP-embedding clustering columns.\n",
            "Tip: Now re-run CORUM / disease / GO cells; they will include new columns if configured to auto-detect.\n"
          ]
        }
      ],
      "execution_count": 20,
      "id": "4wXjuSW8TQ-p"
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4C) FINAL: Keep only the best GCN+EdgeMLP (best config + best seed)\n",
        "# - Optional: quick random-search on VAL AP to pick best_cfg (NO test selection)\n",
        "# - Confirm best_cfg with multi-seed runs\n",
        "# - Keeps ONLY:\n",
        "#     model  : best-seed trained model (highest VAL AP)\n",
        "#     z_train: embeddings from that model (train graph)\n",
        "# - Exports:\n",
        "#     gcn_edgemlp_tuning_trials.csv (if DO_TUNE)\n",
        "#     gcn_edgemlp_confirm_multiseed.csv\n",
        "#     embeddings_train_gcn_edgemlp_tuned.npy\n",
        "# =========================\n",
        "\n",
        "import gc, itertools, numpy as np, pandas as pd, torch\n",
        "\n",
        "assert all(k in globals() for k in [\"data_train\",\"data_val\",\"data_test\",\"build_lp_model\",\"train_linkpred\",\"set_seed\"]), \\\n",
        "    \"Missing required globals. Run the utilities + split cells first.\"\n",
        "\n",
        "def _cleanup():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# -------------------------\n",
        "# Controls\n",
        "# -------------------------\n",
        "DO_TUNE = False  # <- set True if you want to re-run random search\n",
        "\n",
        "# If DO_TUNE=False, paste your best cfg here (from your screenshot):\n",
        "BEST_CFG_MANUAL = {\n",
        "    \"hidden\": 256,\n",
        "    \"dropout\": 0.2,\n",
        "    \"dec_hidden\": 128,\n",
        "    \"lr\": 0.002,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"neg_ratio\": 5.0,\n",
        "    \"edge_dropout\": 0.1,\n",
        "}\n",
        "\n",
        "# Tuning budget (only used if DO_TUNE=True)\n",
        "TUNE_SEED = 0\n",
        "N_TRIALS = 30\n",
        "TUNE_EPOCHS = 120\n",
        "TUNE_PATIENCE = 12\n",
        "\n",
        "# Confirm budget (paper-ready)\n",
        "CONFIRM_SEEDS = [0, 1, 2, 3, 4]\n",
        "CONFIRM_EPOCHS = 200\n",
        "CONFIRM_PATIENCE = 25\n",
        "\n",
        "# Fixed protocol (align with your benchmark cell)\n",
        "USE_AMP = True\n",
        "EMB_DIM = 64\n",
        "APPNP_K = 10\n",
        "APPNP_ALPHA = 0.1\n",
        "GAT_HEADS = 4  # not used, but build_lp_model signature expects it\n",
        "\n",
        "# Search space (only used if DO_TUNE=True)\n",
        "search_space = {\n",
        "    \"hidden\":       [128, 256],\n",
        "    \"dropout\":      [0.0, 0.2, 0.5],\n",
        "    \"dec_hidden\":   [64, 128, 256],\n",
        "    \"lr\":           [5e-4, 1e-3, 2e-3],\n",
        "    \"weight_decay\": [0.0, 1e-4, 5e-4],\n",
        "    \"neg_ratio\":    [1.0, 2.0, 5.0],\n",
        "    \"edge_dropout\": [0.0, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# (A) Optional tuning: pick best_cfg by VAL AP\n",
        "# -------------------------\n",
        "if DO_TUNE:\n",
        "    keys = list(search_space.keys())\n",
        "    all_cfgs = list(itertools.product(*[search_space[k] for k in keys]))\n",
        "    rng = np.random.default_rng(0)\n",
        "    if N_TRIALS >= len(all_cfgs):\n",
        "        sampled = all_cfgs\n",
        "    else:\n",
        "        idx = rng.choice(len(all_cfgs), size=N_TRIALS, replace=False)\n",
        "        sampled = [all_cfgs[i] for i in idx]\n",
        "\n",
        "    rows = []\n",
        "    best_cfg = None\n",
        "    best_val_ap = -1.0\n",
        "\n",
        "    print(f\"[TUNE] GCN+EdgeMLP random search: trials={len(sampled)} seed={TUNE_SEED}\")\n",
        "\n",
        "    for t, vals in enumerate(sampled, 1):\n",
        "        _cleanup()\n",
        "        set_seed(TUNE_SEED)\n",
        "        cfg = dict(zip(keys, vals))\n",
        "\n",
        "        model_cur = build_lp_model(\n",
        "            encoder_name=\"gcn\",\n",
        "            in_dim=data_train.num_node_features,\n",
        "            hidden=int(cfg[\"hidden\"]),\n",
        "            emb_dim=int(EMB_DIM),\n",
        "            dropout=float(cfg[\"dropout\"]),\n",
        "            appnp_K=APPNP_K,\n",
        "            appnp_alpha=APPNP_ALPHA,\n",
        "            gat_heads=GAT_HEADS,\n",
        "            decoder_name=\"edge_mlp\",\n",
        "            dec_hidden=int(cfg[\"dec_hidden\"]),\n",
        "        )\n",
        "\n",
        "        model_cur, _z_tr, metrics, _ = train_linkpred(\n",
        "            model_name=f\"GCN+EdgeMLP TUNE | trial={t}\",\n",
        "            model=model_cur,\n",
        "            data_train=data_train,\n",
        "            data_val=data_val,\n",
        "            data_test=data_test,  # not used for selection\n",
        "            epochs=int(TUNE_EPOCHS),\n",
        "            lr=float(cfg[\"lr\"]),\n",
        "            weight_decay=float(cfg[\"weight_decay\"]),\n",
        "            neg_ratio=float(cfg[\"neg_ratio\"]),\n",
        "            patience=int(TUNE_PATIENCE),\n",
        "            grad_clip=1.0,\n",
        "            use_amp=USE_AMP,\n",
        "            edge_dropout=float(cfg[\"edge_dropout\"]),\n",
        "        )\n",
        "\n",
        "        row = {\n",
        "            \"trial\": t,\n",
        "            **cfg,\n",
        "            \"val_ap\": float(metrics[\"best_val_ap\"]),\n",
        "            \"best_epoch\": int(metrics[\"best_epoch\"]),\n",
        "            \"test_ap\": float(metrics[\"test_ap\"]),\n",
        "            \"test_roc_auc\": float(metrics[\"test_roc_auc\"]),\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "        if row[\"val_ap\"] > best_val_ap + 1e-6:\n",
        "            best_val_ap = row[\"val_ap\"]\n",
        "            best_cfg = cfg\n",
        "            print(f\"  ✅ new best @trial {t}: val_ap={best_val_ap:.4f} cfg={best_cfg}\")\n",
        "\n",
        "        # free asap\n",
        "        del model_cur, _z_tr\n",
        "        _cleanup()\n",
        "\n",
        "    df_tune = pd.DataFrame(rows).sort_values([\"val_ap\"], ascending=False).reset_index(drop=True)\n",
        "    display(df_tune.head(15))\n",
        "    df_tune.to_csv(\"gcn_edgemlp_tuning_trials.csv\", index=False)\n",
        "    print(\"Saved: gcn_edgemlp_tuning_trials.csv\")\n",
        "else:\n",
        "    best_cfg = BEST_CFG_MANUAL\n",
        "    print(\"[TUNE] Skipped. Using BEST_CFG_MANUAL:\", best_cfg)\n",
        "\n",
        "# -------------------------\n",
        "# (B) Confirm best_cfg (multi-seed) and keep ONLY best seed by VAL AP\n",
        "# -------------------------\n",
        "confirm_rows = []\n",
        "best_seed = None\n",
        "best_seed_val_ap = -1.0\n",
        "best_seed_model = None\n",
        "best_seed_z = None\n",
        "\n",
        "print(\"\\n[CONFIRM] best_cfg with multi-seed:\", CONFIRM_SEEDS)\n",
        "\n",
        "for sd in CONFIRM_SEEDS:\n",
        "    _cleanup()\n",
        "    set_seed(int(sd))\n",
        "\n",
        "    model_cur = build_lp_model(\n",
        "        encoder_name=\"gcn\",\n",
        "        in_dim=data_train.num_node_features,\n",
        "        hidden=int(best_cfg[\"hidden\"]),\n",
        "        emb_dim=int(EMB_DIM),\n",
        "        dropout=float(best_cfg[\"dropout\"]),\n",
        "        appnp_K=APPNP_K,\n",
        "        appnp_alpha=APPNP_ALPHA,\n",
        "        gat_heads=GAT_HEADS,\n",
        "        decoder_name=\"edge_mlp\",\n",
        "        dec_hidden=int(best_cfg[\"dec_hidden\"]),\n",
        "    )\n",
        "\n",
        "    model_cur, z_tr, metrics, _ = train_linkpred(\n",
        "        model_name=f\"GCN+EdgeMLP BESTCFG | seed={sd}\",\n",
        "        model=model_cur,\n",
        "        data_train=data_train,\n",
        "        data_val=data_val,\n",
        "        data_test=data_test,\n",
        "        epochs=int(CONFIRM_EPOCHS),\n",
        "        lr=float(best_cfg[\"lr\"]),\n",
        "        weight_decay=float(best_cfg[\"weight_decay\"]),\n",
        "        neg_ratio=float(best_cfg[\"neg_ratio\"]),\n",
        "        patience=int(CONFIRM_PATIENCE),\n",
        "        grad_clip=1.0,\n",
        "        use_amp=USE_AMP,\n",
        "        edge_dropout=float(best_cfg[\"edge_dropout\"]),\n",
        "    )\n",
        "\n",
        "    row = {\n",
        "        \"seed\": int(sd),\n",
        "        **best_cfg,\n",
        "        \"val_ap\": float(metrics[\"best_val_ap\"]),\n",
        "        \"best_epoch\": int(metrics[\"best_epoch\"]),\n",
        "        \"test_ap\": float(metrics[\"test_ap\"]),\n",
        "        \"test_roc_auc\": float(metrics[\"test_roc_auc\"]),\n",
        "    }\n",
        "    confirm_rows.append(row)\n",
        "\n",
        "    # keep only best seed by VAL AP\n",
        "    if row[\"val_ap\"] > best_seed_val_ap + 1e-6:\n",
        "        # drop previous best to free memory\n",
        "        best_seed_model = model_cur\n",
        "        best_seed_z = z_tr\n",
        "        best_seed = int(sd)\n",
        "        best_seed_val_ap = row[\"val_ap\"]\n",
        "        print(f\"  ✅ new best seed={best_seed} | val_ap={best_seed_val_ap:.4f}\")\n",
        "    else:\n",
        "        # free non-best run immediately\n",
        "        del model_cur, z_tr\n",
        "        _cleanup()\n",
        "\n",
        "df_confirm = pd.DataFrame(confirm_rows).sort_values(\"val_ap\", ascending=False).reset_index(drop=True)\n",
        "display(df_confirm)\n",
        "\n",
        "summary = {\n",
        "    \"val_ap_mean\": float(df_confirm[\"val_ap\"].mean()),\n",
        "    \"val_ap_std\": float(df_confirm[\"val_ap\"].std(ddof=1)) if len(df_confirm) > 1 else 0.0,\n",
        "    \"test_ap_mean\": float(df_confirm[\"test_ap\"].mean()),\n",
        "    \"test_ap_std\": float(df_confirm[\"test_ap\"].std(ddof=1)) if len(df_confirm) > 1 else 0.0,\n",
        "    \"test_roc_mean\": float(df_confirm[\"test_roc_auc\"].mean()),\n",
        "    \"test_roc_std\": float(df_confirm[\"test_roc_auc\"].std(ddof=1)) if len(df_confirm) > 1 else 0.0,\n",
        "}\n",
        "print(\"\\nCONFIRM SUMMARY (mean±std):\", summary)\n",
        "\n",
        "df_confirm.to_csv(\"gcn_edgemlp_confirm_multiseed.csv\", index=False)\n",
        "print(\"Saved: gcn_edgemlp_confirm_multiseed.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# (C) Final outputs for downstream pipeline\n",
        "# -------------------------\n",
        "model = best_seed_model\n",
        "z_train = best_seed_z\n",
        "np.save(\"embeddings_train_gcn_edgemlp_tuned.npy\", z_train)\n",
        "\n",
        "print(f\"\\n✅ FINAL kept: seed={best_seed} (highest VAL AP).\")\n",
        "print(\"Saved: embeddings_train_gcn_edgemlp_tuned.npy\", z_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mvaFKsPejIZ",
        "outputId": "4543c0f5-d4d0-4cf7-d409-e2f46141e464"
      },
      "id": "2mvaFKsPejIZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TUNE] Skipped. Using BEST_CFG_MANUAL: {'hidden': 256, 'dropout': 0.2, 'dec_hidden': 128, 'lr': 0.002, 'weight_decay': 0.0, 'neg_ratio': 5.0, 'edge_dropout': 0.1}\n",
            "\n",
            "[CONFIRM] best_cfg with multi-seed: [0, 1, 2, 3, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 001 | loss=1.1557 | val ROC=0.8731 | val AP=0.8827 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 010 | loss=0.7171 | val ROC=0.8706 | val AP=0.8862 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 020 | loss=0.6775 | val ROC=0.8843 | val AP=0.8986 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 030 | loss=0.6447 | val ROC=0.8972 | val AP=0.9098 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 040 | loss=0.5707 | val ROC=0.9161 | val AP=0.9273 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 050 | loss=0.5256 | val ROC=0.9236 | val AP=0.9333 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 060 | loss=0.4930 | val ROC=0.9292 | val AP=0.9385 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 070 | loss=0.4704 | val ROC=0.9332 | val AP=0.9415 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 080 | loss=0.4492 | val ROC=0.9364 | val AP=0.9443 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 090 | loss=0.4333 | val ROC=0.9391 | val AP=0.9468 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 100 | loss=0.4179 | val ROC=0.9415 | val AP=0.9491 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 110 | loss=0.4059 | val ROC=0.9430 | val AP=0.9506 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 120 | loss=0.3988 | val ROC=0.9441 | val AP=0.9517 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 130 | loss=0.3918 | val ROC=0.9449 | val AP=0.9525 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 140 | loss=0.3856 | val ROC=0.9456 | val AP=0.9532 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 150 | loss=0.3814 | val ROC=0.9462 | val AP=0.9539 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 160 | loss=0.3758 | val ROC=0.9467 | val AP=0.9544 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 170 | loss=0.3725 | val ROC=0.9472 | val AP=0.9548 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 180 | loss=0.3697 | val ROC=0.9477 | val AP=0.9553 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 190 | loss=0.3642 | val ROC=0.9480 | val AP=0.9556 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0] ep 200 | loss=0.3614 | val ROC=0.9484 | val AP=0.9559 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=0 TEST] ROC-AUC=0.9475 PR-AUC=0.9547\n",
            "  ✅ new best seed=0 | val_ap=0.9559\n",
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 001 | loss=1.1511 | val ROC=0.8532 | val AP=0.8646 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 010 | loss=0.7146 | val ROC=0.8730 | val AP=0.8880 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 020 | loss=0.6690 | val ROC=0.8876 | val AP=0.9023 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 030 | loss=0.6153 | val ROC=0.9045 | val AP=0.9170 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 040 | loss=0.5483 | val ROC=0.9185 | val AP=0.9299 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 050 | loss=0.5115 | val ROC=0.9259 | val AP=0.9360 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 060 | loss=0.4816 | val ROC=0.9313 | val AP=0.9401 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 070 | loss=0.4612 | val ROC=0.9344 | val AP=0.9426 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 080 | loss=0.4455 | val ROC=0.9371 | val AP=0.9450 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 090 | loss=0.4291 | val ROC=0.9396 | val AP=0.9473 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 100 | loss=0.4159 | val ROC=0.9414 | val AP=0.9492 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 110 | loss=0.4057 | val ROC=0.9430 | val AP=0.9507 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 120 | loss=0.3976 | val ROC=0.9440 | val AP=0.9518 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 130 | loss=0.3921 | val ROC=0.9449 | val AP=0.9528 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 140 | loss=0.3861 | val ROC=0.9456 | val AP=0.9534 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 150 | loss=0.3812 | val ROC=0.9462 | val AP=0.9540 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 160 | loss=0.3760 | val ROC=0.9466 | val AP=0.9543 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 170 | loss=0.3715 | val ROC=0.9470 | val AP=0.9548 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 180 | loss=0.3694 | val ROC=0.9474 | val AP=0.9551 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 190 | loss=0.3654 | val ROC=0.9478 | val AP=0.9555 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1] ep 200 | loss=0.3612 | val ROC=0.9478 | val AP=0.9556 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=1 TEST] ROC-AUC=0.9470 PR-AUC=0.9544\n",
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 001 | loss=1.1511 | val ROC=0.8370 | val AP=0.8484 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 010 | loss=0.7206 | val ROC=0.8708 | val AP=0.8865 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 020 | loss=0.6713 | val ROC=0.8871 | val AP=0.9012 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 030 | loss=0.6230 | val ROC=0.9028 | val AP=0.9149 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 040 | loss=0.5505 | val ROC=0.9194 | val AP=0.9301 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 050 | loss=0.5113 | val ROC=0.9264 | val AP=0.9364 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 060 | loss=0.4820 | val ROC=0.9316 | val AP=0.9404 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 070 | loss=0.4578 | val ROC=0.9351 | val AP=0.9432 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 080 | loss=0.4412 | val ROC=0.9379 | val AP=0.9457 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 090 | loss=0.4256 | val ROC=0.9402 | val AP=0.9480 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 100 | loss=0.4111 | val ROC=0.9421 | val AP=0.9499 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 110 | loss=0.4030 | val ROC=0.9436 | val AP=0.9514 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 120 | loss=0.3951 | val ROC=0.9444 | val AP=0.9522 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 130 | loss=0.3902 | val ROC=0.9454 | val AP=0.9532 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 140 | loss=0.3846 | val ROC=0.9457 | val AP=0.9536 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 150 | loss=0.3802 | val ROC=0.9463 | val AP=0.9542 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 160 | loss=0.3758 | val ROC=0.9467 | val AP=0.9545 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 170 | loss=0.3709 | val ROC=0.9473 | val AP=0.9551 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 180 | loss=0.3681 | val ROC=0.9477 | val AP=0.9555 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 190 | loss=0.3636 | val ROC=0.9480 | val AP=0.9558 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2] ep 200 | loss=0.3615 | val ROC=0.9481 | val AP=0.9560 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n",
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=2 TEST] ROC-AUC=0.9473 PR-AUC=0.9547\n",
            "  ✅ new best seed=2 | val_ap=0.9560\n",
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 001 | loss=1.1500 | val ROC=0.8593 | val AP=0.8674 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 010 | loss=0.7305 | val ROC=0.8695 | val AP=0.8845 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 020 | loss=0.6846 | val ROC=0.8832 | val AP=0.8977 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 030 | loss=0.6486 | val ROC=0.8949 | val AP=0.9078 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 040 | loss=0.5794 | val ROC=0.9134 | val AP=0.9245 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 050 | loss=0.5255 | val ROC=0.9229 | val AP=0.9332 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 060 | loss=0.4889 | val ROC=0.9306 | val AP=0.9391 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 070 | loss=0.4636 | val ROC=0.9340 | val AP=0.9422 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 080 | loss=0.4451 | val ROC=0.9366 | val AP=0.9448 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 090 | loss=0.4282 | val ROC=0.9397 | val AP=0.9475 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 100 | loss=0.4140 | val ROC=0.9419 | val AP=0.9497 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GCN+EdgeMLP BESTCFG | seed=3] ep 110 | loss=0.4041 | val ROC=0.9434 | val AP=0.9513 | lr=2.00e-03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2175096599.py:246: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast(enabled=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xA2VjDnMbWGH",
      "metadata": {
        "id": "xA2VjDnMbWGH"
      },
      "source": [
        "## 8) PAPER PLOTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GKdIlIbgbWGH",
      "metadata": {
        "id": "GKdIlIbgbWGH"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8) PAPER PLOTS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fmK_4MCKbWGI",
      "metadata": {
        "id": "fmK_4MCKbWGI"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5fff9a",
      "metadata": {
        "id": "de5fff9a"
      },
      "source": [
        "### 8D) Top-K evaluation (Precision@K / Recall@K) on TEST  \n",
        "Useful for 'top predicted links' reporting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04e196c",
      "metadata": {
        "id": "b04e196c"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8D) TOP-K evaluation on TEST (Precision@K / Recall@K)  [paper add-on]\n",
        "# Works on the *existing* test set (pos+neg) from RandomLinkSplit.\n",
        "# This is NOT \"top edges over all pairs\" (which is huge), but it's still a standard ranking eval.\n",
        "# Saves: topk_metrics_test.csv\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def topk_metrics(y_true, scores, K_list=(100, 500, 1000, 5000, 10000)):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    scores = np.asarray(scores).astype(float)\n",
        "    order = np.argsort(-scores)\n",
        "    y_sorted = y_true[order]\n",
        "    total_pos = int(y_true.sum())\n",
        "\n",
        "    rows = []\n",
        "    for K in K_list:\n",
        "        K = int(min(K, len(y_true)))\n",
        "        tp = int(y_sorted[:K].sum())\n",
        "        prec = tp / max(1, K)\n",
        "        rec = tp / max(1, total_pos)\n",
        "        rows.append({\"K\": K, \"precision_at_K\": prec, \"recall_at_K\": rec, \"tp_at_K\": tp, \"total_pos\": total_pos})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# pick reference y_true\n",
        "if \"y_ref\" in globals():\n",
        "    yT = np.array(y_ref).astype(int)\n",
        "elif \"y_test\" in globals():\n",
        "    yT = np.array(y_test).astype(int)\n",
        "elif \"y_gcn\" in globals():\n",
        "    yT = np.array(y_gcn).astype(int)\n",
        "else:\n",
        "    raise RuntimeError(\"Could not find test labels (y_ref / y_test / y_gcn). Run link prediction evaluation cells first.\")\n",
        "\n",
        "# collect available score vectors\n",
        "score_dict = {}\n",
        "for name, var in [\n",
        "    (\"APPNP\", \"p_appnp\"),\n",
        "    (\"GCN\", \"p_gcn\"),\n",
        "    (\"GraphSAGE\", \"p_sage\"),\n",
        "    (\"CN\", \"s_cn_n\"),\n",
        "    (\"AdamicAdar\", \"s_aa_n\"),\n",
        "    (\"Jaccard\", \"s_jac_n\"),\n",
        "    (\"PrefAttach\", \"s_pa_n\"),\n",
        "    (\"Node2Vec\", \"s_n2v_n\"),\n",
        "]:\n",
        "    if var in globals():\n",
        "        score_dict[name] = np.array(globals()[var]).astype(float).reshape(-1)\n",
        "\n",
        "K_LIST = (100, 500, 1000, 5000, 10000)\n",
        "\n",
        "all_rows = []\n",
        "for name, s in score_dict.items():\n",
        "    dfk = topk_metrics(yT, s, K_list=K_LIST)\n",
        "    dfk.insert(0, \"model\", name)\n",
        "    all_rows.append(dfk)\n",
        "\n",
        "df_topk = pd.concat(all_rows, ignore_index=True) if all_rows else pd.DataFrame()\n",
        "display(df_topk.head(20))\n",
        "\n",
        "df_topk.to_csv(\"topk_metrics_test.csv\", index=False)\n",
        "print(\"Saved: topk_metrics_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80RE6dBTbWGI",
      "metadata": {
        "id": "80RE6dBTbWGI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "def plot_pr_roc(y_true, score_dict, title_prefix=\"\", out_prefix=\"\"):\n",
        "    plt.figure()\n",
        "    for name, s in score_dict.items():\n",
        "        prec, rec, _ = precision_recall_curve(y_true, s)\n",
        "        plt.plot(rec, prec, label=name)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"{title_prefix} Precision-Recall\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{out_prefix}pr_curve.png\" if out_prefix else \"pr_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    for name, s in score_dict.items():\n",
        "        fpr, tpr, _ = roc_curve(y_true, s)\n",
        "        plt.plot(fpr, tpr, label=name)\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "    plt.title(f\"{title_prefix} ROC\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{out_prefix}roc_curve.png\" if out_prefix else \"roc_curve.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Pick the GNN you want\n",
        "# -----------------------\n",
        "# If you ran the improved compare cell, you should have:\n",
        "# BEST_MODEL_NAME in {\"appnp\",\"gcn\",\"graphsage\"} and test_preds dict.\n",
        "assert \"test_preds\" in globals(), \"Missing test_preds. Run the 'Train + compare GNNs' cell first.\"\n",
        "\n",
        "best = BEST_MODEL_NAME.lower() if \"BEST_MODEL_NAME\" in globals() else \"graphsage\"\n",
        "assert best in test_preds, f\"Best model '{best}' not found in test_preds keys: {list(test_preds.keys())}\"\n",
        "\n",
        "y_best, p_best = test_preds[best]\n",
        "\n",
        "# -----------------------\n",
        "# Baselines vs BEST GNN\n",
        "# -----------------------\n",
        "score_dict = {\n",
        "    \"CN\": s_cn_n,\n",
        "    \"Adamic-Adar\": s_aa_n,\n",
        "    \"Jaccard\": s_jac_n,\n",
        "    \"PrefAttach\": s_pa_n,\n",
        "    f\"{best.upper()} (GNN)\": p_best,\n",
        "}\n",
        "\n",
        "plot_pr_roc(y_best, score_dict, title_prefix=\"TEST:\", out_prefix=f\"{best}_\")\n",
        "\n",
        "rows = [\n",
        "    (\"CN\", roc_cn, ap_cn),\n",
        "    (\"Adamic-Adar\", roc_aa, ap_aa),\n",
        "    (\"Jaccard\", roc_jac, ap_jac),\n",
        "    (\"PrefAttach\", roc_pa, ap_pa),\n",
        "    (f\"{best.upper()} (GNN)\", roc_auc_score(y_best, p_best), average_precision_score(y_best, p_best)),\n",
        "]\n",
        "df_lp = pd.DataFrame(rows, columns=[\"method\", \"ROC_AUC\", \"PR_AUC\"])\n",
        "display(df_lp)\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(df_lp[\"method\"], df_lp[\"PR_AUC\"])\n",
        "plt.xticks(rotation=20, ha=\"right\")\n",
        "plt.ylabel(\"PR-AUC (TEST)\")\n",
        "plt.title(\"Link Prediction: PR-AUC vs baselines\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"pr_auc_barplot_{best}.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "df_lp.to_csv(f\"linkpred_baselines_vs_{best}.csv\", index=False)\n",
        "print(f\"Saved: linkpred_baselines_vs_{best}.csv\")\n",
        "\n",
        "# -----------------------\n",
        "# Training curves (BEST)\n",
        "# -----------------------\n",
        "# In the improved notebook, `train_log` is set to the best model log.\n",
        "assert \"train_log\" in globals(), \"Missing train_log. It should be set in the compare cell.\"\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_log[\"epoch\"], train_log[\"loss\"])\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Train loss\")\n",
        "plt.title(f\"Training loss (best={best.upper()})\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"train_loss_curve_{best}.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_log[\"epoch\"], train_log[\"val_ap\"])\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Val AP\")\n",
        "plt.title(f\"Validation AP (best={best.upper()})\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"val_ap_curve_{best}.png\", dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-FfywPD24hO",
      "metadata": {
        "id": "m-FfywPD24hO"
      },
      "source": [
        "## 8B) PR/ROC comparison of GNNs on TEST (APPNP vs GCN vs GraphSAGE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wx8hiGrF24hO",
      "metadata": {
        "id": "Wx8hiGrF24hO"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8B) PR/ROC comparison of GNNs on TEST (APPNP vs GCN vs GraphSAGE)\n",
        "#     Saves separate figures to avoid overwriting your baseline plots.\n",
        "# =========================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "\n",
        "assert \"p_gcn\" in globals() and \"p_sage\" in globals(), \"Run Section 7B first.\"\n",
        "assert \"y_gcn\" in globals() and \"y_sage\" in globals()\n",
        "\n",
        "# Use the test labels from any model (they should match)\n",
        "y_ref = np.array(y_gcn).astype(int)\n",
        "\n",
        "score_dict = {}\n",
        "if \"p_appnp\" in globals():\n",
        "    score_dict[\"APPNP\"] = np.array(p_appnp)\n",
        "score_dict[\"GCN\"] = np.array(p_gcn)\n",
        "score_dict[\"GraphSAGE\"] = np.array(p_sage)\n",
        "\n",
        "# PR curve\n",
        "plt.figure()\n",
        "for name, s in score_dict.items():\n",
        "    prec, rec, _ = precision_recall_curve(y_ref, s)\n",
        "    plt.plot(rec, prec, label=name)\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"TEST Precision–Recall (GNN comparison)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"pr_curve_gnn_comparison.png\", dpi=300)\n",
        "plt.show()\n",
        "print(\"Saved: pr_curve_gnn_comparison.png\")\n",
        "\n",
        "# ROC curve\n",
        "plt.figure()\n",
        "for name, s in score_dict.items():\n",
        "    fpr, tpr, _ = roc_curve(y_ref, s)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc(fpr,tpr):.3f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"TEST ROC (GNN comparison)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"roc_curve_gnn_comparison.png\", dpi=300)\n",
        "plt.show()\n",
        "print(\"Saved: roc_curve_gnn_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dVuAeoV5Y1QD",
      "metadata": {
        "id": "dVuAeoV5Y1QD"
      },
      "source": [
        "## 8C) Probability calibration (reliability) on TEST (best GNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fxQ9HJEbY1QD",
      "metadata": {
        "id": "fxQ9HJEbY1QD"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8C) Probability calibration (reliability) on TEST (best GNN)\n",
        "# - Uses y_true / p_pred from the selected best model in Section 4B\n",
        "# - Saves: calibration_reliability.png, calibration_bins.csv\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import brier_score_loss, roc_auc_score, average_precision_score\n",
        "\n",
        "assert \"test_preds\" in globals() and \"BEST_MODEL_NAME\" in globals(), \"Run Section 4B first (train + compare GNNs).\"\n",
        "\n",
        "y_true, p_pred = test_preds[BEST_MODEL_NAME]\n",
        "y_true = np.asarray(y_true).astype(int)\n",
        "p_pred = np.asarray(p_pred).astype(float)\n",
        "\n",
        "# basic sanity\n",
        "print(\"Best model:\", BEST_MODEL_NAME)\n",
        "print(\"TEST ROC:\", roc_auc_score(y_true, p_pred))\n",
        "print(\"TEST AP :\", average_precision_score(y_true, p_pred))\n",
        "print(\"Brier   :\", brier_score_loss(y_true, p_pred))\n",
        "\n",
        "# Expected Calibration Error (ECE)\n",
        "def expected_calibration_error(y, p, n_bins=15):\n",
        "    y = np.asarray(y).astype(int)\n",
        "    p = np.asarray(p).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    N = len(y)\n",
        "    rows = []\n",
        "    for i in range(n_bins):\n",
        "        lo, hi = bins[i], bins[i+1]\n",
        "        m = (p >= lo) & (p < hi) if i < n_bins - 1 else (p >= lo) & (p <= hi)\n",
        "        if m.sum() == 0:\n",
        "            continue\n",
        "        acc = float(y[m].mean())\n",
        "        conf = float(p[m].mean())\n",
        "        w = float(m.sum()) / max(1, N)\n",
        "        ece += w * abs(acc - conf)\n",
        "        rows.append({\"bin_lo\": lo, \"bin_hi\": hi, \"n\": int(m.sum()), \"acc\": acc, \"conf\": conf, \"abs_gap\": abs(acc-conf)})\n",
        "    return float(ece), pd.DataFrame(rows)\n",
        "\n",
        "ece, df_bins = expected_calibration_error(y_true, p_pred, n_bins=15)\n",
        "print(\"ECE:\", ece)\n",
        "\n",
        "# reliability curve\n",
        "frac_pos, mean_pred = calibration_curve(y_true, p_pred, n_bins=15, strategy=\"uniform\")\n",
        "\n",
        "plt.figure(figsize=(5.5, 5))\n",
        "plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(f\"Reliability diagram (TEST) — {BEST_MODEL_NAME}\\nBrier={brier_score_loss(y_true,p_pred):.4f}, ECE={ece:.4f}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"calibration_reliability.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "df_bins.to_csv(\"calibration_bins.csv\", index=False)\n",
        "print(\"Saved: calibration_reliability.png\")\n",
        "print(\"Saved: calibration_bins.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w-p5KmIjTL5F",
      "metadata": {
        "id": "w-p5KmIjTL5F"
      },
      "source": [
        "## 8C2) Hard-negative evaluation (2-hop negatives) on TEST (best GNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6uTLYyyhTL5F",
      "metadata": {
        "id": "6uTLYyyhTL5F"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8C2) Hard-negative evaluation (2-hop negatives) on TEST (best GNN)\n",
        "# - Hard negatives: node pairs at distance 2 in TRAIN graph, but not directly connected\n",
        "# - This tests if your model really learned structure (harder than random negatives)\n",
        "# Saves:\n",
        "#  - hard_negative_metrics.csv\n",
        "#  - hard_negative_pr_curve.png\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "\n",
        "assert \"data_train\" in globals() and \"data_test\" in globals(), \"Need data_train/data_test from RandomLinkSplit.\"\n",
        "assert \"model\" in globals(), \"Need trained model.\"\n",
        "\n",
        "# --- device ---\n",
        "try:\n",
        "    device = next(model.parameters()).device\n",
        "except Exception:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- (1) Compute embeddings on TRAIN graph (no leakage) ---\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    try:\n",
        "        if hasattr(data_train, \"edge_weight\") and data_train.edge_weight is not None:\n",
        "            z_train_hn = model.enc(data_train.x.to(device), data_train.edge_index.to(device), data_train.edge_weight.to(device))\n",
        "        else:\n",
        "            z_train_hn = model.enc(data_train.x.to(device), data_train.edge_index.to(device))\n",
        "    except TypeError:\n",
        "        # enc signature without edge_weight\n",
        "        z_train_hn = model.enc(data_train.x.to(device), data_train.edge_index.to(device))\n",
        "\n",
        "# --- helpers to get test positives ---\n",
        "def _get_pos_edges(data):\n",
        "    if hasattr(data, \"pos_edge_label_index\") and data.pos_edge_label_index is not None:\n",
        "        return data.pos_edge_label_index\n",
        "    if hasattr(data, \"edge_label_index\") and hasattr(data, \"edge_label\"):\n",
        "        m = (data.edge_label == 1)\n",
        "        return data.edge_label_index[:, m]\n",
        "    raise ValueError(\"Could not find positive test edges in data_test.\")\n",
        "\n",
        "pos_eidx = _get_pos_edges(data_test).detach().cpu()\n",
        "n_pos = pos_eidx.size(1)\n",
        "print(\"Test positives:\", n_pos)\n",
        "\n",
        "# --- (2) Build TRAIN adjacency (undirected) ---\n",
        "N = int(data_train.num_nodes)\n",
        "ei = data_train.edge_index.detach().cpu().numpy()\n",
        "edge_set = set()\n",
        "nbrs = [set() for _ in range(N)]\n",
        "for u, v in zip(ei[0], ei[1]):\n",
        "    a, b = int(u), int(v)\n",
        "    if a == b:\n",
        "        continue\n",
        "    x, y = (a, b) if a < b else (b, a)\n",
        "    edge_set.add((x, y))\n",
        "    nbrs[a].add(b)\n",
        "    nbrs[b].add(a)\n",
        "\n",
        "deg = np.array([len(s) for s in nbrs], dtype=int)\n",
        "nodes_deg = np.where(deg > 0)[0]\n",
        "assert len(nodes_deg) > 0, \"Train graph appears empty.\"\n",
        "\n",
        "# --- (3) Sample 2-hop hard negatives ---\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "target = min(n_pos, 100000)  # cap for speed\n",
        "hard = set()\n",
        "tries = 0\n",
        "max_tries = target * 50\n",
        "\n",
        "while len(hard) < target and tries < max_tries:\n",
        "    tries += 1\n",
        "    u = int(rng.choice(nodes_deg))\n",
        "    if len(nbrs[u]) == 0:\n",
        "        continue\n",
        "    n1 = int(rng.choice(list(nbrs[u])))\n",
        "    if len(nbrs[n1]) == 0:\n",
        "        continue\n",
        "    v = int(rng.choice(list(nbrs[n1])))\n",
        "    if v == u:\n",
        "        continue\n",
        "    a, b = (u, v) if u < v else (v, u)\n",
        "    if (a, b) in edge_set:\n",
        "        continue\n",
        "    hard.add((a, b))\n",
        "\n",
        "hard = np.array(list(hard), dtype=np.int64)\n",
        "print(f\"Hard negatives sampled: {len(hard)} (target={target}) | tries={tries}\")\n",
        "\n",
        "# align sizes\n",
        "pos_use = pos_eidx[:, :len(hard)]\n",
        "neg_use = torch.tensor(hard.T, dtype=torch.long)\n",
        "\n",
        "# --- (4) Score edges with decoder ---\n",
        "def _score(eidx_cpu):\n",
        "    eidx = eidx_cpu.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model.dec(z_train_hn, eidx).view(-1)\n",
        "        p = torch.sigmoid(logits).detach().cpu().numpy().astype(float)\n",
        "    return p\n",
        "\n",
        "p_pos = _score(pos_use)\n",
        "p_neg = _score(neg_use)\n",
        "\n",
        "y = np.concatenate([np.ones_like(p_pos), np.zeros_like(p_neg)])\n",
        "p = np.concatenate([p_pos, p_neg])\n",
        "\n",
        "roc = roc_auc_score(y, p)\n",
        "ap  = average_precision_score(y, p)\n",
        "print(f\"[HardNeg] ROC-AUC={roc:.4f} | AP={ap:.4f} | n_pos={len(p_pos)} | n_neg={len(p_neg)}\")\n",
        "\n",
        "df_hard = pd.DataFrame([{\n",
        "    \"n_pos\": int(len(p_pos)),\n",
        "    \"n_neg\": int(len(p_neg)),\n",
        "    \"roc_auc\": float(roc),\n",
        "    \"average_precision\": float(ap),\n",
        "    \"neg_type\": \"2-hop (hard)\",\n",
        "}])\n",
        "df_hard.to_csv(\"hard_negative_metrics.csv\", index=False)\n",
        "print(\"Saved: hard_negative_metrics.csv\")\n",
        "\n",
        "# --- PR curve plot ---\n",
        "prec, rec, _ = precision_recall_curve(y, p)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"PR curve (test positives vs 2-hop hard negatives)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"hard_negative_pr_curve.png\", dpi=300)\n",
        "plt.show()\n",
        "print(\"Saved: hard_negative_pr_curve.png\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oh-EX8yGbWGI",
      "metadata": {
        "id": "oh-EX8yGbWGI"
      },
      "source": [
        "## 9) TOP-N STRICT (NO LEAKAGE) — uses TRAIN GRAPH embeddings only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qZuPNBdbbWGI",
      "metadata": {
        "id": "qZuPNBdbbWGI"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 9) TOP-N STRICT (NO LEAKAGE) — uses TRAIN GRAPH embeddings only\n",
        "#     Solution A: all tensors on same device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZqQURT1ObWGJ",
      "metadata": {
        "id": "ZqQURT1ObWGJ"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ejiNWEbWGJ",
      "metadata": {
        "id": "89ejiNWEbWGJ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z_train = model.enc(\n",
        "        data_train.x.to(device),\n",
        "        data_train.edge_index.to(device),\n",
        "        data_train.edge_weight.to(device)\n",
        "    )\n",
        "\n",
        "# existing edges in TRAIN graph (undirected)\n",
        "Eset_train = set()\n",
        "ei_tr = data_train.edge_index.detach().cpu().numpy()\n",
        "for u, v in zip(ei_tr[0], ei_tr[1]):\n",
        "    a, b = int(u), int(v)\n",
        "    if a > b: a, b = b, a\n",
        "    Eset_train.add((a, b))\n",
        "\n",
        "# candidate sampling\n",
        "rng = np.random.default_rng(SEED)\n",
        "N = int(data_train.num_nodes)\n",
        "NUM_CAND = 300000\n",
        "pairs = rng.integers(0, N, size=(NUM_CAND, 2), dtype=np.int64)\n",
        "pairs = pairs[pairs[:,0] != pairs[:,1]]\n",
        "\n",
        "cand = []\n",
        "for u, v in pairs:\n",
        "    a, b = int(u), int(v)\n",
        "    if a > b: a, b = b, a\n",
        "    if (a, b) not in Eset_train:\n",
        "        cand.append((a, b))\n",
        "    if len(cand) >= 200000:\n",
        "        break\n",
        "\n",
        "cand = np.array(cand, dtype=np.int64)\n",
        "edge_cand = torch.tensor(cand.T, dtype=torch.long, device=device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model.dec(z_train, edge_cand).detach().cpu().numpy()\n",
        "prob = 1.0 / (1.0 + np.exp(-logits))\n",
        "\n",
        "topk = 200\n",
        "idx = np.argsort(-prob)[:topk]\n",
        "top_edges = cand[idx]\n",
        "top_prob  = prob[idx]\n",
        "\n",
        "def cn_explain(u, v):\n",
        "    nu = adj.get(int(u), set())\n",
        "    nv = adj.get(int(v), set())\n",
        "    return len(nu.intersection(nv))\n",
        "\n",
        "out = []\n",
        "for (u, v), p in zip(top_edges, top_prob):\n",
        "    out.append({\n",
        "        \"u\": int(u), \"v\": int(v),\n",
        "        \"string_u\": string_ids[int(u)],\n",
        "        \"string_v\": string_ids[int(v)],\n",
        "        \"prob\": float(p),\n",
        "        \"cn_train\": int(cn_explain(u, v)),\n",
        "        \"gene_u\": nodes_annot.loc[int(u), \"gene_final\"],\n",
        "        \"gene_v\": nodes_annot.loc[int(v), \"gene_final\"],\n",
        "    })\n",
        "\n",
        "df_top = pd.DataFrame(out).sort_values(\"prob\", ascending=False)\n",
        "df_top.to_csv(\"top_predictions_strict_train_graph.csv\", index=False)\n",
        "print(\"Saved: top_predictions_strict_train_graph.csv\")\n",
        "display(df_top.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pvur9_jpbWGJ",
      "metadata": {
        "id": "Pvur9_jpbWGJ"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pdrCqQXebWGJ",
      "metadata": {
        "id": "pdrCqQXebWGJ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 9b) OPTIONAL: Bootstrap uncertainty on Top predicted edges (merge from version 3)\n",
        "#     Train a small ensemble (different seeds) and compute mean/std on the SAME top edges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "itTEtxKaTL5F",
      "metadata": {
        "id": "itTEtxKaTL5F"
      },
      "source": [
        "## 8C3) MC-Dropout uncertainty on TOP predicted edges (best GNN, optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dUIkWwo3TL5G",
      "metadata": {
        "id": "dUIkWwo3TL5G"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 8C3) MC-Dropout uncertainty on TOP predicted edges (best GNN, optional)\n",
        "# - Lightweight alternative to the multi-seed ensemble\n",
        "# - Requires df_top from the TOP-N prediction section\n",
        "# Saves:\n",
        "#  - top_edges_mc_dropout.csv\n",
        "#  - mc_dropout_mean_vs_std.png\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if \"df_top\" not in globals():\n",
        "    print(\"df_top not found -> skip MC-Dropout. (Run TOP-N prediction cell first.)\")\n",
        "else:\n",
        "    assert \"data_train\" in globals(), \"Need data_train.\"\n",
        "    assert \"model\" in globals(), \"Need trained model.\"\n",
        "    try:\n",
        "        device = next(model.parameters()).device\n",
        "    except Exception:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # compute embeddings on TRAIN graph once\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            if hasattr(data_train, \"edge_weight\") and data_train.edge_weight is not None:\n",
        "                z_mc = model.enc(data_train.x.to(device), data_train.edge_index.to(device), data_train.edge_weight.to(device))\n",
        "            else:\n",
        "                z_mc = model.enc(data_train.x.to(device), data_train.edge_index.to(device))\n",
        "        except TypeError:\n",
        "            z_mc = model.enc(data_train.x.to(device), data_train.edge_index.to(device))\n",
        "\n",
        "    # edges\n",
        "    N_EDGES = min(20000, len(df_top))  # cap for speed\n",
        "    uv = df_top[[\"u\",\"v\"]].head(N_EDGES).astype(int).values\n",
        "    eidx = torch.tensor(uv.T, dtype=torch.long, device=device)\n",
        "\n",
        "    T = 30\n",
        "    probs = []\n",
        "\n",
        "    # enable dropout sampling\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "        for t in range(T):\n",
        "            logits = model.dec(z_mc, eidx).view(-1)\n",
        "            probs.append(torch.sigmoid(logits).detach().cpu().numpy().astype(np.float32))\n",
        "    model.eval()\n",
        "\n",
        "    P = np.stack(probs, axis=0)  # [T, E]\n",
        "    mean = P.mean(axis=0)\n",
        "    std  = P.std(axis=0)\n",
        "\n",
        "    out = df_top.head(N_EDGES).copy()\n",
        "    out[\"mc_prob_mean\"] = mean\n",
        "    out[\"mc_prob_std\"]  = std\n",
        "    out.to_csv(\"top_edges_mc_dropout.csv\", index=False)\n",
        "    print(\"Saved: top_edges_mc_dropout.csv\")\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.scatter(out[\"mc_prob_mean\"], out[\"mc_prob_std\"], s=6)\n",
        "    plt.xlabel(\"MC mean prob\")\n",
        "    plt.ylabel(\"MC std (uncertainty)\")\n",
        "    plt.title(\"MC-Dropout uncertainty on top predicted edges\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"mc_dropout_mean_vs_std.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(\"Saved: mc_dropout_mean_vs_std.png\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f09df941",
      "metadata": {
        "id": "f09df941"
      },
      "source": [
        "\n",
        "## 26D) Stronger link decoder: GNN encoder + Edge MLP decoder (with tuning)\n",
        "\n",
        "Dot-product decoders are simple and fast, but for harder link prediction they can underfit.\n",
        "Here we use an MLP edge-decoder over pair embeddings (concat, abs-diff, hadamard), and we **tune** key hyperparameters using the validation split:\n",
        "\n",
        "- Encoder: hidden dim, dropout\n",
        "- Decoder: depth, hidden sizes, dropout, activation\n",
        "- Optimizer: lr, weight decay\n",
        "- Training: negative sampling ratio, early stopping\n",
        "\n",
        "Selection criterion: **validation AP** (tie-break: validation AUC).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc43269",
      "metadata": {
        "id": "5bc43269"
      },
      "source": [
        "## Edge-MLP embeddings → Clustering → CORUM/GO/Disease\n",
        "\n",
        "Run in this order:\n",
        "1) Train Edge-MLP decoder (produces `z_lp_mlp`)\n",
        "2) KMeans clustering on `z_lp_mlp` (produces `labels_mlp`)\n",
        "3) Register to `df_clusters` as `edge_mlp_kmeans`\n",
        "4) Run CORUM (cell 15), Disease enrichment (cell 16), GO enrichment (cell 28A)\n",
        "\n",
        "Notes:\n",
        "- CORUM/GO/Disease require `df_clusters['gene_final']`. The cell **30D-bio2** tries to create it safely if missing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e9d03f",
      "metadata": {
        "id": "a0e9d03f"
      },
      "source": [
        "# =========================\n",
        "# 26D) Tuned link prediction: GNN encoder + Edge-MLP decoder (grid search + early stopping)\n",
        "# - Robust to RandomLinkSplit outputs (edge_label_index / pos_edge_label_index)\n",
        "# - Tunes: encoder hidden, decoder depth/hidden/dropout, lr, weight_decay, neg_ratio\n",
        "# - Selects best config by VAL AP (tie-break: VAL AUC)\n",
        "# =========================\n",
        "\n",
        "import math\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "    from torch_geometric.nn import GCNConv\n",
        "    from torch_geometric.utils import negative_sampling as pyg_negative_sampling\n",
        "except Exception as e:\n",
        "    raise ImportError(\"Need torch_geometric (GCNConv, negative_sampling) for Edge-MLP tuning.\") from e\n",
        "\n",
        "\n",
        "def _get_pos_edge_index_for_loss(data):\n",
        "    \"\"\"Return positive edges for supervision.\"\"\"\n",
        "    if hasattr(data, 'pos_edge_label_index') and data.pos_edge_label_index is not None:\n",
        "        return data.pos_edge_label_index\n",
        "    if hasattr(data, 'edge_label_index') and data.edge_label_index is not None:\n",
        "        # edge_label_index may include both pos & neg; try to filter if edge_label exists\n",
        "        if hasattr(data, 'edge_label') and data.edge_label is not None:\n",
        "            y = data.edge_label\n",
        "            return data.edge_label_index[:, y == 1]\n",
        "        return data.edge_label_index\n",
        "    return data.edge_index\n",
        "\n",
        "\n",
        "def _get_neg_edge_index_for_loss(data, num_nodes, num_neg, device):\n",
        "    \"\"\"Return negative edges for supervision.\"\"\"\n",
        "    if hasattr(data, 'neg_edge_label_index') and data.neg_edge_label_index is not None:\n",
        "        return data.neg_edge_label_index\n",
        "    if hasattr(data, 'edge_label_index') and hasattr(data, 'edge_label'):\n",
        "        if data.edge_label_index is not None and data.edge_label is not None:\n",
        "            y = data.edge_label\n",
        "            neg = data.edge_label_index[:, y == 0]\n",
        "            if neg.numel() > 0:\n",
        "                return neg\n",
        "    # fallback sampling\n",
        "    return pyg_negative_sampling(\n",
        "        edge_index=_get_pos_edge_index_for_loss(data),\n",
        "        num_nodes=num_nodes,\n",
        "        num_neg_samples=int(num_neg),\n",
        "        method='sparse'\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "class SimpleGCNEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, out_dim=64, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.c1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.c2 = GCNConv(hidden_dim, out_dim)\n",
        "        self.dropout = float(dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.c1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        if self.dropout > 0:\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.c2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeMLPDecoder(nn.Module):\n",
        "    \"\"\"Edge decoder over pair features: [zi, zj, |zi-zj|, zi*zj].\"\"\"\n",
        "    def __init__(self, z_dim, hidden_dims=(128,), dropout=0.1, activation='relu'):\n",
        "        super().__init__()\n",
        "        act = {'relu': nn.ReLU, 'gelu': nn.GELU, 'elu': nn.ELU}.get(str(activation).lower(), nn.ReLU)\n",
        "\n",
        "        layers = []\n",
        "        in_dim = z_dim * 4\n",
        "        for h in hidden_dims:\n",
        "            layers += [nn.Linear(in_dim, int(h)), act()]\n",
        "            if dropout and float(dropout) > 0:\n",
        "                layers += [nn.Dropout(float(dropout))]\n",
        "            in_dim = int(h)\n",
        "        layers += [nn.Linear(in_dim, 1)]\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        zs, zd = z[src], z[dst]\n",
        "        feat = torch.cat([zs, zd, torch.abs(zs - zd), zs * zd], dim=-1)\n",
        "        return self.mlp(feat).view(-1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _eval_lp(enc, dec, data_mp, data_eval):\n",
        "    \"\"\"Evaluate with pos edges from data_eval and negatives either provided or sampled.\"\"\"\n",
        "    enc.eval(); dec.eval()\n",
        "    z = enc(data_mp.x, data_mp.edge_index)\n",
        "\n",
        "    pos_e = _get_pos_edge_index_for_loss(data_eval)\n",
        "    # use provided negatives if available, else sample same count\n",
        "    if hasattr(data_eval, 'neg_edge_label_index') and data_eval.neg_edge_label_index is not None:\n",
        "        neg_e = data_eval.neg_edge_label_index\n",
        "    else:\n",
        "        neg_e = pyg_negative_sampling(\n",
        "            edge_index=pos_e,\n",
        "            num_nodes=data_mp.num_nodes,\n",
        "            num_neg_samples=pos_e.size(1),\n",
        "            method='sparse'\n",
        "        ).to(pos_e.device)\n",
        "\n",
        "    pos_s = torch.sigmoid(dec(z, pos_e)).detach().cpu().numpy()\n",
        "    neg_s = torch.sigmoid(dec(z, neg_e)).detach().cpu().numpy()\n",
        "\n",
        "    y_true = np.concatenate([np.ones_like(pos_s), np.zeros_like(neg_s)])\n",
        "    y_score = np.concatenate([pos_s, neg_s])\n",
        "\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    return {\n",
        "        'auc': float(roc_auc_score(y_true, y_score)),\n",
        "        'ap': float(average_precision_score(y_true, y_score))\n",
        "    }\n",
        "\n",
        "\n",
        "def train_edge_mlp_one_run(\n",
        "    data_train,\n",
        "    data_val,\n",
        "    *,\n",
        "    z_dim=64,\n",
        "    enc_hidden=128,\n",
        "    enc_dropout=0.0,\n",
        "    dec_hidden_dims=(128,),\n",
        "    dec_dropout=0.1,\n",
        "    dec_activation='relu',\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    neg_ratio=1.0,\n",
        "    epochs=300,\n",
        "    patience=30,\n",
        "    seed=0,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Train on train supervision, early-stop on val AP.\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    device = data_train.x.device\n",
        "    enc = SimpleGCNEncoder(data_train.num_node_features, hidden_dim=enc_hidden, out_dim=z_dim, dropout=enc_dropout).to(device)\n",
        "    dec = EdgeMLPDecoder(z_dim=z_dim, hidden_dims=dec_hidden_dims, dropout=dec_dropout, activation=dec_activation).to(device)\n",
        "    opt = torch.optim.AdamW(list(enc.parameters()) + list(dec.parameters()), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    pos_e = _get_pos_edge_index_for_loss(data_train)\n",
        "    num_pos = int(pos_e.size(1))\n",
        "\n",
        "    best = {'ap': -1.0, 'auc': -1.0, 'epoch': 0}\n",
        "    best_state = None\n",
        "    bad = 0\n",
        "\n",
        "    for ep in range(1, int(epochs) + 1):\n",
        "        enc.train(); dec.train(); opt.zero_grad()\n",
        "\n",
        "        z = enc(data_train.x, data_train.edge_index)\n",
        "\n",
        "        neg_e = _get_neg_edge_index_for_loss(\n",
        "            data_train,\n",
        "            num_nodes=data_train.num_nodes,\n",
        "            num_neg=int(math.ceil(num_pos * float(neg_ratio))),\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        pos_logits = dec(z, pos_e)\n",
        "        neg_logits = dec(z, neg_e)\n",
        "\n",
        "        logits = torch.cat([pos_logits, neg_logits], dim=0)\n",
        "        y = torch.cat([torch.ones_like(pos_logits), torch.zeros_like(neg_logits)], dim=0)\n",
        "\n",
        "        # imbalance-aware if neg_ratio != 1\n",
        "        if float(neg_ratio) != 1.0:\n",
        "            pos_weight = torch.tensor([float(neg_ratio)], device=device)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y, pos_weight=pos_weight)\n",
        "        else:\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(list(enc.parameters()) + list(dec.parameters()), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        # validate\n",
        "        val = _eval_lp(enc, dec, data_train, data_val)\n",
        "\n",
        "        improved = (val['ap'] > best['ap'] + 1e-6) or (abs(val['ap'] - best['ap']) <= 1e-6 and val['auc'] > best['auc'] + 1e-6)\n",
        "        if improved:\n",
        "            best = {**val, 'epoch': ep}\n",
        "            best_state = {\n",
        "                'enc': {k: v.detach().cpu() for k, v in enc.state_dict().items()},\n",
        "                'dec': {k: v.detach().cpu() for k, v in dec.state_dict().items()},\n",
        "            }\n",
        "            bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "\n",
        "        if verbose and (ep % 25 == 0 or ep == 1):\n",
        "            print(f\"[EdgeMLP] ep {ep:03d} | loss {loss.item():.4f} | val AP {val['ap']:.4f} | val AUC {val['auc']:.4f}\")\n",
        "\n",
        "        if bad >= int(patience):\n",
        "            break\n",
        "\n",
        "    # restore best\n",
        "    if best_state is not None:\n",
        "        enc.load_state_dict(best_state['enc'])\n",
        "        dec.load_state_dict(best_state['dec'])\n",
        "\n",
        "    return enc, dec, best\n",
        "\n",
        "\n",
        "def tune_edge_mlp_lp(\n",
        "    data_train,\n",
        "    data_val,\n",
        "    data_test,\n",
        "    *,\n",
        "    z_dim=64,\n",
        "    seeds=(0, 1, 2),\n",
        "    param_grid=None,\n",
        "    epochs=300,\n",
        "    patience=30,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"Grid-search configs; score = mean VAL AP across seeds (tie-break mean VAL AUC).\"\"\"\n",
        "    if param_grid is None:\n",
        "        param_grid = {\n",
        "            'enc_hidden': [64, 128, 256],\n",
        "            'enc_dropout': [0.0, 0.2],\n",
        "            'dec_hidden_dims': [(64,), (128,), (256,), (256, 128)],\n",
        "            'dec_dropout': [0.0, 0.1, 0.3],\n",
        "            'dec_activation': ['relu', 'gelu'],\n",
        "            'lr': [5e-4, 1e-3, 2e-3],\n",
        "            'weight_decay': [0.0, 1e-4, 5e-4],\n",
        "            'neg_ratio': [1.0, 2.0],\n",
        "        }\n",
        "\n",
        "    keys = list(param_grid.keys())\n",
        "    combos = list(itertools.product(*[param_grid[k] for k in keys]))\n",
        "\n",
        "    rows = []\n",
        "    best_cfg = None\n",
        "    best_mean = (-1.0, -1.0)\n",
        "\n",
        "    for t, values in enumerate(combos, 1):\n",
        "        cfg = dict(zip(keys, values))\n",
        "        ap_list, auc_list, best_ep = [], [], []\n",
        "\n",
        "        for sd in seeds:\n",
        "            enc, dec, best = train_edge_mlp_one_run(\n",
        "                data_train,\n",
        "                data_val,\n",
        "                z_dim=z_dim,\n",
        "                epochs=epochs,\n",
        "                patience=patience,\n",
        "                seed=int(sd),\n",
        "                verbose=False,\n",
        "                **cfg,\n",
        "            )\n",
        "            ap_list.append(best['ap']); auc_list.append(best['auc']); best_ep.append(best['epoch'])\n",
        "\n",
        "        mean_ap = float(np.mean(ap_list))\n",
        "        mean_auc = float(np.mean(auc_list))\n",
        "\n",
        "        row = {**cfg,\n",
        "               'trial': t,\n",
        "               'val_ap_mean': mean_ap,\n",
        "               'val_auc_mean': mean_auc,\n",
        "               'best_epoch_mean': float(np.mean(best_ep))}\n",
        "        rows.append(row)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Trial {t:03d}/{len(combos)} | val AP {mean_ap:.4f} | val AUC {mean_auc:.4f} | cfg={cfg}\")\n",
        "\n",
        "        if (mean_ap > best_mean[0] + 1e-6) or (abs(mean_ap - best_mean[0]) <= 1e-6 and mean_auc > best_mean[1] + 1e-6):\n",
        "            best_mean = (mean_ap, mean_auc)\n",
        "            best_cfg = cfg\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(['val_ap_mean', 'val_auc_mean'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # retrain once with best config (seed=0) and evaluate on test\n",
        "    enc_best, dec_best, best_val = train_edge_mlp_one_run(\n",
        "        data_train,\n",
        "        data_val,\n",
        "        z_dim=z_dim,\n",
        "        epochs=epochs,\n",
        "        patience=patience,\n",
        "        seed=int(seeds[0]) if len(seeds) else 0,\n",
        "        verbose=True,\n",
        "        **best_cfg,\n",
        "    )\n",
        "\n",
        "    test_metrics = _eval_lp(enc_best, dec_best, data_train, data_test)\n",
        "\n",
        "    out = {\n",
        "        'best_cfg': best_cfg,\n",
        "        'val_best': best_val,\n",
        "        'test': test_metrics,\n",
        "        'df_trials': df,\n",
        "        'encoder': enc_best,\n",
        "        'decoder': dec_best,\n",
        "    }\n",
        "    return out\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------\n",
        "# Toggles (safe defaults)\n",
        "# -------------------------\n",
        "if 'RUN_DGI_PRETRAIN' not in globals():\n",
        "    RUN_DGI_PRETRAIN = True          # contrastive pretraining to get better embeddings\n",
        "if 'RUN_TRANSFORMER_VGAE' not in globals():\n",
        "    RUN_TRANSFORMER_VGAE = True      # VGAE encoder = TransformerConv\n",
        "if 'RUN_EDGE_MLP_DECODER' not in globals():\n",
        "    RUN_EDGE_MLP_DECODER = True      # stronger decoder for link prediction\n",
        "if 'RUN_CLUSTER_STABILITY' not in globals():\n",
        "    RUN_CLUSTER_STABILITY = True     # stability across seeds / runs\n",
        "if 'RUN_K_MODEL_SELECTION' not in globals():\n",
        "    RUN_K_MODEL_SELECTION = True     # choose K via stability+modularity curve\n",
        "\n",
        "print(\"RUN_DGI_PRETRAIN:\", RUN_DGI_PRETRAIN)\n",
        "print(\"RUN_TRANSFORMER_VGAE:\", RUN_TRANSFORMER_VGAE)\n",
        "print(\"RUN_EDGE_MLP_DECODER:\", RUN_EDGE_MLP_DECODER)\n",
        "print(\"RUN_CLUSTER_STABILITY:\", RUN_CLUSTER_STABILITY)\n",
        "print(\"RUN_K_MODEL_SELECTION:\", RUN_K_MODEL_SELECTION)\n"
      ],
      "metadata": {
        "id": "w9Fs7o8NGAHU"
      },
      "id": "w9Fs7o8NGAHU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef24d03",
      "metadata": {
        "id": "eef24d03"
      },
      "outputs": [],
      "source": [
        "# Run tuned Edge-MLP link prediction (uses data_train/data_val/data_test from RandomLinkSplit)\n",
        "# Outputs:\n",
        "# - edge_mlp_tune['df_trials'] : full grid results\n",
        "# - edge_mlp_tune['best_cfg']  : best hyperparameters\n",
        "# - edge_mlp_tune['test']      : final test AUC/AP\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "if RUN_EDGE_MLP_DECODER and all(k in globals() for k in ['data_train','data_val','data_test']):\n",
        "    _train = data_train.to(device)\n",
        "    _val   = data_val.to(device)\n",
        "    _test  = data_test.to(device)\n",
        "\n",
        "    # ensure features exist\n",
        "    if _train.x is None:\n",
        "        _train.x = torch.ones((_train.num_nodes, 1), device=device)\n",
        "        _val.x   = _train.x\n",
        "        _test.x  = _train.x\n",
        "\n",
        "    # OPTIONAL: shrink grid if you want fast runs\n",
        "    param_grid_fast = {\n",
        "        'enc_hidden': [128, 256],\n",
        "        'enc_dropout': [0.0, 0.2],\n",
        "        'dec_hidden_dims': [(128,), (256, 128)],\n",
        "        'dec_dropout': [0.0, 0.1, 0.3],\n",
        "        'dec_activation': ['relu', 'gelu'],\n",
        "        'lr': [5e-4, 1e-3, 2e-3],\n",
        "        'weight_decay': [0.0, 1e-4],\n",
        "        'neg_ratio': [1.0, 2.0],\n",
        "    }\n",
        "\n",
        "    edge_mlp_tune = tune_edge_mlp_lp(\n",
        "        _train,\n",
        "        _val,\n",
        "        _test,\n",
        "        z_dim=64,\n",
        "        seeds=(SEED, SEED+1, SEED+2),\n",
        "        param_grid=param_grid_fast,\n",
        "        epochs=300,\n",
        "        patience=30,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    display(edge_mlp_tune['df_trials'].head(15))\n",
        "    print('Best cfg:', edge_mlp_tune['best_cfg'])\n",
        "    print('Best val:', edge_mlp_tune['val_best'])\n",
        "    print('Test:', edge_mlp_tune['test'])\n",
        "\n",
        "    # embeddings from final tuned encoder\n",
        "    with torch.no_grad():\n",
        "        z_lp_mlp = edge_mlp_tune['encoder'](_train.x, _train.edge_index).detach().cpu().numpy()\n",
        "\n",
        "    # Optional clustering baseline on tuned embeddings\n",
        "    if 'K_FINAL' in globals() and K_FINAL is not None:\n",
        "        km = KMeans(n_clusters=int(K_FINAL), n_init=20, random_state=SEED)\n",
        "        pred = km.fit_predict(z_lp_mlp)\n",
        "        print('KMeans on tuned LP embeddings done. (pred shape:', pred.shape, ')')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xXLgpsxubWGJ",
      "metadata": {
        "id": "xXLgpsxubWGJ"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_zMu3JOgbWGJ",
      "metadata": {
        "id": "_zMu3JOgbWGJ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 4C) OPTIONAL: Bootstrap/Ensemble uncertainty on TOP predicted edges\n",
        "# =========================\n",
        "DO_BOOTSTRAP_UNCERTAINTY = True\n",
        "N_ENSEMBLE = 5\n",
        "ENS_EPOCHS = 80\n",
        "\n",
        "if DO_BOOTSTRAP_UNCERTAINTY:\n",
        "    import gc, numpy as np, torch\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    assert \"df_top\" in globals(), \"Need df_top (top predicted edges). Run the TOP-N prediction cell first.\"\n",
        "    assert \"BEST_MODEL_NAME\" in globals(), \"Need BEST_MODEL_NAME (from GNN compare cell).\"\n",
        "    assert \"data_train\" in globals() and \"data_val\" in globals() and \"data_test\" in globals()\n",
        "\n",
        "    def _pick_col(df, cands):\n",
        "        for c in cands:\n",
        "            if c in df.columns:\n",
        "                return c\n",
        "        return None\n",
        "\n",
        "    u_col = _pick_col(df_top, [\"u\",\"src\",\"source\"])\n",
        "    v_col = _pick_col(df_top, [\"v\",\"dst\",\"target\"])\n",
        "    if u_col is None or v_col is None:\n",
        "        raise ValueError(f\"df_top must contain endpoint columns. Columns: {list(df_top.columns)}\")\n",
        "\n",
        "    edge_index_top = torch.tensor(df_top[[u_col, v_col]].to_numpy().T, dtype=torch.long, device=device)\n",
        "\n",
        "    def _cleanup():\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    def train_one_seed(seed, epochs=ENS_EPOCHS):\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        m = build_model(\n",
        "            BEST_MODEL_NAME,\n",
        "            in_dim=data_train.num_node_features,\n",
        "            hidden=HIDDEN,\n",
        "            emb_dim=EMB_DIM,\n",
        "            dropout=DROPOUT,\n",
        "            appnp_K=APPNP_K,\n",
        "            appnp_alpha=APPNP_ALPHA,\n",
        "        )\n",
        "\n",
        "        m, _, _, _ = train_linkpred(\n",
        "            model_name=BEST_MODEL_NAME,\n",
        "            model=m,\n",
        "            data_train=data_train,\n",
        "            data_val=data_val,\n",
        "            data_test=data_test,\n",
        "            epochs=epochs,\n",
        "            lr=LR,\n",
        "            weight_decay=WEIGHT_DECAY,\n",
        "            neg_ratio=NEG_RATIO,\n",
        "            patience=max(10, PATIENCE//2),\n",
        "            grad_clip=1.0,\n",
        "            use_amp=USE_AMP,\n",
        "            edge_dropout=EDGE_DROPOUT,\n",
        "        )\n",
        "        return m\n",
        "\n",
        "    scores_ens = []\n",
        "    for s in range(N_ENSEMBLE):\n",
        "        _cleanup()\n",
        "        print(f\"[Ensemble] training seed {s}/{N_ENSEMBLE-1} ...\")\n",
        "        m = train_one_seed(s, epochs=ENS_EPOCHS).to(device)\n",
        "        m.eval()\n",
        "        with torch.no_grad():\n",
        "            x = data_train.x.to(device)\n",
        "            ei = data_train.edge_index.to(device)\n",
        "            ew = getattr(data_train, \"edge_weight\", None)\n",
        "            ew = ew.to(device) if ew is not None else None\n",
        "            with (torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16) if (USE_AMP and device.type==\"cuda\" and hasattr(torch, \"amp\")) else torch.cuda.amp.autocast(enabled=(USE_AMP and device.type==\"cuda\"))):\n",
        "                z = m.enc(x, ei, edge_weight=ew)\n",
        "                logits = m.dec(z, edge_index_top)\n",
        "            p = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "        scores_ens.append(p)\n",
        "\n",
        "    scores_ens = np.vstack(scores_ens)\n",
        "    df_top[\"prob_mean\"] = scores_ens.mean(axis=0)\n",
        "    df_top[\"prob_std\"]  = scores_ens.std(axis=0)\n",
        "\n",
        "    df_top.to_csv(\"top_predictions_with_uncertainty.csv\", index=False)\n",
        "    print(\"Saved: top_predictions_with_uncertainty.csv\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(df_top[\"prob_mean\"], df_top[\"prob_std\"], s=15)\n",
        "    plt.xlabel(\"Mean predicted probability\")\n",
        "    plt.ylabel(\"Std (uncertainty)\")\n",
        "    plt.title(\"Uncertainty of Top predicted edges (bootstrap ensemble)\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"top_edges_uncertainty_scatter.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(\"Saved: top_edges_uncertainty_scatter.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Cjj5-qRbWGK",
      "metadata": {
        "id": "2Cjj5-qRbWGK"
      },
      "source": [
        "## 10) OPTIONAL: RETRAIN ON FULL GRAPH (deliverable mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ReJSyBZlbWGK",
      "metadata": {
        "id": "ReJSyBZlbWGK"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 10) OPTIONAL: RETRAIN ON FULL GRAPH (deliverable mode)\n",
        "#    Robust: handles whatever train_linkpred returns (model, (y,p)) OR (model, history, (y,p)) etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OcxIGf7wbWGK",
      "metadata": {
        "id": "OcxIGf7wbWGK"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fSN72r6bbWGK",
      "metadata": {
        "id": "fSN72r6bbWGK"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 4D) OPTIONAL: Retrain best GNN on ALL edges (train=val=test) for final embeddings/predictions\n",
        "# =========================\n",
        "# For paper: NOT strictly required. Useful if you want final embeddings from full graph.\n",
        "DO_RETRAIN_ALL = True\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "assert \"data_full\" in globals(), \"Missing data_full\"\n",
        "assert \"build_model\" in globals() and \"train_linkpred\" in globals(), \"Missing build_model/train_linkpred\"\n",
        "assert \"w_dict\" in globals() and \"edge_weight_from_dict\" in globals(), \"Missing edge_weight_from_dict / w_dict\"\n",
        "\n",
        "MODEL_NAME_RETRAIN = globals().get(\"BEST_MODEL_NAME\", \"graphsage\")\n",
        "\n",
        "if DO_RETRAIN_ALL:\n",
        "    # build a split where everything is training (and we reuse train as val/test to satisfy code)\n",
        "    split_all = RandomLinkSplit(\n",
        "        num_val=0.0,\n",
        "        num_test=0.0,\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=True,\n",
        "        neg_sampling_ratio=globals().get(\"NEG_RATIO\", 1.0),\n",
        "    )\n",
        "    tr_all, va_all, te_all = split_all(data_full)\n",
        "\n",
        "    # restore weights for all splits (they share edges here)\n",
        "    tr_all.edge_weight = edge_weight_from_dict(tr_all.edge_index, w_dict)\n",
        "    va_all = tr_all\n",
        "    te_all = tr_all\n",
        "\n",
        "    model_all = build_model(\n",
        "        MODEL_NAME_RETRAIN,\n",
        "        in_dim=tr_all.num_node_features,\n",
        "        hidden=globals().get(\"HIDDEN\", 128),\n",
        "        emb_dim=globals().get(\"EMB_DIM\", 64),\n",
        "        dropout=globals().get(\"DROPOUT\", 0.2),\n",
        "        appnp_K=globals().get(\"APPNP_K\", 10),\n",
        "        appnp_alpha=globals().get(\"APPNP_ALPHA\", 0.1),\n",
        "    )\n",
        "\n",
        "    model_all, z_all, metrics_all, log_all = train_linkpred(\n",
        "        model_name=f\"{MODEL_NAME_RETRAIN}_ALL\",\n",
        "        model=model_all,\n",
        "        data_train=tr_all,\n",
        "        data_val=va_all,\n",
        "        data_test=te_all,\n",
        "        epochs=100,\n",
        "        lr=globals().get(\"LR\", 1e-3),\n",
        "        weight_decay=globals().get(\"WEIGHT_DECAY\", 1e-4),\n",
        "        neg_ratio=globals().get(\"NEG_RATIO\", 1.0),\n",
        "        patience=25,\n",
        "        grad_clip=1.0,\n",
        "        use_amp=globals().get(\"USE_AMP\", True),\n",
        "        edge_dropout=globals().get(\"EDGE_DROPOUT\", 0.0),\n",
        "    )\n",
        "\n",
        "    np.save(\"embeddings_fullgraph_best.npy\", z_all)\n",
        "    print(\"Saved: embeddings_fullgraph_best.npy\", z_all.shape)\n",
        "    print(\"✅ Retrain-on-all done. Use `model_all` and `z_all` if you need full-graph embeddings.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2wbb4ZjbWGL",
      "metadata": {
        "id": "f2wbb4ZjbWGL"
      },
      "source": [
        "## 11) CLUSTERING ON EMBEDDINGS + METRICS + PLOTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76UbuP-fbWGL",
      "metadata": {
        "id": "76UbuP-fbWGL"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11) CLUSTERING ON EMBEDDINGS + METRICS + PLOTS\n",
        "# FIX: modularity needs a true partition of G nodes.\n",
        "#      We build a graph with ALL nodes [0..N-1] and the TRAIN edges.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acA63qpabWGL",
      "metadata": {
        "id": "acA63qpabWGL"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iqEZhuT7bWGL",
      "metadata": {
        "id": "iqEZhuT7bWGL"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11B) Clustering stability + GNN-based cluster validity (ML-oriented)\n",
        "# - Stability: pairwise ARI/AMI between partitions across random seeds\n",
        "# - Validity (GNN-based): how well the trained decoder separates intra-cluster vs inter-cluster pairs\n",
        "# Saves:\n",
        "#  - clustering_stability_pairwise.csv\n",
        "#  - clustering_stability_summary.csv\n",
        "#  - gnn_cluster_validity_scores.csv\n",
        "# =========================\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, roc_auc_score\n",
        "\n",
        "# -------------------------\n",
        "# Must-have objects for ML validity\n",
        "# -------------------------\n",
        "assert \"data_train\" in globals(), \"Missing data_train. Run the split/train cells first.\"\n",
        "assert \"z_train\" in globals(), \"Need embeddings z_train (from best GNN training).\"\n",
        "assert \"model\" in globals(), \"Need trained model (best).\"\n",
        "\n",
        "N = int(data_train.num_nodes)\n",
        "\n",
        "# -------------------------\n",
        "# Auto-build G_train if missing\n",
        "# -------------------------\n",
        "if \"G_train\" not in globals():\n",
        "    ei = data_train.edge_index.detach().cpu().numpy()\n",
        "    G_train = nx.Graph()\n",
        "    G_train.add_nodes_from(range(N))\n",
        "    G_train.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "    print(\"✅ Auto-built G_train:\", G_train.number_of_nodes(), \"nodes,\", G_train.number_of_edges(), \"edges\")\n",
        "\n",
        "Gnx = G_train\n",
        "\n",
        "# -------------------------\n",
        "# Auto-load df_clusters if missing (try common names)\n",
        "# -------------------------\n",
        "def _try_load_df_clusters():\n",
        "    candidates = []\n",
        "    candidates += sorted(glob.glob(\"embedding_clusters*.csv\"))\n",
        "    candidates += sorted(glob.glob(\"cluster*clusters*.csv\"))\n",
        "    candidates += sorted(glob.glob(\"cluster_assignments*.csv\"))\n",
        "    candidates += sorted(glob.glob(\"df_clusters*.csv\"))\n",
        "    if os.path.exists(\"/content\"):\n",
        "        candidates += sorted(glob.glob(\"/content/embedding_clusters*.csv\"))\n",
        "        candidates += sorted(glob.glob(\"/content/cluster*clusters*.csv\"))\n",
        "        candidates += sorted(glob.glob(\"/content/cluster_assignments*.csv\"))\n",
        "        candidates += sorted(glob.glob(\"/content/df_clusters*.csv\"))\n",
        "\n",
        "    for p in candidates:\n",
        "        try:\n",
        "            df = pd.read_csv(p)\n",
        "            if \"node\" in df.columns:\n",
        "                print(f\"✅ Loaded df_clusters from: {p}  shape={df.shape}\")\n",
        "                return df\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "if \"df_clusters\" not in globals():\n",
        "    df_tmp = _try_load_df_clusters()\n",
        "    if df_tmp is not None:\n",
        "        df_clusters = df_tmp\n",
        "\n",
        "# If still missing, compute minimal labels now (KMeans + Louvain + optional Leiden)\n",
        "if \"df_clusters\" not in globals():\n",
        "    print(\"⚠️ df_clusters not found on disk; computing cluster labels on-the-fly...\")\n",
        "\n",
        "    import torch\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    def to_numpy(z):\n",
        "        if isinstance(z, np.ndarray): return z\n",
        "        if isinstance(z, torch.Tensor): return z.detach().cpu().numpy()\n",
        "        return np.asarray(z)\n",
        "\n",
        "    Z = to_numpy(z_train)\n",
        "    assert Z.shape[0] == N, f\"z_train rows ({Z.shape[0]}) != N ({N}).\"\n",
        "\n",
        "    df_clusters = pd.DataFrame({\"node\": np.arange(N, dtype=int)})\n",
        "\n",
        "    K = int(best_K) if \"best_K\" in globals() else 15\n",
        "    SEED0 = int(SEED) if \"SEED\" in globals() else 0\n",
        "    km = KMeans(n_clusters=K, n_init=10, random_state=SEED0)\n",
        "    df_clusters[\"kmeans_cluster\"] = km.fit_predict(Z)\n",
        "    print(f\"✅ Computed kmeans_cluster (K={K})\")\n",
        "\n",
        "    # Louvain\n",
        "    try:\n",
        "        import community.community_louvain as community_louvain\n",
        "        part = community_louvain.best_partition(Gnx, random_state=SEED0)\n",
        "        lv = np.array([part[i] for i in range(N)], dtype=int)\n",
        "        print(\"✅ Computed louvain_train (python-louvain)\")\n",
        "    except Exception:\n",
        "        from networkx.algorithms.community import louvain_communities\n",
        "        comms = louvain_communities(Gnx, seed=SEED0)\n",
        "        lv = np.zeros(N, dtype=int)\n",
        "        for cid, nodes in enumerate(comms):\n",
        "            lv[np.array(list(nodes), dtype=int)] = cid\n",
        "        print(\"✅ Computed louvain_train (networkx)\")\n",
        "    df_clusters[\"louvain_train\"] = lv\n",
        "\n",
        "    # Leiden optional\n",
        "    try:\n",
        "        import igraph as ig\n",
        "        import leidenalg\n",
        "        edges = list(Gnx.edges())\n",
        "        g = ig.Graph(n=N, edges=edges, directed=False)\n",
        "        part = leidenalg.find_partition(g, leidenalg.RBConfigurationVertexPartition, seed=SEED0)\n",
        "        ld = np.zeros(N, dtype=int)\n",
        "        for cid, nodes in enumerate(part):\n",
        "            ld[np.array(list(nodes), dtype=int)] = cid\n",
        "        df_clusters[\"leiden_train\"] = ld\n",
        "        print(\"✅ Computed leiden_train\")\n",
        "    except Exception as e:\n",
        "        print(\"Leiden not available (ok):\", e)\n",
        "\n",
        "assert \"node\" in df_clusters.columns, \"df_clusters must contain column 'node'.\"\n",
        "\n",
        "# ------------------------------------\n",
        "# (A) Stability of community detection\n",
        "# ------------------------------------\n",
        "STAB_SEEDS = [0, 1, 2, 3, 4]\n",
        "METHOD = \"leiden\"  # 'leiden' or 'louvain'\n",
        "print(\"Stability method:\", METHOD, \"| seeds:\", STAB_SEEDS)\n",
        "\n",
        "labels_list = []\n",
        "used_seeds = []\n",
        "\n",
        "if METHOD.lower() == \"leiden\":\n",
        "    try:\n",
        "        import igraph as ig\n",
        "        import leidenalg\n",
        "        edges = list(Gnx.edges())\n",
        "        g = ig.Graph(n=N, edges=edges, directed=False)\n",
        "        for sd in STAB_SEEDS:\n",
        "            part = leidenalg.find_partition(g, leidenalg.RBConfigurationVertexPartition, seed=int(sd))\n",
        "            lab = np.zeros(N, dtype=int)\n",
        "            for cid, nodes in enumerate(part):\n",
        "                lab[np.array(list(nodes), dtype=int)] = cid\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "    except Exception as e:\n",
        "        print(\"Leiden unavailable, falling back to Louvain:\", e)\n",
        "        METHOD = \"louvain\"\n",
        "\n",
        "if METHOD.lower() == \"louvain\":\n",
        "    try:\n",
        "        import community.community_louvain as community_louvain\n",
        "        for sd in STAB_SEEDS:\n",
        "            part = community_louvain.best_partition(Gnx, random_state=int(sd))\n",
        "            lab = np.array([part[i] for i in range(N)], dtype=int)\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "    except Exception as e:\n",
        "        print(\"python-louvain not available, using NetworkX louvain_communities:\", e)\n",
        "        from networkx.algorithms.community import louvain_communities\n",
        "        for sd in STAB_SEEDS:\n",
        "            comms = louvain_communities(Gnx, seed=int(sd))\n",
        "            lab = np.zeros(N, dtype=int)\n",
        "            for cid, nodes in enumerate(comms):\n",
        "                lab[np.array(list(nodes), dtype=int)] = cid\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "\n",
        "assert len(labels_list) >= 2, \"Need at least 2 partitions to compute stability.\"\n",
        "\n",
        "rows = []\n",
        "for i in range(len(labels_list)):\n",
        "    for j in range(i+1, len(labels_list)):\n",
        "        ari = adjusted_rand_score(labels_list[i], labels_list[j])\n",
        "        ami = adjusted_mutual_info_score(labels_list[i], labels_list[j], average_method=\"arithmetic\")\n",
        "        rows.append({\"seed_i\": used_seeds[i], \"seed_j\": used_seeds[j], \"ARI\": ari, \"AMI\": ami})\n",
        "\n",
        "df_pair = pd.DataFrame(rows)\n",
        "display(df_pair.head())\n",
        "\n",
        "df_sum = df_pair[[\"ARI\",\"AMI\"]].agg([\"mean\",\"std\"]).T.reset_index().rename(columns={\"index\":\"metric\"})\n",
        "display(df_sum)\n",
        "\n",
        "df_pair.to_csv(\"clustering_stability_pairwise.csv\", index=False)\n",
        "df_sum.to_csv(\"clustering_stability_summary.csv\", index=False)\n",
        "print(\"Saved: clustering_stability_pairwise.csv\")\n",
        "print(\"Saved: clustering_stability_summary.csv\")\n",
        "\n",
        "# ------------------------------------\n",
        "# (B) GNN-based clustering validity (intra vs inter AUC)\n",
        "# ------------------------------------\n",
        "import torch\n",
        "\n",
        "def to_numpy(z):\n",
        "    if isinstance(z, np.ndarray): return z\n",
        "    if isinstance(z, torch.Tensor): return z.detach().cpu().numpy()\n",
        "    return np.asarray(z)\n",
        "\n",
        "Z = to_numpy(z_train)\n",
        "assert Z.shape[0] == N, f\"z_train rows ({Z.shape[0]}) != N ({N}).\"\n",
        "\n",
        "Zt = torch.tensor(Z, dtype=torch.float32)\n",
        "model_cpu = model.to(\"cpu\").eval()\n",
        "\n",
        "def score_pairs(u, v, batch=200000):\n",
        "    u = np.asarray(u, dtype=np.int64)\n",
        "    v = np.asarray(v, dtype=np.int64)\n",
        "    out = np.empty(len(u), dtype=np.float32)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(u), batch):\n",
        "            uu = torch.tensor(u[i:i+batch], dtype=torch.long)\n",
        "            vv = torch.tensor(v[i:i+batch], dtype=torch.long)\n",
        "            eidx = torch.stack([uu, vv], dim=0)\n",
        "            logits = model_cpu.dec(Zt, eidx).view(-1)\n",
        "            out[i:i+batch] = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def sample_pairs_from_labels(labels, n_pairs=40000, rng=None):\n",
        "    rng = np.random.default_rng(0) if rng is None else rng\n",
        "    labels = np.asarray(labels, dtype=int)\n",
        "\n",
        "    clusters = {}\n",
        "    for i, l in enumerate(labels):\n",
        "        clusters.setdefault(int(l), []).append(i)\n",
        "\n",
        "    cl_ids = [k for k, v in clusters.items() if len(v) >= 2]\n",
        "    if len(cl_ids) == 0:\n",
        "        return None\n",
        "\n",
        "    u_in, v_in = [], []\n",
        "    while len(u_in) < n_pairs:\n",
        "        cid = int(rng.choice(cl_ids))\n",
        "        nodes = clusters[cid]\n",
        "        a, b = rng.choice(nodes, size=2, replace=False)\n",
        "        u_in.append(a); v_in.append(b)\n",
        "\n",
        "    u_out, v_out = [], []\n",
        "    while len(u_out) < n_pairs:\n",
        "        a = int(rng.integers(0, len(labels)))\n",
        "        b = int(rng.integers(0, len(labels)))\n",
        "        if labels[a] != labels[b]:\n",
        "            u_out.append(a); v_out.append(b)\n",
        "\n",
        "    return np.array(u_in), np.array(v_in), np.array(u_out), np.array(v_out)\n",
        "\n",
        "cluster_cols = [c for c in [\"leiden_train\",\"louvain_train\",\"kmeans_cluster\",\"louvain_pred\"] if c in df_clusters.columns]\n",
        "print(\"Clusterings to score:\", cluster_cols)\n",
        "\n",
        "dfc = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").set_index(\"node\")\n",
        "\n",
        "valid_rows = []\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "for col in cluster_cols:\n",
        "    lab = dfc[col].reindex(np.arange(N)).values\n",
        "    if np.any(pd.isna(lab)):\n",
        "        print(f\"Skipping {col}: missing labels for some nodes.\")\n",
        "        continue\n",
        "\n",
        "    samp = sample_pairs_from_labels(lab, n_pairs=40000, rng=rng)\n",
        "    if samp is None:\n",
        "        print(f\"Skipping {col}: no clusters with size>=2\")\n",
        "        continue\n",
        "\n",
        "    u_in, v_in, u_out, v_out = samp\n",
        "    p_in  = score_pairs(u_in,  v_in)\n",
        "    p_out = score_pairs(u_out, v_out)\n",
        "\n",
        "    y = np.concatenate([np.ones_like(p_in), np.zeros_like(p_out)])\n",
        "    p = np.concatenate([p_in, p_out])\n",
        "\n",
        "    auc = roc_auc_score(y, p)\n",
        "    valid_rows.append({\n",
        "        \"clustering\": col,\n",
        "        \"n_pairs_each\": int(len(p_in)),\n",
        "        \"auc_intra_vs_inter\": float(auc),\n",
        "        \"mean_p_intra\": float(p_in.mean()),\n",
        "        \"mean_p_inter\": float(p_out.mean()),\n",
        "        \"gap\": float(p_in.mean() - p_out.mean()),\n",
        "    })\n",
        "    print(f\"[{col}] AUC={auc:.4f} | mean_intra={p_in.mean():.4f} | mean_inter={p_out.mean():.4f} | gap={p_in.mean()-p_out.mean():.4f}\")\n",
        "\n",
        "df_valid = pd.DataFrame(valid_rows).sort_values(\"auc_intra_vs_inter\", ascending=False)\n",
        "display(df_valid)\n",
        "\n",
        "df_valid.to_csv(\"gnn_cluster_validity_scores.csv\", index=False)\n",
        "print(\"Saved: gnn_cluster_validity_scores.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f509861c",
      "metadata": {
        "id": "f509861c"
      },
      "source": [
        "### 11A) Resolution sweep (Leiden/Louvain)  \n",
        "Runs only if `RUN_CLUSTER_SWEEP=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3704424a",
      "metadata": {
        "id": "3704424a"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11A) Resolution sweep for community detection (Leiden/Louvain)  [paper add-on]\n",
        "# Robust version:\n",
        "# - Auto-build G_train if missing\n",
        "# - Defines compute_conductance if missing\n",
        "# Saves:\n",
        "#  - clustering_resolution_sweep.csv\n",
        "#  - clustering_resolution_sweep.png\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "if not RUN_CLUSTER_SWEEP:\n",
        "    print(\"RUN_CLUSTER_SWEEP=False (skip). Set RUN_CLUSTER_SWEEP=True to run.\")\n",
        "else:\n",
        "    assert \"data_train\" in globals(), \"Need data_train (RandomLinkSplit). Run split section first.\"\n",
        "\n",
        "    # ---- Auto-build G_train if missing ----\n",
        "    if \"G_train\" not in globals():\n",
        "        N_auto = int(data_train.num_nodes)\n",
        "        ei = data_train.edge_index.detach().cpu().numpy()\n",
        "        G_train = nx.Graph()\n",
        "        G_train.add_nodes_from(range(N_auto))\n",
        "        G_train.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "        print(\"✅ Auto-built G_train:\", G_train.number_of_nodes(), \"nodes,\", G_train.number_of_edges(), \"edges\")\n",
        "\n",
        "    # ---- Define compute_conductance if missing ----\n",
        "    if \"compute_conductance\" not in globals():\n",
        "        def compute_conductance(G, clusters):\n",
        "            degG = dict(G.degree())\n",
        "            neigh = {u: set(G.neighbors(u)) for u in G.nodes()}\n",
        "            all_nodes = set(G.nodes())\n",
        "\n",
        "            def vol(S):\n",
        "                return sum(degG[u] for u in S)\n",
        "\n",
        "            conds = []\n",
        "            for C in clusters:\n",
        "                C = set(C)\n",
        "                if len(C) == 0 or len(C) == len(all_nodes):\n",
        "                    continue\n",
        "                cut = 0\n",
        "                for u in C:\n",
        "                    cut += len(neigh[u] - C)\n",
        "                vC = vol(C)\n",
        "                vNot = vol(all_nodes - C)\n",
        "                denom = max(1e-9, min(vC, vNot))\n",
        "                conds.append(cut / denom)\n",
        "            return float(np.mean(conds)) if conds else np.nan\n",
        "\n",
        "        print(\"✅ Defined compute_conductance() locally (was missing).\")\n",
        "\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "    N = int(data_train.num_nodes)\n",
        "    Gnx = G_train\n",
        "\n",
        "    RES_LIST = [0.5, 0.8, 1.0, 1.2, 1.5, 2.0]\n",
        "    SEED0 = int(SEED) if \"SEED\" in globals() else 0\n",
        "    rows = []\n",
        "\n",
        "    def run_louvain(resolution):\n",
        "        # try python-louvain first\n",
        "        try:\n",
        "            import community.community_louvain as community_louvain\n",
        "            part = community_louvain.best_partition(Gnx, random_state=SEED0, resolution=float(resolution))\n",
        "            labels = np.array([part[i] for i in range(N)], dtype=int)\n",
        "            comm_ids = sorted(set(part.values()))\n",
        "            clusters = [[n for n, c in part.items() if c == cid] for cid in comm_ids]\n",
        "            return labels, clusters, \"python-louvain\"\n",
        "        except Exception:\n",
        "            from networkx.algorithms.community import louvain_communities\n",
        "            comms = louvain_communities(Gnx, seed=SEED0, resolution=float(resolution))\n",
        "            labels = np.zeros(N, dtype=int)\n",
        "            for cid, nodes in enumerate(comms):\n",
        "                labels[np.array(list(nodes), dtype=int)] = cid\n",
        "            clusters = [list(nodes) for nodes in comms]\n",
        "            return labels, clusters, \"networkx\"\n",
        "\n",
        "    def run_leiden(resolution):\n",
        "        import igraph as ig\n",
        "        import leidenalg\n",
        "        edges = list(Gnx.edges())\n",
        "        g = ig.Graph(n=N, edges=edges, directed=False)\n",
        "        part = leidenalg.find_partition(\n",
        "            g,\n",
        "            leidenalg.RBConfigurationVertexPartition,\n",
        "            seed=SEED0,\n",
        "            resolution_parameter=float(resolution),\n",
        "        )\n",
        "        labels = np.zeros(N, dtype=int)\n",
        "        for cid, nodes in enumerate(part):\n",
        "            labels[np.array(list(nodes), dtype=int)] = cid\n",
        "        clusters = [list(nodes) for nodes in part]\n",
        "        return labels, clusters, \"leidenalg\"\n",
        "\n",
        "    # detect Leiden availability\n",
        "    have_leiden = True\n",
        "    try:\n",
        "        import igraph as ig  # noqa\n",
        "        import leidenalg     # noqa\n",
        "    except Exception:\n",
        "        have_leiden = False\n",
        "        print(\"ℹ️ Leiden not available; using Louvain sweep instead.\")\n",
        "\n",
        "    for res in RES_LIST:\n",
        "        if have_leiden:\n",
        "            labels, clusters, impl = run_leiden(res)\n",
        "            meth = \"leiden\"\n",
        "        else:\n",
        "            labels, clusters, impl = run_louvain(res)\n",
        "            meth = \"louvain\"\n",
        "\n",
        "        mod = nx_modularity(Gnx, clusters)\n",
        "        cond = compute_conductance(Gnx, clusters)\n",
        "        sizes = np.array([len(c) for c in clusters], dtype=int)\n",
        "\n",
        "        rows.append({\n",
        "            \"method\": meth,\n",
        "            \"impl\": impl,\n",
        "            \"resolution\": float(res),\n",
        "            \"n_clusters\": int(len(clusters)),\n",
        "            \"modularity\": float(mod),\n",
        "            \"avg_conductance\": float(cond),\n",
        "            \"min_size\": int(sizes.min()) if len(sizes) else 0,\n",
        "            \"median_size\": float(np.median(sizes)) if len(sizes) else 0,\n",
        "            \"max_size\": int(sizes.max()) if len(sizes) else 0,\n",
        "        })\n",
        "        print(f\"[{meth}] res={res:.2f} | k={len(clusters)} | Q={mod:.4f} | cond={cond:.4f}\")\n",
        "\n",
        "    df_sweep = pd.DataFrame(rows)\n",
        "    display(df_sweep)\n",
        "\n",
        "    df_sweep.to_csv(\"clustering_resolution_sweep.csv\", index=False)\n",
        "    print(\"Saved: clustering_resolution_sweep.csv\")\n",
        "\n",
        "    # plot modularity + conductance vs resolution\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(df_sweep[\"resolution\"], df_sweep[\"modularity\"], marker=\"o\")\n",
        "    plt.xlabel(\"Resolution\")\n",
        "    plt.ylabel(\"Modularity (train graph)\")\n",
        "    plt.title(\"Community detection resolution sweep\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"clustering_resolution_sweep.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(\"Saved: clustering_resolution_sweep.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138be481",
      "metadata": {
        "id": "138be481"
      },
      "source": [
        "### 11C) Per-cluster cohesion scores (decoder-based) + export  \n",
        "Runs only if `RUN_CLUSTER_COHESION=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99513e9",
      "metadata": {
        "id": "e99513e9"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11C) Per-cluster cohesion scores (decoder-based)  [paper add-on]\n",
        "# For the chosen clustering (default: leiden_train if exists):\n",
        "# - cohesion_intra: mean decoder-prob for sampled intra-cluster pairs\n",
        "# - cohesion_inter: mean decoder-prob for sampled inter-cluster pairs\n",
        "# - cohesion_gap = intra - inter\n",
        "# Saves: cluster_cohesion_scores.csv\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "if not RUN_CLUSTER_COHESION:\n",
        "    print(\"RUN_CLUSTER_COHESION=False (skip). Set RUN_CLUSTER_COHESION=True to run.\")\n",
        "else:\n",
        "    assert \"df_clusters\" in globals(), \"Need df_clusters from Section 11.\"\n",
        "    assert \"z_train\" in globals(), \"Need z_train.\"\n",
        "    assert \"model\" in globals(), \"Need trained model.\"\n",
        "\n",
        "    # choose cluster labels\n",
        "    for _col in [\"leiden_train\",\"louvain_train\",\"kmeans_cluster\"]:\n",
        "        if _col in df_clusters.columns:\n",
        "            CLUSTER_COL = _col\n",
        "            break\n",
        "    print(\"Using cluster labels for cohesion:\", CLUSTER_COL)\n",
        "\n",
        "    N = int(data_train.num_nodes)\n",
        "    dfc = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").set_index(\"node\")\n",
        "    labels = dfc[CLUSTER_COL].reindex(np.arange(N)).values\n",
        "    assert not np.any(pd.isna(labels)), \"Missing labels for some nodes.\"\n",
        "\n",
        "    # embeddings\n",
        "    def to_numpy(z):\n",
        "        if isinstance(z, np.ndarray): return z\n",
        "        if isinstance(z, torch.Tensor): return z.detach().cpu().numpy()\n",
        "        return np.asarray(z)\n",
        "    Z = to_numpy(z_train)\n",
        "    assert Z.shape[0] == N\n",
        "\n",
        "    Zt = torch.tensor(Z, dtype=torch.float32)\n",
        "    model_cpu = model.to(\"cpu\").eval()\n",
        "\n",
        "    def score_pairs(u, v):\n",
        "        uu = torch.tensor(u, dtype=torch.long)\n",
        "        vv = torch.tensor(v, dtype=torch.long)\n",
        "        eidx = torch.stack([uu, vv], dim=0)\n",
        "        with torch.no_grad():\n",
        "            logits = model_cpu.dec(Zt, eidx).view(-1)\n",
        "            p = torch.sigmoid(logits).cpu().numpy().astype(float)\n",
        "        return p\n",
        "\n",
        "    rng = np.random.default_rng(0)\n",
        "\n",
        "    # cluster sizes + filter\n",
        "    MIN_SIZE = 20\n",
        "    MAX_SIZE = 500\n",
        "    N_SAMP = 3000  # per cluster (increase for smoother estimates)\n",
        "\n",
        "    clusters = {}\n",
        "    for i, cid in enumerate(labels.astype(int)):\n",
        "        clusters.setdefault(int(cid), []).append(i)\n",
        "\n",
        "    rows = []\n",
        "    for cid, nodes in clusters.items():\n",
        "        if len(nodes) < MIN_SIZE or len(nodes) > MAX_SIZE:\n",
        "            continue\n",
        "\n",
        "        # intra samples\n",
        "        u_in = []; v_in = []\n",
        "        for _ in range(N_SAMP):\n",
        "            a, b = rng.choice(nodes, size=2, replace=False)\n",
        "            u_in.append(int(a)); v_in.append(int(b))\n",
        "\n",
        "        # inter samples: one in cluster, one outside\n",
        "        outside = np.where(labels.astype(int) != int(cid))[0]\n",
        "        if len(outside) < 1:\n",
        "            continue\n",
        "        u_out = []; v_out = []\n",
        "        for _ in range(N_SAMP):\n",
        "            a = int(rng.choice(nodes))\n",
        "            b = int(rng.choice(outside))\n",
        "            u_out.append(a); v_out.append(b)\n",
        "\n",
        "        p_in = score_pairs(u_in, v_in)\n",
        "        p_out = score_pairs(u_out, v_out)\n",
        "\n",
        "        rows.append({\n",
        "            \"cluster_id\": int(cid),\n",
        "            \"cluster_size\": int(len(nodes)),\n",
        "            \"cohesion_intra\": float(np.mean(p_in)),\n",
        "            \"cohesion_inter\": float(np.mean(p_out)),\n",
        "            \"cohesion_gap\": float(np.mean(p_in) - np.mean(p_out)),\n",
        "        })\n",
        "\n",
        "    df_coh = pd.DataFrame(rows).sort_values(\"cohesion_gap\", ascending=False)\n",
        "    display(df_coh.head(20))\n",
        "\n",
        "    df_coh.to_csv(\"cluster_cohesion_scores.csv\", index=False)\n",
        "    print(\"Saved: cluster_cohesion_scores.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hTl6Gk1fbWGN",
      "metadata": {
        "id": "hTl6Gk1fbWGN"
      },
      "source": [
        "## 13) OPTIONAL: INDUCTIVE / OOD NODE SPLIT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0iISqDdtbWGN",
      "metadata": {
        "id": "0iISqDdtbWGN"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 13) OPTIONAL: INDUCTIVE / OOD NODE SPLIT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cy7QoMHgbWGN",
      "metadata": {
        "id": "cy7QoMHgbWGN"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bj409Gtbw5gj",
      "metadata": {
        "id": "bj409Gtbw5gj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# reproducibility seed (αν δεν το έχεις ήδη)\n",
        "SEED = globals().get(\"SEED\", 42)\n",
        "\n",
        "def to_numpy_embeddings(z):\n",
        "    \"\"\"\n",
        "    Accepts torch.Tensor / numpy array / (z, ...) tuples (π.χ. VGAE returns tuple)\n",
        "    and returns a NumPy array of shape [N, d].\n",
        "    \"\"\"\n",
        "    # Αν έρθει tuple/list (π.χ. (z, mu, logvar)), κράτα το πρώτο\n",
        "    if isinstance(z, (tuple, list)):\n",
        "        z = z[0]\n",
        "\n",
        "    # ήδη numpy\n",
        "    if isinstance(z, np.ndarray):\n",
        "        return z\n",
        "\n",
        "    # torch tensor\n",
        "    try:\n",
        "        import torch\n",
        "        if isinstance(z, torch.Tensor):\n",
        "            return z.detach().cpu().numpy()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # fallback\n",
        "    return np.asarray(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AW0SCgaybWGN",
      "metadata": {
        "id": "AW0SCgaybWGN"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11) CLUSTERING / COMMUNITIES (paper-ready + robust)\n",
        "# - Works with z_train as NumPy or torch\n",
        "# - Runs KMeans on embeddings + Louvain/Leiden on graphs\n",
        "# - Optionally also communities on predicted (Top edges) graph\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "# ---- Required objects ----\n",
        "assert \"data_train\" in globals(), \"Missing data_train. Run the train/val/test split cell first.\"\n",
        "assert \"z_train\" in globals(), \"Missing z_train. Train a GNN first (we need train-graph embeddings).\"\n",
        "\n",
        "# ---- Embeddings ----\n",
        "Z = to_numpy_embeddings(z_train)\n",
        "N = int(data_train.num_nodes)\n",
        "assert Z.shape[0] == N, f\"Embedding rows ({Z.shape[0]}) must match num_nodes ({N}).\"\n",
        "\n",
        "print(\"Embeddings:\", Z.shape, \"| num_nodes:\", N)\n",
        "\n",
        "# ---- Build TRAIN graph (all nodes included) ----\n",
        "G_train = nx.Graph()\n",
        "G_train.add_nodes_from(range(N))\n",
        "ei = data_train.edge_index.detach().cpu().numpy()\n",
        "G_train.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "print(\"Train graph:\", G_train.number_of_nodes(), \"nodes,\", G_train.number_of_edges(), \"edges\")\n",
        "\n",
        "def compute_conductance(G, clusters):\n",
        "    degG = dict(G.degree())\n",
        "    neigh = {u: set(G.neighbors(u)) for u in G.nodes()}\n",
        "    all_nodes = set(G.nodes())\n",
        "\n",
        "    def vol(S):\n",
        "        return sum(degG[u] for u in S)\n",
        "\n",
        "    conds = []\n",
        "    for C in clusters:\n",
        "        C = set(C)\n",
        "        if len(C) == 0 or len(C) == len(all_nodes):\n",
        "            continue\n",
        "        cut = 0\n",
        "        for u in C:\n",
        "            cut += len(neigh[u] - C)\n",
        "        vC = vol(C)\n",
        "        vNot = vol(all_nodes - C)\n",
        "        denom = max(1e-9, min(vC, vNot))\n",
        "        conds.append(cut / denom)\n",
        "    return float(np.mean(conds)) if conds else np.nan\n",
        "\n",
        "# =========================================================\n",
        "# (A) KMeans on embeddings: sweep K and pick best by graph modularity\n",
        "# =========================================================\n",
        "K_LIST = [10, 15, 20, 30, 40]\n",
        "kmeans_rows = []\n",
        "kmeans_labels_byK = {}\n",
        "\n",
        "for K in K_LIST:\n",
        "    km = KMeans(n_clusters=K, n_init=10, random_state=SEED)\n",
        "    lab = km.fit_predict(Z)\n",
        "    kmeans_labels_byK[K] = lab\n",
        "    clusters_km = [np.where(lab == c)[0].tolist() for c in range(K)]\n",
        "    mod = nx_modularity(G_train, clusters_km)\n",
        "    cond = compute_conductance(G_train, clusters_km)\n",
        "    sizes = np.array([len(c) for c in clusters_km], dtype=int)\n",
        "    kmeans_rows.append({\n",
        "        \"K\": K,\n",
        "        \"modularity_train\": float(mod),\n",
        "        \"avg_conductance\": float(cond),\n",
        "        \"min_cluster\": int(sizes.min()),\n",
        "        \"median_cluster\": float(np.median(sizes)),\n",
        "        \"max_cluster\": int(sizes.max()),\n",
        "    })\n",
        "    print(f\"[KMeans] K={K:>2} | modularity={mod:.4f} | conductance={cond:.4f} | size(min/med/max)={sizes.min()}/{np.median(sizes):.0f}/{sizes.max()}\")\n",
        "\n",
        "df_kmeans_sweep = pd.DataFrame(kmeans_rows).sort_values(\"modularity_train\", ascending=False)\n",
        "display(df_kmeans_sweep)\n",
        "\n",
        "# Pick K with best modularity, but avoid extreme imbalance (simple penalty)\n",
        "df_kmeans_sweep[\"imbalance\"] = df_kmeans_sweep[\"max_cluster\"] / np.maximum(1.0, df_kmeans_sweep[\"median_cluster\"])\n",
        "df_kmeans_sweep[\"score\"] = df_kmeans_sweep[\"modularity_train\"] - 0.01*df_kmeans_sweep[\"avg_conductance\"] - 0.001*df_kmeans_sweep[\"imbalance\"]\n",
        "best_K = int(df_kmeans_sweep.sort_values(\"score\", ascending=False).iloc[0][\"K\"])\n",
        "k_labels = kmeans_labels_byK[best_K]\n",
        "print(\"✅ Selected K for KMeans:\", best_K)\n",
        "\n",
        "# =========================================================\n",
        "# (B) Louvain / Leiden on TRAIN graph (structure-only communities)\n",
        "# =========================================================\n",
        "# Louvain\n",
        "try:\n",
        "    import community.community_louvain as community_louvain\n",
        "    part_lv = community_louvain.best_partition(G_train, random_state=SEED)\n",
        "    comm_ids = sorted(set(part_lv.values()))\n",
        "    lv_labels = np.array([part_lv[i] for i in range(N)], dtype=int)\n",
        "    clusters_lv = [[n for n, c in part_lv.items() if c == cid] for cid in comm_ids]\n",
        "    mod_lv = nx_modularity(G_train, clusters_lv)\n",
        "    cond_lv = compute_conductance(G_train, clusters_lv)\n",
        "    print(f\"[Louvain(train)] communities={len(clusters_lv)} | modularity={mod_lv:.4f} | conductance={cond_lv:.4f}\")\n",
        "except Exception as e:\n",
        "    part_lv = None\n",
        "    lv_labels = None\n",
        "    print(\"Louvain not available:\", e)\n",
        "\n",
        "# Leiden (optional)\n",
        "ld_labels = None\n",
        "try:\n",
        "    import igraph as ig\n",
        "    import leidenalg\n",
        "    edges = list(G_train.edges())\n",
        "    g = ig.Graph(n=N, edges=edges, directed=False)\n",
        "    part_ld = leidenalg.find_partition(g, leidenalg.RBConfigurationVertexPartition, seed=SEED)\n",
        "    ld_labels = np.zeros(N, dtype=int)\n",
        "    for cid, nodes in enumerate(part_ld):\n",
        "        ld_labels[np.array(list(nodes), dtype=int)] = cid\n",
        "    clusters_ld = [list(nodes) for nodes in part_ld]\n",
        "    mod_ld = nx_modularity(G_train, clusters_ld)\n",
        "    cond_ld = compute_conductance(G_train, clusters_ld)\n",
        "    print(f\"[Leiden(train)] communities={len(clusters_ld)} | modularity={mod_ld:.4f} | conductance={cond_ld:.4f}\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# =========================================================\n",
        "# (C) Communities on PREDICTED graph (Top edges)  [often more biology-friendly]\n",
        "# Fix: avoid over-strict probability thresholds that create (almost) isolated nodes.\n",
        "#      We keep a reasonably large Top-E set and run WEIGHTED Louvain.\n",
        "# =========================================================\n",
        "pred_labels = None\n",
        "if \"df_top\" in globals() and {\"u\",\"v\"}.issubset(df_top.columns):\n",
        "    prob_col = \"prob_mean\" if \"prob_mean\" in df_top.columns else (\"prob\" if \"prob\" in df_top.columns else None)\n",
        "\n",
        "    if prob_col is None:\n",
        "        print(\"Predicted-graph: no probability column found (expected prob_mean or prob). Skipping.\")\n",
        "    else:\n",
        "        dfp = df_top.dropna(subset=[prob_col]).copy()\n",
        "        dfp = dfp.sort_values(prob_col, ascending=False)\n",
        "\n",
        "        # Keep enough edges so the graph is connected enough for community detection\n",
        "        TOP_EDGES = min(200_000, len(dfp))  # increase if you have memory/time\n",
        "        dfp = dfp.head(TOP_EDGES)\n",
        "\n",
        "        print(f\"Predicted-graph edges kept: {len(dfp)} | min {prob_col} in kept: {float(dfp[prob_col].min()):.4f}\")\n",
        "\n",
        "        G_pred = nx.Graph()\n",
        "        G_pred.add_nodes_from(range(N))\n",
        "\n",
        "        # Weighted edges (weight = predicted probability)\n",
        "        edges_w = [(int(u), int(v), float(w)) for u, v, w in dfp[[\"u\",\"v\",prob_col]].values]\n",
        "        G_pred.add_weighted_edges_from(edges_w, weight=\"weight\")\n",
        "\n",
        "        print(\"Predicted graph:\", G_pred.number_of_nodes(), \"nodes,\", G_pred.number_of_edges(), \"edges\")\n",
        "\n",
        "        try:\n",
        "            import community.community_louvain as community_louvain\n",
        "            part_pred = community_louvain.best_partition(G_pred, random_state=SEED, weight=\"weight\")\n",
        "            pred_labels = np.array([part_pred.get(i, -1) for i in range(N)], dtype=int)\n",
        "\n",
        "            # quick sanity check: if most clusters are singletons, don't use it downstream\n",
        "            _sizes = pd.Series(pred_labels[pred_labels >= 0]).value_counts()\n",
        "            if len(_sizes) == 0:\n",
        "                print(\"[Louvain(pred)] produced no communities. Skipping louvain_pred.\")\n",
        "                pred_labels = None\n",
        "            else:\n",
        "                print(\"[Louvain(pred)] #communities:\", int(_sizes.shape[0]),\n",
        "                      \"| cluster size median:\", float(_sizes.median()),\n",
        "                      \"| max:\", int(_sizes.max()))\n",
        "                if _sizes.median() <= 1 and _sizes.max() < 20:\n",
        "                    print(\"⚠️ Predicted-graph communities are mostly singletons (graph too sparse). \"\n",
        "                          \"We will NOT store louvain_pred; prefer louvain_train/leiden/kmeans for GO.\")\n",
        "                    pred_labels = None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Predicted-graph Louvain failed:\", e)\n",
        "\n",
        "# =========================================================\n",
        "# (D) t-SNE plot (paper-friendly)\n",
        "# =========================================================\n",
        "tsne = TSNE(n_components=2, random_state=SEED, perplexity=30, init=\"pca\")\n",
        "Z2 = tsne.fit_transform(Z)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(Z2[:, 0], Z2[:, 1], c=k_labels, s=6)\n",
        "plt.title(f\"t-SNE of embeddings (colored by KMeans, K={best_K})\")\n",
        "plt.xlabel(\"t-SNE-1\"); plt.ylabel(\"t-SNE-2\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"tsne_embeddings_kmeans.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Cluster size plot\n",
        "sizes = pd.Series(k_labels).value_counts().sort_index()\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(sizes.index.astype(str), sizes.values)\n",
        "plt.xlabel(\"Cluster id (KMeans)\")\n",
        "plt.ylabel(\"Size (#nodes)\")\n",
        "plt.title(\"Cluster sizes (KMeans on embeddings)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"cluster_sizes_kmeans.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# =========================================================\n",
        "# (E) Save cluster assignments\n",
        "# =========================================================\n",
        "df_clusters = pd.DataFrame({\"node\": np.arange(N), \"kmeans_cluster\": k_labels})\n",
        "if lv_labels is not None:\n",
        "    df_clusters[\"louvain_train\"] = lv_labels\n",
        "if ld_labels is not None:\n",
        "    df_clusters[\"leiden_train\"] = ld_labels\n",
        "if pred_labels is not None:\n",
        "    df_clusters[\"louvain_pred\"] = pred_labels\n",
        "\n",
        "if \"nodes_annot\" in globals():\n",
        "    cols = [c for c in [\"node\",\"string_id\",\"gene_final\"] if c in nodes_annot.columns]\n",
        "    df_clusters = df_clusters.merge(nodes_annot[cols], on=\"node\", how=\"left\")\n",
        "\n",
        "df_clusters.to_csv(\"embedding_clusters.csv\", index=False)\n",
        "print(\"Saved: embedding_clusters.csv\")\n",
        "display(df_clusters.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A_WA8XlbXhBb",
      "metadata": {
        "id": "A_WA8XlbXhBb"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30D-bio) Register Edge-MLP embedding clustering in df_clusters for CORUM/GO/Disease\n",
        "# Safe: only ADDS a new column; does not overwrite existing cluster columns\n",
        "# Requires: labels_mlp (from 30D) and df_clusters with a node index + gene_final mapping\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "if \"labels_mlp\" in globals() and \"df_clusters\" in globals():\n",
        "    dfc = df_clusters.copy()\n",
        "    # ensure node column exists\n",
        "    if \"node\" not in dfc.columns:\n",
        "        # try to recover node index from index\n",
        "        dfc = dfc.reset_index().rename(columns={\"index\":\"node\"})\n",
        "    # align by node id (0..N-1)\n",
        "    lab = np.asarray(labels_mlp)\n",
        "    if lab.ndim != 1:\n",
        "        lab = lab.reshape(-1)\n",
        "    N = len(lab)\n",
        "    # keep only nodes that fit in [0,N)\n",
        "    ok = dfc[\"node\"].astype(int).between(0, N-1)\n",
        "    dfc.loc[ok, \"edge_mlp_kmeans\"] = dfc.loc[ok, \"node\"].astype(int).map(lambda i: int(lab[i]))\n",
        "    df_clusters = dfc\n",
        "    print(\"✅ Added df_clusters['edge_mlp_kmeans'] from labels_mlp (N=\", N, \")\")\n",
        "    if \"gene_final\" not in df_clusters.columns:\n",
        "        print(\"⚠️ df_clusters has no gene_final. CORUM/GO/Disease steps need gene_final mapping.\")\n",
        "else:\n",
        "    print(\"🟦 Skipped: labels_mlp or df_clusters not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494373fd",
      "metadata": {
        "id": "494373fd"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30D-bio2) Ensure df_clusters has gene_final mapping (SAFE)\n",
        "# - Needed for CORUM/GO/Disease enrichment.\n",
        "# - Tries, in order:\n",
        "#   (1) nodes_annot[['node','gene_final']]\n",
        "#   (2) node2gene dict/list\n",
        "# Does NOT overwrite existing gene_final.\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "assert \"df_clusters\" in globals(), \"df_clusters missing\"\n",
        "\n",
        "df_clusters = df_clusters.copy()\n",
        "if \"node\" not in df_clusters.columns:\n",
        "    df_clusters = df_clusters.reset_index().rename(columns={\"index\":\"node\"})\n",
        "\n",
        "if \"gene_final\" in df_clusters.columns and df_clusters[\"gene_final\"].notna().any():\n",
        "    print(\"✅ gene_final already present in df_clusters\")\n",
        "else:\n",
        "    # (1) from nodes_annot\n",
        "    if \"nodes_annot\" in globals() and isinstance(nodes_annot, pd.DataFrame) and {\"node\",\"gene_final\"}.issubset(nodes_annot.columns):\n",
        "        m = nodes_annot[[\"node\",\"gene_final\"]].drop_duplicates(\"node\")\n",
        "        df_clusters = df_clusters.drop(columns=[c for c in [\"gene_final\"] if c in df_clusters.columns])\n",
        "        df_clusters = df_clusters.merge(m, on=\"node\", how=\"left\")\n",
        "        print(\"✅ gene_final added from nodes_annot\")\n",
        "    # (2) from node2gene\n",
        "    elif \"node2gene\" in globals() and node2gene is not None:\n",
        "        if isinstance(node2gene, dict):\n",
        "            df_clusters[\"gene_final\"] = df_clusters[\"node\"].map(lambda i: node2gene.get(int(i), None))\n",
        "        else:\n",
        "            arr = list(node2gene)\n",
        "            df_clusters[\"gene_final\"] = df_clusters[\"node\"].map(lambda i: arr[int(i)] if 0 <= int(i) < len(arr) else None)\n",
        "        print(\"✅ gene_final added from node2gene\")\n",
        "    else:\n",
        "        print(\"⚠️ Could not create gene_final (need nodes_annot or node2gene). CORUM/GO/Disease will skip.\")\n",
        "\n",
        "# write back\n",
        "globals()[\"df_clusters\"] = df_clusters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MMvxIk8ihbuc",
      "metadata": {
        "id": "MMvxIk8ihbuc"
      },
      "source": [
        "11B) Clustering stability (Leiden/Louvain) + GNN-based cluster validity score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y2Ade5OphObJ",
      "metadata": {
        "id": "Y2Ade5OphObJ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 11B) Clustering stability + GNN-based cluster validity (ML-oriented)\n",
        "# - Stability: pairwise ARI/AMI between partitions across random seeds\n",
        "# - Validity (GNN-based): how well the trained decoder separates intra-cluster vs inter-cluster pairs\n",
        "# Saves:\n",
        "#  - clustering_stability_pairwise.csv\n",
        "#  - clustering_stability_summary.csv\n",
        "#  - gnn_cluster_validity_scores.csv\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, roc_auc_score\n",
        "\n",
        "# -------------------------\n",
        "# Auto-build / auto-load dependencies\n",
        "# -------------------------\n",
        "\n",
        "# 1) Auto-build G_train if missing\n",
        "if \"G_train\" not in globals():\n",
        "    assert \"data_train\" in globals(), \"Missing data_train. Run the split/train cells first.\"\n",
        "    N_auto = int(data_train.num_nodes)\n",
        "    ei = data_train.edge_index.detach().cpu().numpy()\n",
        "    G_train = nx.Graph()\n",
        "    G_train.add_nodes_from(range(N_auto))\n",
        "    G_train.add_edges_from(list(zip(ei[0], ei[1])))\n",
        "    print(\"✅ Auto-built G_train:\", G_train.number_of_nodes(), \"nodes,\", G_train.number_of_edges(), \"edges\")\n",
        "\n",
        "# 2) Auto-load df_clusters if missing\n",
        "if \"df_clusters\" not in globals():\n",
        "    if os.path.exists(\"embedding_clusters.csv\"):\n",
        "        df_clusters = pd.read_csv(\"embedding_clusters.csv\")\n",
        "        print(\"✅ Loaded df_clusters from embedding_clusters.csv:\", df_clusters.shape)\n",
        "    else:\n",
        "        raise AssertionError(\"df_clusters not found. Run Section 11 (clustering) first (or ensure embedding_clusters.csv exists).\")\n",
        "\n",
        "# 3) Must-have objects\n",
        "assert \"z_train\" in globals(), \"Need embeddings z_train (from best GNN training).\"\n",
        "assert \"model\" in globals(), \"Need trained model (best).\"\n",
        "\n",
        "# Basic sanity for df_clusters\n",
        "assert \"node\" in df_clusters.columns, \"df_clusters must contain column 'node'.\"\n",
        "\n",
        "# -------------------------\n",
        "# Setup\n",
        "# -------------------------\n",
        "N = int(data_train.num_nodes) if \"data_train\" in globals() else int(G_train.number_of_nodes())\n",
        "Gnx = G_train\n",
        "\n",
        "# ---------- (A) STABILITY of graph community detection ----------\n",
        "STAB_SEEDS = [0, 1, 2, 3, 4]\n",
        "METHOD = \"leiden\"  # 'leiden' or 'louvain'\n",
        "print(\"Stability method:\", METHOD, \"| seeds:\", STAB_SEEDS)\n",
        "\n",
        "labels_list = []\n",
        "used_seeds = []\n",
        "\n",
        "# ---- Leiden stability (preferred) ----\n",
        "if METHOD.lower() == \"leiden\":\n",
        "    try:\n",
        "        import igraph as ig\n",
        "        import leidenalg\n",
        "\n",
        "        edges = list(Gnx.edges())\n",
        "        g = ig.Graph(n=N, edges=edges, directed=False)\n",
        "\n",
        "        for sd in STAB_SEEDS:\n",
        "            part = leidenalg.find_partition(\n",
        "                g, leidenalg.RBConfigurationVertexPartition, seed=int(sd)\n",
        "            )\n",
        "            lab = np.zeros(N, dtype=int)\n",
        "            for cid, nodes in enumerate(part):\n",
        "                lab[np.array(list(nodes), dtype=int)] = cid\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Leiden unavailable, falling back to Louvain:\", e)\n",
        "        METHOD = \"louvain\"\n",
        "\n",
        "# ---- Louvain stability (python-louvain if available, else NetworkX) ----\n",
        "if METHOD.lower() == \"louvain\":\n",
        "    try:\n",
        "        import community.community_louvain as community_louvain\n",
        "\n",
        "        for sd in STAB_SEEDS:\n",
        "            part = community_louvain.best_partition(Gnx, random_state=int(sd))\n",
        "            lab = np.array([part[i] for i in range(N)], dtype=int)\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"python-louvain not available, using NetworkX louvain_communities:\", e)\n",
        "        from networkx.algorithms.community import louvain_communities\n",
        "\n",
        "        for sd in STAB_SEEDS:\n",
        "            comms = louvain_communities(Gnx, seed=int(sd))\n",
        "            lab = np.zeros(N, dtype=int)\n",
        "            for cid, nodes in enumerate(comms):\n",
        "                lab[np.array(list(nodes), dtype=int)] = cid\n",
        "            labels_list.append(lab)\n",
        "            used_seeds.append(sd)\n",
        "\n",
        "assert len(labels_list) >= 2, \"Need at least 2 partitions to compute stability (check METHOD / installs).\"\n",
        "\n",
        "# pairwise ARI/AMI\n",
        "rows = []\n",
        "for i in range(len(labels_list)):\n",
        "    for j in range(i + 1, len(labels_list)):\n",
        "        ari = adjusted_rand_score(labels_list[i], labels_list[j])\n",
        "        ami = adjusted_mutual_info_score(labels_list[i], labels_list[j], average_method=\"arithmetic\")\n",
        "        rows.append({\"seed_i\": used_seeds[i], \"seed_j\": used_seeds[j], \"ARI\": ari, \"AMI\": ami})\n",
        "\n",
        "df_pair = pd.DataFrame(rows)\n",
        "display(df_pair.head())\n",
        "\n",
        "df_sum = df_pair[[\"ARI\", \"AMI\"]].agg([\"mean\", \"std\"]).T.reset_index().rename(columns={\"index\": \"metric\"})\n",
        "display(df_sum)\n",
        "\n",
        "df_pair.to_csv(\"clustering_stability_pairwise.csv\", index=False)\n",
        "df_sum.to_csv(\"clustering_stability_summary.csv\", index=False)\n",
        "print(\"Saved: clustering_stability_pairwise.csv\")\n",
        "print(\"Saved: clustering_stability_summary.csv\")\n",
        "\n",
        "# ---------- (B) GNN-based cluster validity score ----------\n",
        "# Use trained decoder as learned similarity: intra-cluster pairs should score higher than inter-cluster pairs.\n",
        "import torch\n",
        "\n",
        "def to_numpy(z):\n",
        "    if isinstance(z, np.ndarray):\n",
        "        return z\n",
        "    if isinstance(z, torch.Tensor):\n",
        "        return z.detach().cpu().numpy()\n",
        "    return np.asarray(z)\n",
        "\n",
        "Z = to_numpy(z_train)\n",
        "assert Z.shape[0] == N, f\"z_train rows ({Z.shape[0]}) != N ({N}). Make sure embeddings match data_train nodes.\"\n",
        "\n",
        "Zt = torch.tensor(Z, dtype=torch.float32)\n",
        "model_cpu = model.to(\"cpu\").eval()\n",
        "\n",
        "def score_pairs(u, v, batch=200000):\n",
        "    u = np.asarray(u, dtype=np.int64)\n",
        "    v = np.asarray(v, dtype=np.int64)\n",
        "    out = np.empty(len(u), dtype=np.float32)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(u), batch):\n",
        "            uu = torch.tensor(u[i:i+batch], dtype=torch.long)\n",
        "            vv = torch.tensor(v[i:i+batch], dtype=torch.long)\n",
        "            eidx = torch.stack([uu, vv], dim=0)\n",
        "            logits = model_cpu.dec(Zt, eidx).view(-1)\n",
        "            out[i:i+batch] = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def sample_pairs_from_labels(labels, n_pairs=50000, rng=None):\n",
        "    rng = np.random.default_rng(0) if rng is None else rng\n",
        "    labels = np.asarray(labels, dtype=int)\n",
        "\n",
        "    clusters = {}\n",
        "    for i, l in enumerate(labels):\n",
        "        clusters.setdefault(int(l), []).append(i)\n",
        "\n",
        "    cl_ids = [k for k, v in clusters.items() if len(v) >= 2]\n",
        "    if len(cl_ids) == 0:\n",
        "        return None\n",
        "\n",
        "    u_in, v_in = [], []\n",
        "    while len(u_in) < n_pairs:\n",
        "        cid = int(rng.choice(cl_ids))\n",
        "        nodes = clusters[cid]\n",
        "        a, b = rng.choice(nodes, size=2, replace=False)\n",
        "        u_in.append(a); v_in.append(b)\n",
        "\n",
        "    u_out, v_out = [], []\n",
        "    while len(u_out) < n_pairs:\n",
        "        a = int(rng.integers(0, len(labels)))\n",
        "        b = int(rng.integers(0, len(labels)))\n",
        "        if labels[a] != labels[b]:\n",
        "            u_out.append(a); v_out.append(b)\n",
        "\n",
        "    return np.array(u_in), np.array(v_in), np.array(u_out), np.array(v_out)\n",
        "\n",
        "cluster_cols = [c for c in [\"leiden_train\", \"louvain_train\", \"kmeans_cluster\"] if c in df_clusters.columns]\n",
        "print(\"Clusterings to score:\", cluster_cols)\n",
        "\n",
        "valid_rows = []\n",
        "rng = np.random.default_rng(123)\n",
        "\n",
        "dfc = df_clusters.copy()\n",
        "# ensure every node exists exactly once\n",
        "dfc = dfc.sort_values(\"node\").drop_duplicates(\"node\", keep=\"first\")\n",
        "dfc = dfc.set_index(\"node\")\n",
        "\n",
        "for col in cluster_cols:\n",
        "    lab = dfc[col].reindex(np.arange(N)).values\n",
        "    if np.any(pd.isna(lab)):\n",
        "        # if some nodes missing labels (shouldn't), skip safely\n",
        "        print(f\"Skipping {col}: missing labels for some nodes.\")\n",
        "        continue\n",
        "\n",
        "    samp = sample_pairs_from_labels(lab, n_pairs=40000, rng=rng)\n",
        "    if samp is None:\n",
        "        print(f\"Skipping {col}: no clusters with size>=2\")\n",
        "        continue\n",
        "\n",
        "    u_in, v_in, u_out, v_out = samp\n",
        "    p_in  = score_pairs(u_in,  v_in)\n",
        "    p_out = score_pairs(u_out, v_out)\n",
        "\n",
        "    y = np.concatenate([np.ones_like(p_in), np.zeros_like(p_out)])\n",
        "    p = np.concatenate([p_in, p_out])\n",
        "\n",
        "    auc = roc_auc_score(y, p)\n",
        "    valid_rows.append({\n",
        "        \"clustering\": col,\n",
        "        \"n_pairs_each\": int(len(p_in)),\n",
        "        \"auc_intra_vs_inter\": float(auc),\n",
        "        \"mean_p_intra\": float(p_in.mean()),\n",
        "        \"mean_p_inter\": float(p_out.mean()),\n",
        "        \"gap\": float(p_in.mean() - p_out.mean()),\n",
        "    })\n",
        "    print(f\"[{col}] AUC={auc:.4f} | mean_intra={p_in.mean():.4f} | mean_inter={p_out.mean():.4f} | gap={p_in.mean()-p_out.mean():.4f}\")\n",
        "\n",
        "df_valid = pd.DataFrame(valid_rows).sort_values(\"auc_intra_vs_inter\", ascending=False)\n",
        "display(df_valid)\n",
        "\n",
        "df_valid.to_csv(\"gnn_cluster_validity_scores.csv\", index=False)\n",
        "print(\"Saved: gnn_cluster_validity_scores.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6vNa9lK9bWGM",
      "metadata": {
        "id": "6vNa9lK9bWGM"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 12) GO ENRICHMENT (g:Profiler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XmVzp-omljv9",
      "metadata": {
        "id": "XmVzp-omljv9"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 12) GO ENRICHMENT (g:Profiler)  [paper-ready]\n",
        "# Notes:\n",
        "# - Filters very small/huge clusters to avoid inflated counts\n",
        "# - Filters overly-broad GO terms (term_size) to improve interpretability\n",
        "# - Saves: go_enrichment_all_terms.csv + go_enrichment_top_terms_per_cluster.csv\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gprofiler import GProfiler\n",
        "gp = GProfiler(return_dataframe=True)\n",
        "\n",
        "assert \"df_clusters\" in globals(), \"df_clusters not found. Run clustering section first.\"\n",
        "assert \"gene_final\" in df_clusters.columns, \"df_clusters must include gene_final column (merge nodes_annot in clustering).\"\n",
        "\n",
        "\n",
        "GENE_COL = \"gene_final\"\n",
        "ORGANISM = \"hsapiens\"\n",
        "\n",
        "# Cluster-size filter (prevents huge clusters from producing thousands of generic terms)\n",
        "MIN_CLUSTER_SIZE = 20\n",
        "MAX_CLUSTER_SIZE = 400\n",
        "\n",
        "# Choose which clustering to enrich.\n",
        "# Preferred order for biology: predicted communities (if non-degenerate) -> Leiden/Louvain on train graph -> KMeans.\n",
        "PREFERRED_CLUSTER_COLS = [\"louvain_pred\", \"leiden_train\", \"louvain_train\", \"kmeans_cluster\"]\n",
        "\n",
        "def choose_cluster_col(df, preferred_cols, min_size, max_size):\n",
        "    existing = [c for c in preferred_cols if c in df.columns]\n",
        "    if not existing:\n",
        "        raise ValueError(\"No clustering label columns found in df_clusters.\")\n",
        "\n",
        "    # If user already set CLUSTER_COL manually upstream, respect it (if valid)\n",
        "    if \"CLUSTER_COL\" in globals() and isinstance(globals()[\"CLUSTER_COL\"], str):\n",
        "        _c = globals()[\"CLUSTER_COL\"]\n",
        "        if _c in df.columns:\n",
        "            return _c\n",
        "\n",
        "    for c in existing:\n",
        "        sizes = df[c].value_counts(dropna=True)\n",
        "        n_good = int(((sizes >= min_size) & (sizes <= max_size)).sum())\n",
        "        if n_good > 0:\n",
        "            return c\n",
        "    # fallback: at least return something\n",
        "    return existing[0]\n",
        "\n",
        "CLUSTER_COL = choose_cluster_col(df_clusters, PREFERRED_CLUSTER_COLS, MIN_CLUSTER_SIZE, MAX_CLUSTER_SIZE)\n",
        "print(\"Using cluster labels:\", CLUSTER_COL)\n",
        "\n",
        "# quick visibility\n",
        "_sizes = df_clusters[CLUSTER_COL].value_counts()\n",
        "print(\"Cluster sizes (describe):\")\n",
        "print(_sizes.describe())\n",
        "print(\"Clusters within [MIN,MAX]:\", int(((_sizes >= MIN_CLUSTER_SIZE) & (_sizes <= MAX_CLUSTER_SIZE)).sum()))\n",
        "\n",
        "# Term-level filters (reduce generic GO terms)\n",
        "MIN_INTERSECTION = 3\n",
        "MIN_TERM_SIZE = 10\n",
        "MAX_TERM_SIZE = 1000\n",
        "\n",
        "TOP_TERMS_PER_CLUSTER = 8\n",
        "\n",
        "def _safe_upper_genes(x):\n",
        "    genes = pd.Series(x).dropna().astype(str).str.strip().str.upper()\n",
        "    genes = genes[genes != \"NAN\"]\n",
        "    return genes.unique().tolist()\n",
        "\n",
        "enr_rows = []\n",
        "summary_rows = []\n",
        "\n",
        "for cid, sub in df_clusters.groupby(CLUSTER_COL):\n",
        "    genes = _safe_upper_genes(sub[GENE_COL])\n",
        "    n = len(genes)\n",
        "    if n < MIN_CLUSTER_SIZE or n > MAX_CLUSTER_SIZE:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        res = gp.profile(\n",
        "            organism=ORGANISM,\n",
        "            query=genes,\n",
        "            sources=[\"GO:BP\",\"GO:MF\",\"GO:CC\"],\n",
        "            user_threshold=0.05,\n",
        "            significance_threshold_method=\"fdr\",\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"Cluster\", cid, \"GO failed:\", e)\n",
        "        continue\n",
        "\n",
        "    if res is None or len(res) == 0:\n",
        "        summary_rows.append({\"cluster\": int(cid), \"n_genes\": n, \"n_terms_fdr05\": 0, \"enrich_score\": 0.0})\n",
        "        continue\n",
        "\n",
        "    res = res.copy()\n",
        "    res[\"cluster\"] = int(cid)\n",
        "    # Defensive column handling across gprofiler versions\n",
        "    pcol = \"p_value\" if \"p_value\" in res.columns else (\"pvalue\" if \"pvalue\" in res.columns else None)\n",
        "    if pcol is None:\n",
        "        # last resort: pick a column containing 'p' and 'value'\n",
        "        p_cands = [c for c in res.columns if (\"p\" in c.lower() and \"value\" in c.lower())]\n",
        "        pcol = p_cands[0] if p_cands else res.columns[0]\n",
        "\n",
        "    # Common columns: intersection_size, term_size, query_size\n",
        "    inter_col = \"intersection_size\" if \"intersection_size\" in res.columns else None\n",
        "    termsize_col = \"term_size\" if \"term_size\" in res.columns else None\n",
        "    qsize_col = \"query_size\" if \"query_size\" in res.columns else None\n",
        "\n",
        "    res[\"p_use\"] = res[pcol].astype(float)\n",
        "\n",
        "    # Apply term filters when columns exist\n",
        "    m = np.ones(len(res), dtype=bool)\n",
        "    if inter_col is not None:\n",
        "        m &= (res[inter_col].astype(int) >= MIN_INTERSECTION)\n",
        "    if termsize_col is not None:\n",
        "        m &= (res[termsize_col].astype(int) >= MIN_TERM_SIZE)\n",
        "        m &= (res[termsize_col].astype(int) <= MAX_TERM_SIZE)\n",
        "    if qsize_col is not None and inter_col is not None:\n",
        "        # precision of overlap (helps filter \"tiny overlaps\")\n",
        "        m &= (res[inter_col].astype(int) / np.maximum(1, res[qsize_col].astype(int)) >= 0.03)\n",
        "\n",
        "    res_f = res[m].copy()\n",
        "    # Enrichment strength: sum(-log10(p)) of significant terms (after filters)\n",
        "    sig = res_f[res_f[\"p_use\"] <= 0.05].copy()\n",
        "    enrich_score = float(np.sum(-np.log10(np.maximum(sig[\"p_use\"].values, 1e-300)))) if len(sig) else 0.0\n",
        "    summary_rows.append({\n",
        "        \"cluster\": int(cid),\n",
        "        \"n_genes\": int(n),\n",
        "        \"n_terms_fdr05\": int(len(sig)),\n",
        "        \"enrich_score\": enrich_score,\n",
        "    })\n",
        "\n",
        "    if len(res_f) > 0:\n",
        "        enr_rows.append(res_f)\n",
        "\n",
        "df_go_all = pd.concat(enr_rows, ignore_index=True) if enr_rows else pd.DataFrame()\n",
        "\n",
        "df_go_summary = pd.DataFrame(summary_rows)\n",
        "if df_go_summary.empty:\n",
        "    df_go_summary = pd.DataFrame(columns=[\"cluster\",\"n_genes\",\"n_terms_fdr05\",\"enrich_score\"])\n",
        "else:\n",
        "    df_go_summary = df_go_summary.sort_values([\"enrich_score\",\"n_terms_fdr05\"], ascending=False)\n",
        "\n",
        "display(df_go_summary.head(15))\n",
        "\n",
        "# Plot: enrichment score vs cluster size (top 15 by enrich_score)\n",
        "if len(df_go_summary) > 0:\n",
        "    top = df_go_summary.head(15).copy()\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar(top[\"cluster\"].astype(str), top[\"enrich_score\"])\n",
        "    plt.xlabel(\"Cluster\")\n",
        "    plt.ylabel(\"Enrichment score = Σ -log10(FDR)\")\n",
        "    plt.title(\"GO enrichment strength per cluster (top 15)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"go_enrichment_cluster_summary.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Save full results\n",
        "if len(df_go_all) > 0:\n",
        "    df_go_all.to_csv(\"go_enrichment_all_terms.csv\", index=False)\n",
        "    print(\"Saved: go_enrichment_all_terms.csv\")\n",
        "\n",
        "    # Top terms per cluster (paper table)\n",
        "    # Use columns if present\n",
        "    name_col = \"name\" if \"name\" in df_go_all.columns else (\"term_name\" if \"term_name\" in df_go_all.columns else None)\n",
        "    src_col = \"source\" if \"source\" in df_go_all.columns else (\"src\" if \"src\" in df_go_all.columns else None)\n",
        "    keep_cols = [c for c in [\"cluster\", src_col, name_col, \"p_use\", \"intersection_size\", \"term_size\"] if c is not None and c in df_go_all.columns]\n",
        "\n",
        "    df_top_terms = (df_go_all.sort_values([\"cluster\",\"p_use\"], ascending=[True, True])\n",
        "                           .groupby(\"cluster\")\n",
        "                           .head(TOP_TERMS_PER_CLUSTER))\n",
        "    if keep_cols:\n",
        "        df_top_terms = df_top_terms[keep_cols]\n",
        "\n",
        "    df_top_terms = df_top_terms.rename(columns={\"p_use\":\"FDR_p\"})\n",
        "    df_top_terms.to_csv(\"go_enrichment_top_terms_per_cluster.csv\", index=False)\n",
        "    print(\"Saved: go_enrichment_top_terms_per_cluster.csv\")\n",
        "else:\n",
        "    print(\"No GO enrichment results (after filters). Try relaxing MAX_CLUSTER_SIZE or term filters.\")\n",
        "\n",
        "\n",
        "print(\"Cluster sizes:\")\n",
        "print(df_clusters[CLUSTER_COL].value_counts().describe())\n",
        "\n",
        "print(\"\\nNon-null genes:\", df_clusters[\"gene_final\"].notna().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K7mrFJf7bWGO",
      "metadata": {
        "id": "K7mrFJf7bWGO"
      },
      "source": [
        "## 14) Edge explanation via PERTURBATION (robust, no GNNExplainer assertions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kHXlVLF-bWGO",
      "metadata": {
        "id": "kHXlVLF-bWGO"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 14) Edge explanation via PERTURBATION (robust, no GNNExplainer assertions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s4CddRz1bWGO",
      "metadata": {
        "id": "s4CddRz1bWGO"
      },
      "source": [
        "## =========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EamCT9IibWGO",
      "metadata": {
        "id": "EamCT9IibWGO"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import k_hop_subgraph\n",
        "\n",
        "u0, v0 = int(df_top.iloc[0][\"u\"]), int(df_top.iloc[0][\"v\"])\n",
        "print(\"Explaining edge:\", (u0, v0), \"prob=\", float(df_top.iloc[0][\"prob\"]))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device).eval()\n",
        "\n",
        "# ---- build small subgraph around {u0,v0} ----\n",
        "num_hops = 2     # αν είναι μεγάλο/αργό -> 1\n",
        "node_pair = torch.tensor([u0, v0], dtype=torch.long)\n",
        "\n",
        "edge_index_cpu = data_train.edge_index.detach().cpu()\n",
        "x_cpu = data_train.x.detach().cpu()\n",
        "\n",
        "edge_weight_cpu = None\n",
        "if hasattr(data_train, \"edge_weight\") and data_train.edge_weight is not None:\n",
        "    edge_weight_cpu = data_train.edge_weight.detach().cpu()\n",
        "\n",
        "subset, ei_sub, mapping, sub_edge_mask = k_hop_subgraph(\n",
        "    node_idx=node_pair,\n",
        "    num_hops=num_hops,\n",
        "    edge_index=edge_index_cpu,\n",
        "    relabel_nodes=True\n",
        ")\n",
        "\n",
        "x_sub = x_cpu[subset]\n",
        "if edge_weight_cpu is not None:\n",
        "    ew_sub = edge_weight_cpu[sub_edge_mask]\n",
        "else:\n",
        "    ew_sub = torch.ones(ei_sub.size(1), dtype=torch.float)\n",
        "\n",
        "# edge to explain inside subgraph\n",
        "edge_label_index_sub = mapping.view(2, 1)  # [2,1]\n",
        "\n",
        "# move to device\n",
        "x_sub = x_sub.to(device)\n",
        "ei_sub = ei_sub.to(device)\n",
        "ew_sub = ew_sub.to(device)\n",
        "edge_label_index_sub = edge_label_index_sub.to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def link_score(edge_index, edge_weight):\n",
        "    # robust to enc signature\n",
        "    try:\n",
        "        z = model.enc(x_sub, edge_index, edge_weight)\n",
        "    except TypeError:\n",
        "        z = model.enc(x_sub, edge_index)\n",
        "    out = model.dec(z, edge_label_index_sub).view(-1)\n",
        "    return float(out.item())\n",
        "\n",
        "base = link_score(ei_sub, ew_sub)\n",
        "print(\"Baseline raw score:\", base)\n",
        "\n",
        "E = ei_sub.size(1)\n",
        "\n",
        "# ---- group reverse-direction duplicates (undirected graphs often store both) ----\n",
        "# We'll remove both (a->b) and (b->a) together to be fair.\n",
        "ei_cpu = ei_sub.detach().cpu()\n",
        "pairs = [(int(ei_cpu[0,i]), int(ei_cpu[1,i])) for i in range(E)]\n",
        "pair_to_idxs = {}\n",
        "for i,(a,b) in enumerate(pairs):\n",
        "    key = (min(a,b), max(a,b))\n",
        "    pair_to_idxs.setdefault(key, []).append(i)\n",
        "\n",
        "keys_all = list(pair_to_idxs.keys())\n",
        "\n",
        "max_test = 800\n",
        "if len(keys_all) > max_test:\n",
        "    rng = np.random.default_rng(0)\n",
        "    idx = rng.choice(len(keys_all), size=max_test, replace=False)\n",
        "    keys = [keys_all[i] for i in idx]\n",
        "    print(f\"Subgraph unique-edges={len(keys_all)} -> testing random {len(keys)} edges for speed\")\n",
        "else:\n",
        "    keys = keys_all\n",
        "\n",
        "importances = []\n",
        "edge_keys = []\n",
        "\n",
        "for k in keys:\n",
        "    idxs = pair_to_idxs[k]\n",
        "    keep = torch.ones(E, dtype=torch.bool, device=device)\n",
        "    keep[idxs] = False\n",
        "\n",
        "    ei_drop = ei_sub[:, keep]\n",
        "    ew_drop = ew_sub[keep]\n",
        "\n",
        "    s_drop = link_score(ei_drop, ew_drop)\n",
        "    imp = base - s_drop  # positive => removing edge decreases score => important\n",
        "    importances.append(imp)\n",
        "    edge_keys.append(k)\n",
        "\n",
        "importances = np.array(importances, dtype=float)\n",
        "\n",
        "# save\n",
        "np.save(\"perturb_edge_importance.npy\", importances)\n",
        "print(\"Saved: perturb_edge_importance.npy\")\n",
        "\n",
        "# ---- plot top-20 ----\n",
        "top = np.argsort(-importances)[:20]\n",
        "top_imps = importances[top]\n",
        "top_edges = [edge_keys[i] for i in top]\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(np.arange(len(top)), top_imps)\n",
        "plt.xticks(np.arange(len(top)), [f\"{a}-{b}\" for (a,b) in top_edges], rotation=60, ha=\"right\")\n",
        "plt.ylabel(\"Importance (baseline - score_removed)\")\n",
        "plt.title(f\"Perturbation edge importance for link ({u0},{v0}) in {num_hops}-hop subgraph\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"edge_importance_perturbation.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved: edge_importance_perturbation.png\")\n",
        "\n",
        "# ---- print edges back to ORIGINAL node ids ----\n",
        "# map subgraph node ids -> original ids:\n",
        "subset_cpu = subset.detach().cpu().numpy()\n",
        "print(\"\\nTop edges (ORIGINAL node ids, importance):\")\n",
        "for (a_sub, b_sub), imp in zip(top_edges, top_imps):\n",
        "    a = int(subset_cpu[a_sub])\n",
        "    b = int(subset_cpu[b_sub])\n",
        "    print(f\"  ({a}, {b})  importance={imp:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1M4dUeN5BMt2",
      "metadata": {
        "id": "1M4dUeN5BMt2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# ---- Wrapper: returns score for ONE target edge (edge_label_index_sub) ----\n",
        "class LPWrapper(nn.Module):\n",
        "    def __init__(self, model, edge_label_index_sub):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.edge_label_index_sub = edge_label_index_sub  # [2,1] on device\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None):\n",
        "        # edge_attr used as edge_weight if available\n",
        "        try:\n",
        "            if edge_attr is None:\n",
        "                z = self.model.enc(x, edge_index)\n",
        "            else:\n",
        "                z = self.model.enc(x, edge_index, edge_attr)\n",
        "        except TypeError:\n",
        "            z = self.model.enc(x, edge_index)\n",
        "\n",
        "        out = self.model.dec(z, self.edge_label_index_sub).view(-1)  # shape [1]\n",
        "        return out  # raw score or prob depending on your decoder\n",
        "\n",
        "wrapped = LPWrapper(model, edge_label_index_sub).to(device).eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vzvxa44HBSaz",
      "metadata": {
        "id": "Vzvxa44HBSaz"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.explain import Explainer\n",
        "from torch_geometric.explain.algorithm import GNNExplainer\n",
        "from torch_geometric.explain.config import ModelConfig\n",
        "\n",
        "# Αν το dec σου βγάζει prob (0..1) βάλε return_type=\"probs\"\n",
        "# Αν βγάζει logit/raw score βάλε return_type=\"raw\"\n",
        "return_type = \"raw\"\n",
        "\n",
        "explainer = Explainer(\n",
        "    model=wrapped,\n",
        "    algorithm=GNNExplainer(epochs=200, lr=0.01),\n",
        "    explanation_type=\"model\",\n",
        "    node_mask_type=\"attributes\",   # importance στα features (αν έχεις)\n",
        "    edge_mask_type=\"object\",       # importance στα edges\n",
        "    model_config=ModelConfig(\n",
        "        mode=\"binary_classification\",\n",
        "        task_level=\"edge\",\n",
        "        return_type=return_type,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Αν έχεις ew_sub, περνά το ως edge_attr\n",
        "explanation = explainer(x_sub, ei_sub, edge_attr=ew_sub)\n",
        "\n",
        "edge_mask = explanation.edge_mask.detach().cpu().numpy()  # importance per edge in ei_sub order\n",
        "print(\"edge_mask shape:\", edge_mask.shape, \"E_sub:\", ei_sub.size(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IyMuQi73BWRY",
      "metadata": {
        "id": "IyMuQi73BWRY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# --- inputs assumed available: ei_sub, subset, edge_mask ---\n",
        "ei_cpu = ei_sub.detach().cpu().numpy()\n",
        "subset_cpu = subset.detach().cpu().numpy()\n",
        "E = ei_cpu.shape[1]\n",
        "\n",
        "# 1) Build NetworkX subgraph using ORIGINAL node ids\n",
        "Gx = nx.Graph()\n",
        "Gx.add_nodes_from(subset_cpu.tolist())\n",
        "\n",
        "# add edges + importance\n",
        "for j in range(E):\n",
        "    a_sub = int(ei_cpu[0, j]); b_sub = int(ei_cpu[1, j])\n",
        "    a = int(subset_cpu[a_sub]); b = int(subset_cpu[b_sub])\n",
        "    w = float(edge_mask[j])\n",
        "    # undirected: keep max importance if duplicates exist\n",
        "    if Gx.has_edge(a, b):\n",
        "        Gx[a][b][\"importance\"] = max(Gx[a][b][\"importance\"], w)\n",
        "    else:\n",
        "        Gx.add_edge(a, b, importance=w)\n",
        "\n",
        "# 2) Keep only top edges for clarity\n",
        "TOP_EDGES_PLOT = 40  # άλλαξε το (πχ 20/60) ανάλογα πόσο “γεμάτο” θες\n",
        "edges_sorted = sorted(Gx.edges(data=True), key=lambda x: x[2].get(\"importance\", 0.0), reverse=True)\n",
        "edges_keep = edges_sorted[:min(TOP_EDGES_PLOT, len(edges_sorted))]\n",
        "\n",
        "Gplot = nx.Graph()\n",
        "Gplot.add_nodes_from(Gx.nodes())\n",
        "for a, b, d in edges_keep:\n",
        "    Gplot.add_edge(a, b, **d)\n",
        "\n",
        "# optionally: drop isolated nodes after edge filtering\n",
        "isolated = [n for n in Gplot.nodes() if Gplot.degree(n) == 0]\n",
        "Gplot.remove_nodes_from(isolated)\n",
        "\n",
        "# 3) Node labels: gene_final if available, else node id\n",
        "labels = {n: str(n) for n in Gplot.nodes()}\n",
        "if \"df_clusters\" in globals() and \"gene_final\" in df_clusters.columns:\n",
        "    tmp = df_clusters.set_index(\"node\")[\"gene_final\"]\n",
        "    for n in list(Gplot.nodes()):\n",
        "        if n in tmp.index and pd.notna(tmp.loc[n]):\n",
        "            labels[n] = str(tmp.loc[n])\n",
        "\n",
        "# 4) Layout\n",
        "pos = nx.spring_layout(Gplot, seed=0, k=0.6)\n",
        "\n",
        "# 5) Edge widths scaled by importance\n",
        "imps = np.array([d.get(\"importance\", 0.0) for _, _, d in Gplot.edges(data=True)], dtype=float)\n",
        "if len(imps) == 0:\n",
        "    print(\"No edges to plot (try increasing TOP_EDGES_PLOT).\")\n",
        "else:\n",
        "    # normalize to [0,1]\n",
        "    imps_n = (imps - imps.min()) / (imps.max() - imps.min() + 1e-12)\n",
        "    widths = 0.5 + 6.0 * imps_n  # thickness range\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    nx.draw_networkx_nodes(Gplot, pos, node_size=250, alpha=0.9)\n",
        "    nx.draw_networkx_edges(Gplot, pos, width=widths, alpha=0.7)\n",
        "    nx.draw_networkx_labels(Gplot, pos, labels=labels, font_size=8)\n",
        "\n",
        "    plt.title(f\"GNNExplainer edge importance (top {len(Gplot.edges())} edges)\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"gnnexplainer_subgraph_importance.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Saved: gnnexplainer_subgraph_importance.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HjaZwrQvmeP1",
      "metadata": {
        "id": "HjaZwrQvmeP1"
      },
      "source": [
        "# Paper add-ons: External validation + Disease association\n",
        "The next cells add paper-grade analyses:\n",
        "- External cluster validation against CORUM complexes\n",
        "- Disease enrichment per cluster (Enrichr)\n",
        "- Disease-centric candidate gene/link ranking (Open Targets + your top predicted links)\n",
        "\n",
        "Run them **after** you have `df_clusters`, `df_top`, and `nodes_annot` created above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32u7dDULuTY4",
      "metadata": {
        "id": "32u7dDULuTY4"
      },
      "outputs": [],
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "CORUM_LOCAL_PATH = \"/content/corum_allComplexes.txt\"  # αυτό που έχεις\n",
        "\n",
        "assert os.path.exists(CORUM_LOCAL_PATH), f\"Δεν βρίσκω το αρχείο: {CORUM_LOCAL_PATH}\"\n",
        "\n",
        "print(\"Loading CORUM TXT from:\", CORUM_LOCAL_PATH)\n",
        "corum = pd.read_csv(CORUM_LOCAL_PATH, sep=\"\\t\")\n",
        "print(\"CORUM loaded:\", corum.shape, \"columns:\", list(corum.columns)[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jzv7-LaqpdNG",
      "metadata": {
        "id": "Jzv7-LaqpdNG"
      },
      "outputs": [],
      "source": [
        "# (no extra installs needed here)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VPyCRMjWmeP1",
      "metadata": {
        "id": "VPyCRMjWmeP1"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 15) EXTERNAL CLUSTER VALIDATION (CORUM protein complexes)  [paper-ready]\n",
        "# What you get:\n",
        "# (A) Jaccard-style overlap metrics (recovery/precision)\n",
        "# (B) Enrichment-style validation (hypergeometric + BH-FDR)\n",
        "# Notes (important for STRING/PPI graphs):\n",
        "# - CORUM is curated physical complexes; overlap with functional networks can be low.\n",
        "# - We improve power by using Universe = (genes in graph) ∩ (genes appearing in CORUM after mapping).\n",
        "# Saves:\n",
        "#  - corum_cluster_validation_jaccard.csv\n",
        "#  - corum_cluster_enrichment_besthit.csv\n",
        "#  - uniprot_to_gene_cache.csv (cache for faster reruns)\n",
        "# =========================\n",
        "import os, re, time, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "assert \"df_clusters\" in globals(), \"Run clustering section first to create df_clusters.\"\n",
        "assert \"gene_final\" in df_clusters.columns, \"df_clusters must include gene_final.\"\n",
        "\n",
        "# ---- choose cluster labels consistent with GO step ----\n",
        "CLUSTER_COL = None\n",
        "for _col in [\"edge_mlp_kmeans\", \"louvain_pred\", \"leiden_train\", \"louvain_train\", \"kmeans_cluster\"]:\n",
        "    if _col in df_clusters.columns:\n",
        "        CLUSTER_COL = _col\n",
        "        break\n",
        "assert CLUSTER_COL is not None, \"No cluster label column found in df_clusters.\"\n",
        "print(\"Using cluster labels:\", CLUSTER_COL)\n",
        "\n",
        "# --- Settings ---\n",
        "CORUM_LOCAL_PATH = \"/content/corum_allComplexes.txt\"  # upload to Colab, or adjust path\n",
        "MIN_COMPLEX_SIZE = 4           # was 10 (too strict for CORUM)\n",
        "MIN_CLUSTER_SIZE = 10          # was 15\n",
        "MAX_CLUSTER_SIZE = 2000        # was 500 (kept too few clusters)\n",
        "JACCARD_THR_LIST = [0.02, 0.05, 0.10, 0.20]  # more realistic for biology\n",
        "\n",
        "# We'll require >=2 shared genes for enrichment rows (k=1 is usually uninformative)\n",
        "MIN_OVERLAP_K = 2\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# BH-FDR (Benjamini-Hochberg) without statsmodels\n",
        "# ---------------------------------------------------------\n",
        "def bh_fdr(pvals):\n",
        "    \"\"\"Benjamini-Hochberg FDR correction. Returns q-values (same shape).\"\"\"\n",
        "    pvals = np.asarray(pvals, dtype=float)\n",
        "    n = pvals.size\n",
        "    if n == 0:\n",
        "        return pvals\n",
        "    order = np.argsort(pvals)\n",
        "    ranked = pvals[order]\n",
        "    q = ranked * n / (np.arange(1, n + 1))\n",
        "    q = np.minimum.accumulate(q[::-1])[::-1]   # monotone\n",
        "    q = np.clip(q, 0.0, 1.0)\n",
        "    out = np.empty_like(q)\n",
        "    out[order] = q\n",
        "    return out\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Auto-find CORUM file if path is wrong\n",
        "# ---------------------------------------------------------\n",
        "if not os.path.exists(CORUM_LOCAL_PATH) and os.path.exists(\"/content\"):\n",
        "    cands = []\n",
        "    for fn in os.listdir(\"/content\"):\n",
        "        if \"corum\" in fn.lower() and fn.lower().endswith((\".txt\", \".tsv\")):\n",
        "            cands.append(\"/content/\" + fn)\n",
        "    if cands:\n",
        "        CORUM_LOCAL_PATH = cands[0]\n",
        "        print(\"Auto-selected CORUM file:\", CORUM_LOCAL_PATH)\n",
        "\n",
        "assert os.path.exists(CORUM_LOCAL_PATH), f\"Δεν βρίσκω το αρχείο: {CORUM_LOCAL_PATH}\"\n",
        "print(\"Loading CORUM from:\", CORUM_LOCAL_PATH)\n",
        "\n",
        "corum = pd.read_csv(CORUM_LOCAL_PATH, sep=\"\\t\")\n",
        "print(\"CORUM loaded:\", corum.shape)\n",
        "\n",
        "# --- Pick best members column (UniProt IDs) ---\n",
        "if \"subunits_uniprot_id\" in corum.columns:\n",
        "    MEMBER_COL = \"subunits_uniprot_id\"\n",
        "elif \"comment_members\" in corum.columns:\n",
        "    MEMBER_COL = \"comment_members\"\n",
        "else:\n",
        "    cands = [c for c in corum.columns if (\"uniprot\" in c.lower()) or (\"subunit\" in c.lower()) or (\"member\" in c.lower())]\n",
        "    if not cands:\n",
        "        raise ValueError(f\"Could not find a suitable members column. Columns: {list(corum.columns)}\")\n",
        "    MEMBER_COL = cands[0]\n",
        "print(\"Using CORUM members column:\", MEMBER_COL)\n",
        "\n",
        "def parse_uniprot_list(s: str):\n",
        "    s = str(s)\n",
        "    if s.lower() == \"nan\":\n",
        "        return []\n",
        "    parts = re.split(r\"[;,|\\s]+\", s.strip())\n",
        "    ids = []\n",
        "    for p in parts:\n",
        "        p = p.strip()\n",
        "        if not p:\n",
        "            continue\n",
        "        # UniProt accessions are typically 6-10 chars alnum\n",
        "        if re.match(r\"^[A-Z0-9]{6,10}$\", p):\n",
        "            ids.append(p)\n",
        "    return ids\n",
        "\n",
        "def parse_corum_complexes_uniprot(df, member_col, min_size=4):\n",
        "    complexes = []\n",
        "    for i, s in enumerate(df[member_col].tolist()):\n",
        "        ids = parse_uniprot_list(s)\n",
        "        upset = set(ids)\n",
        "        if len(upset) >= min_size:\n",
        "            name = df.loc[i, \"complex_name\"] if \"complex_name\" in df.columns else f\"complex_{i}\"\n",
        "            complexes.append((int(i), str(name), upset))\n",
        "    return complexes\n",
        "\n",
        "corum_complexes_up = parse_corum_complexes_uniprot(corum, MEMBER_COL, min_size=MIN_COMPLEX_SIZE)\n",
        "print(\"CORUM complexes kept:\", len(corum_complexes_up), f\"(min_size={MIN_COMPLEX_SIZE})\")\n",
        "\n",
        "# --- Predicted cluster sets (Gene Symbols) ---\n",
        "def cluster_sets_genes(df_clusters, cluster_col, gene_col=\"gene_final\", min_cluster_size=10, max_cluster_size=2000):\n",
        "    out = []\n",
        "    for cid, sub in df_clusters.groupby(cluster_col):\n",
        "        genes = sub[gene_col].dropna().astype(str).str.strip().str.upper()\n",
        "        genes = genes[genes != \"NAN\"].unique().tolist()\n",
        "        gset = set(genes)\n",
        "        if len(gset) >= min_cluster_size and len(gset) <= max_cluster_size:\n",
        "            out.append((int(cid), gset))\n",
        "    return out\n",
        "\n",
        "pred_clusters = cluster_sets_genes(\n",
        "    df_clusters, CLUSTER_COL,\n",
        "    min_cluster_size=MIN_CLUSTER_SIZE, max_cluster_size=MAX_CLUSTER_SIZE\n",
        ")\n",
        "print(\"Clusters used:\", len(pred_clusters), f\"(size in [{MIN_CLUSTER_SIZE},{MAX_CLUSTER_SIZE}])\")\n",
        "\n",
        "# --- UniProt -> Gene Symbol mapping (cache + UniProt idmapping API) ---\n",
        "all_up = sorted(set().union(*[s for _, _, s in corum_complexes_up])) if len(corum_complexes_up) else []\n",
        "print(\"Unique UniProt IDs in kept CORUM complexes:\", len(all_up))\n",
        "\n",
        "CACHE_PATH = \"uniprot_to_gene_cache.csv\"\n",
        "up2gene = {}\n",
        "\n",
        "if os.path.exists(CACHE_PATH):\n",
        "    df_cache = pd.read_csv(CACHE_PATH)\n",
        "    if {\"uniprot\",\"gene\"}.issubset(df_cache.columns):\n",
        "        up2gene = dict(zip(df_cache[\"uniprot\"].astype(str), df_cache[\"gene\"].astype(str)))\n",
        "        print(\"Loaded UniProt->gene cache:\", len(up2gene))\n",
        "\n",
        "need = [u for u in all_up if u not in up2gene]\n",
        "\n",
        "UNIPROT_MAP_URL = \"https://rest.uniprot.org/idmapping/run\"\n",
        "UNIPROT_STATUS_URL = \"https://rest.uniprot.org/idmapping/status/\"\n",
        "UNIPROT_RESULTS_URL = \"https://rest.uniprot.org/idmapping/uniprotkb/results/\"\n",
        "\n",
        "def uniprot_map_uniprot_to_symbol(uniprot_ids, chunk=3000, sleep_s=1.5):\n",
        "    out = {}\n",
        "    headers = {\"User-Agent\": \"colab-corum-eval/1.0\"}\n",
        "\n",
        "    def run_job(ids):\n",
        "        data = {\"from\": \"UniProtKB_AC-ID\", \"to\": \"UniProtKB\", \"ids\": \",\".join(ids)}\n",
        "        r = requests.post(UNIPROT_MAP_URL, data=data, headers=headers, timeout=180)\n",
        "        r.raise_for_status()\n",
        "        return r.json()[\"jobId\"]\n",
        "\n",
        "    def wait_job(job_id):\n",
        "        while True:\n",
        "            r = requests.get(UNIPROT_STATUS_URL + job_id, headers=headers, timeout=180)\n",
        "            r.raise_for_status()\n",
        "            js = r.json()\n",
        "            if js.get(\"jobStatus\") in [\"RUNNING\", \"NEW\"]:\n",
        "                time.sleep(sleep_s)\n",
        "                continue\n",
        "            break\n",
        "\n",
        "    def fetch_tsv(job_id):\n",
        "        params = {\"format\": \"tsv\", \"fields\": \"accession,gene_primary\", \"size\": 500}\n",
        "        url = UNIPROT_RESULTS_URL + job_id\n",
        "        chunks = []\n",
        "        while True:\n",
        "            rr = requests.get(url, params=params, headers=headers, timeout=180)\n",
        "            rr.raise_for_status()\n",
        "            chunks.append(rr.text)\n",
        "            link = rr.headers.get(\"Link\", \"\")\n",
        "            m = re.search(r'<([^>]+)>;\\s*rel=\"next\"', link)\n",
        "            if m:\n",
        "                url = m.group(1)\n",
        "                params = None\n",
        "                continue\n",
        "            break\n",
        "        return \"\".join(chunks)\n",
        "\n",
        "    for i in range(0, len(uniprot_ids), chunk):\n",
        "        ids_chunk = uniprot_ids[i:i+chunk]\n",
        "        print(f\"Mapping UniProt -> gene symbol: chunk {i//chunk+1}/{int(np.ceil(len(uniprot_ids)/chunk))} (n={len(ids_chunk)})\")\n",
        "        job = run_job(ids_chunk)\n",
        "        wait_job(job)\n",
        "        tsv = fetch_tsv(job)\n",
        "        df = pd.read_csv(io.StringIO(tsv), sep=\"\\t\")\n",
        "\n",
        "        acc_col = next((c for c in df.columns if \"accession\" in c.lower()), df.columns[0])\n",
        "        gene_col = next((c for c in df.columns if (\"gene\" in c.lower() and \"primary\" in c.lower())), df.columns[-1])\n",
        "\n",
        "        for a, g in zip(df[acc_col].astype(str), df[gene_col].astype(str)):\n",
        "            a = a.strip()\n",
        "            g = g.strip().upper()\n",
        "            if g and g.lower() != \"nan\":\n",
        "                out[a] = g\n",
        "    return out\n",
        "\n",
        "if len(need) > 0:\n",
        "    new_map = uniprot_map_uniprot_to_symbol(need, chunk=3000, sleep_s=1.5)\n",
        "    up2gene.update(new_map)\n",
        "    print(\"Mapped UniProt IDs to gene symbols (new):\", len(new_map))\n",
        "\n",
        "    df_cache = pd.DataFrame({\"uniprot\": list(up2gene.keys()), \"gene\": list(up2gene.values())})\n",
        "    df_cache.to_csv(CACHE_PATH, index=False)\n",
        "    print(\"Saved cache:\", CACHE_PATH)\n",
        "\n",
        "print(\"Total mapped UniProt IDs:\", len(up2gene))\n",
        "\n",
        "# --- Convert CORUM complexes to gene symbols ---\n",
        "corum_complexes_gene = []\n",
        "for cid, name, upset in corum_complexes_up:\n",
        "    genes = [up2gene.get(u) for u in upset]\n",
        "    genes = [g for g in genes if g is not None and g.strip() and g.lower() != \"nan\"]\n",
        "    gset = set([g.strip().upper() for g in genes])\n",
        "    if len(gset) >= MIN_COMPLEX_SIZE:\n",
        "        corum_complexes_gene.append((cid, name, gset))\n",
        "print(\"CORUM complexes after mapping:\", len(corum_complexes_gene))\n",
        "\n",
        "# =========================================================\n",
        "# (A) Jaccard overlap metrics\n",
        "# =========================================================\n",
        "def best_jaccard(A, B):\n",
        "    A, B = set(A), set(B)\n",
        "    inter = len(A & B)\n",
        "    if inter == 0:\n",
        "        return 0.0\n",
        "    return inter / (len(A | B) + 1e-12)\n",
        "\n",
        "def weighted_best_jaccard(pred_clusters, ref_complexes):\n",
        "    scores, weights = [], []\n",
        "    for _, C in pred_clusters:\n",
        "        best = 0.0\n",
        "        for _, _, R in ref_complexes:\n",
        "            best = max(best, best_jaccard(C, R))\n",
        "        scores.append(best)\n",
        "        weights.append(len(C))\n",
        "    return float(np.average(scores, weights=weights)) if weights else np.nan\n",
        "\n",
        "def recovery_precision(pred_clusters, ref_complexes, j_thr=0.2):\n",
        "    ref_hit = 0\n",
        "    for _, _, R in ref_complexes:\n",
        "        if len(pred_clusters) and max(best_jaccard(R, C) for _, C in pred_clusters) >= j_thr:\n",
        "            ref_hit += 1\n",
        "    cl_hit = 0\n",
        "    for _, C in pred_clusters:\n",
        "        if len(ref_complexes) and max(best_jaccard(C, R) for _, _, R in ref_complexes) >= j_thr:\n",
        "            cl_hit += 1\n",
        "    rec = ref_hit / max(1, len(ref_complexes))\n",
        "    prec = cl_hit / max(1, len(pred_clusters))\n",
        "    f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
        "    return float(rec), float(prec), float(f1)\n",
        "\n",
        "row = {\n",
        "    \"cluster_col\": CLUSTER_COL,\n",
        "    \"n_clusters_used\": len(pred_clusters),\n",
        "    \"weighted_best_jaccard\": weighted_best_jaccard(pred_clusters, corum_complexes_gene),\n",
        "    \"n_corum_complexes_used\": len(corum_complexes_gene),\n",
        "    \"n_uniprot_mapped\": len(up2gene),\n",
        "}\n",
        "for thr in JACCARD_THR_LIST:\n",
        "    rec, prec, f1 = recovery_precision(pred_clusters, corum_complexes_gene, j_thr=float(thr))\n",
        "    row[f\"recovery@{thr}\"] = rec\n",
        "    row[f\"precision@{thr}\"] = prec\n",
        "    row[f\"F1@{thr}\"] = f1\n",
        "\n",
        "df_corum_jacc = pd.DataFrame([row])\n",
        "display(df_corum_jacc)\n",
        "df_corum_jacc.to_csv(\"corum_cluster_validation_jaccard.csv\", index=False)\n",
        "print(\"Saved: corum_cluster_validation_jaccard.csv\")\n",
        "\n",
        "# =========================================================\n",
        "# (B) Enrichment-based validation (hypergeometric + BH-FDR)\n",
        "# =========================================================\n",
        "from scipy.stats import hypergeom\n",
        "\n",
        "def hypergeom_sf(k, K, n, M):\n",
        "    # P(X >= k) where X ~ Hypergeom(M, K, n)\n",
        "    return float(hypergeom.sf(k-1, M, K, n))\n",
        "\n",
        "# Universe = (genes in graph) ∩ (genes that appear in CORUM after mapping)\n",
        "universe_graph = set(df_clusters[\"gene_final\"].dropna().astype(str).str.strip().str.upper().tolist())\n",
        "universe_graph.discard(\"NAN\")\n",
        "universe_corum = set().union(*[R for _, _, R in corum_complexes_gene]) if len(corum_complexes_gene) else set()\n",
        "universe = universe_graph & universe_corum\n",
        "M = len(universe)\n",
        "print(\"Universe genes (graph ∩ CORUM):\", M, f\"(graph={len(universe_graph)}, corum={len(universe_corum)})\")\n",
        "\n",
        "enrich_rows = []\n",
        "for cid, C in pred_clusters:\n",
        "    C = set([g for g in C if g in universe])\n",
        "    n = len(C)\n",
        "    if n < MIN_CLUSTER_SIZE:\n",
        "        continue\n",
        "\n",
        "    for cor_id, cor_name, R in corum_complexes_gene:\n",
        "        R = set([g for g in R if g in universe])\n",
        "        K = len(R)\n",
        "        if K < MIN_COMPLEX_SIZE:\n",
        "            continue\n",
        "\n",
        "        k = len(C & R)\n",
        "        if k < MIN_OVERLAP_K:\n",
        "            continue\n",
        "\n",
        "        p = hypergeom_sf(k=k, K=K, n=n, M=M)\n",
        "        enrich_rows.append({\n",
        "            \"cluster_col\": CLUSTER_COL,\n",
        "            \"cluster_id\": int(cid),\n",
        "            \"cluster_size\": int(n),\n",
        "            \"corum_id\": int(cor_id),\n",
        "            \"corum_name\": cor_name,\n",
        "            \"complex_size\": int(K),\n",
        "            \"overlap_k\": int(k),\n",
        "            \"pval\": p,\n",
        "            \"overlap_genes\": \";\".join(sorted(C & R)[:60]),\n",
        "        })\n",
        "\n",
        "df_enrich = pd.DataFrame(enrich_rows)\n",
        "if len(df_enrich) == 0:\n",
        "    print(f\"No overlaps found with overlap_k>={MIN_OVERLAP_K} between clusters and CORUM complexes (after mapping).\")\n",
        "else:\n",
        "    df_enrich[\"qval\"] = bh_fdr(df_enrich[\"pval\"].values)\n",
        "    df_enrich = df_enrich.sort_values([\"qval\", \"pval\", \"overlap_k\"], ascending=[True, True, False])\n",
        "\n",
        "    # best hit per cluster (paper table)\n",
        "    df_best = (df_enrich.sort_values([\"cluster_id\", \"qval\", \"pval\", \"overlap_k\"],\n",
        "                                     ascending=[True, True, True, False])\n",
        "                      .groupby(\"cluster_id\")\n",
        "                      .head(1)\n",
        "                      .reset_index(drop=True))\n",
        "\n",
        "    display(df_best.head(20))\n",
        "    df_best.to_csv(\"corum_cluster_enrichment_besthit.csv\", index=False)\n",
        "    print(\"Saved: corum_cluster_enrichment_besthit.csv\")\n",
        "\n",
        "    frac_sig = float((df_best[\"qval\"] <= 0.05).mean()) if len(df_best) else 0.0\n",
        "    print(f\"Fraction of clusters with >=1 CORUM complex enriched at FDR<=0.05: {frac_sig:.3f}\")\n",
        "\n",
        "    print(\"Diagnostics:\")\n",
        "    print(\"  Max overlap_k:\", int(df_enrich[\"overlap_k\"].max()))\n",
        "    print(\"  Best qval:\", float(df_enrich[\"qval\"].min()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gUYkqgs0meP1",
      "metadata": {
        "id": "gUYkqgs0meP1"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 16) DISEASE ENRICHMENT PER CLUSTER (Enrichr API)  [FIX 400 addList]\n",
        "# =========================\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "\n",
        "assert \"df_clusters\" in globals()\n",
        "assert \"gene_final\" in df_clusters.columns\n",
        "\n",
        "ENRICHR_BASE = \"https://maayanlab.cloud/Enrichr\"\n",
        "\n",
        "def clean_genes(glist):\n",
        "    out = []\n",
        "    for g in glist:\n",
        "        g = str(g).strip()\n",
        "        if not g or g.lower() == \"nan\":\n",
        "            continue\n",
        "        g = re.sub(r\"[^A-Za-z0-9\\-]\", \"\", g)\n",
        "        if not g:\n",
        "            continue\n",
        "        out.append(g.upper())\n",
        "    # unique preserve order\n",
        "    seen, uniq = set(), []\n",
        "    for g in out:\n",
        "        if g not in seen:\n",
        "            uniq.append(g); seen.add(g)\n",
        "    return uniq\n",
        "\n",
        "def enrichr_add_list(gene_list, description=\"gene_list\", max_genes=1500):\n",
        "    # Enrichr μπορεί να απορρίψει πολύ μεγάλα lists → κράτα ένα safe όριο\n",
        "    if len(gene_list) > max_genes:\n",
        "        gene_list = gene_list[:max_genes]\n",
        "\n",
        "    gene_str = \"\\n\".join(gene_list)\n",
        "\n",
        "    # IMPORTANT: Enrichr expects multipart form-data\n",
        "    files = {\n",
        "        \"list\": (None, gene_str),\n",
        "        \"description\": (None, description),\n",
        "    }\n",
        "\n",
        "    r = requests.post(f\"{ENRICHR_BASE}/addList\", files=files, timeout=120)\n",
        "\n",
        "    # debug message if 400\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"addList failed ({r.status_code}): {r.text[:300]}\")\n",
        "\n",
        "    js = r.json()\n",
        "    if \"userListId\" not in js:\n",
        "        raise RuntimeError(f\"Unexpected addList response: {js}\")\n",
        "    return js[\"userListId\"]\n",
        "\n",
        "def enrichr_enrich(user_list_id, library):\n",
        "    r = requests.get(\n",
        "        f\"{ENRICHR_BASE}/enrich\",\n",
        "        params={\"userListId\": user_list_id, \"backgroundType\": library},\n",
        "        timeout=120\n",
        "    )\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"enrich failed ({r.status_code}): {r.text[:300]}\")\n",
        "    js = r.json()\n",
        "    if library not in js:\n",
        "        raise RuntimeError(f\"Library '{library}' not in response keys: {list(js.keys())[:10]}\")\n",
        "    data = js.get(library, [])\n",
        "    cols = [\"rank\",\"term\",\"pvalue\",\"zscore\",\"combined_score\",\"overlap_genes\",\"adj_pvalue\",\"old_pvalue\",\"old_adj_pvalue\"]\n",
        "    return pd.DataFrame(data, columns=cols)\n",
        "\n",
        "# πιο “σίγουρα” libraries\n",
        "DISEASE_LIBS = [\n",
        "    \"DisGeNET\",\n",
        "    \"OMIM_Disease\",\n",
        "    \"GWAS_Catalog_2019\",\n",
        "]\n",
        "\n",
        "MIN_CLUSTER_SIZE = 15\n",
        "TOP_TERMS_PER_CLUSTER = 10\n",
        "SLEEP_BETWEEN_LISTS = 0.5\n",
        "\n",
        "# Choose which clustering label columns to evaluate.\n",
        "# 1) keep original expected columns (if present)\n",
        "# 2) automatically include any LP-embedding clustering columns we created (lp_*_kmeans / lp_*_knn_louvain / lp_*_knn_leiden)\n",
        "# 3) also include any other column that looks like a clustering assignment\n",
        "import re\n",
        "cluster_cols = []\n",
        "# original / classic columns\n",
        "for c in [\"edge_mlp_kmeans\", \"kmeans_cluster\", \"louvain_cluster\", \"leiden_cluster\"]:\n",
        "    if c in df_clusters.columns:\n",
        "        cluster_cols.append(c)\n",
        "\n",
        "# LP embedding clustering columns\n",
        "for c in df_clusters.columns:\n",
        "    if c in cluster_cols:\n",
        "        continue\n",
        "    if re.match(r\"^lp_.*_(kmeans|knn_louvain|knn_leiden)$\", str(c)):\n",
        "        cluster_cols.append(c)\n",
        "\n",
        "# fallback: any integer-ish column with 'kmeans/louvain/leiden' in its name\n",
        "for c in df_clusters.columns:\n",
        "    if c in cluster_cols:\n",
        "        continue\n",
        "    if re.search(r\"(kmeans|louvain|leiden)\", str(c), flags=re.IGNORECASE):\n",
        "        try:\n",
        "            if pd.api.types.is_integer_dtype(df_clusters[c]) or pd.api.types.is_numeric_dtype(df_clusters[c]):\n",
        "                cluster_cols.append(c)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "print(\"Disease enrichment will run for cluster_cols:\", cluster_cols)\n",
        "\n",
        "if not cluster_cols:\n",
        "    raise ValueError(\"No cluster labels found in df_clusters.\")\n",
        "\n",
        "all_results = []\n",
        "fail_counts = {}\n",
        "\n",
        "for ccol in cluster_cols:\n",
        "    for cid, sub in df_clusters.groupby(ccol):\n",
        "        genes = sub[\"gene_final\"].dropna().astype(str).unique().tolist()\n",
        "        genes = clean_genes(genes)\n",
        "\n",
        "        if len(genes) < MIN_CLUSTER_SIZE:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            ulid = enrichr_add_list(genes, description=f\"{ccol}:{cid}\", max_genes=1500)\n",
        "        except Exception as e:\n",
        "            print(\"Enrichr addList failed for\", ccol, cid, \":\", repr(e))\n",
        "            continue\n",
        "\n",
        "        time.sleep(SLEEP_BETWEEN_LISTS)\n",
        "\n",
        "        for lib in DISEASE_LIBS:\n",
        "            try:\n",
        "                df_en = enrichr_enrich(ulid, lib).head(TOP_TERMS_PER_CLUSTER).copy()\n",
        "                df_en[\"cluster_col\"] = ccol\n",
        "                df_en[\"cluster_id\"] = int(cid)\n",
        "                df_en[\"n_genes_sent\"] = min(len(genes), 1500)\n",
        "                df_en[\"library\"] = lib\n",
        "                all_results.append(df_en)\n",
        "            except Exception as e:\n",
        "                fail_counts[lib] = fail_counts.get(lib, 0) + 1\n",
        "                print(\"Enrichr enrich failed for\", lib, ccol, cid, \":\", repr(e))\n",
        "\n",
        "df_disease = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()\n",
        "display(df_disease.head(20))\n",
        "\n",
        "df_disease.to_csv(\"cluster_disease_enrichment_enrichr.csv\", index=False)\n",
        "print(\"Saved: cluster_disease_enrichment_enrichr.csv\")\n",
        "\n",
        "if len(df_disease) > 0:\n",
        "    df_best = (df_disease.sort_values([\"cluster_col\",\"cluster_id\",\"library\",\"adj_pvalue\",\"pvalue\"])\n",
        "                        .groupby([\"cluster_col\",\"cluster_id\",\"library\"])\n",
        "                        .head(1)\n",
        "                        .reset_index(drop=True))\n",
        "    df_best.to_csv(\"cluster_disease_enrichment_best_terms.csv\", index=False)\n",
        "    print(\"Saved: cluster_disease_enrichment_best_terms.csv\")\n",
        "\n",
        "if fail_counts:\n",
        "    print(\"Failures per library:\", fail_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JRH0nN0F1Kjw",
      "metadata": {
        "id": "JRH0nN0F1Kjw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_best = pd.read_csv(\"cluster_disease_enrichment_best_terms.csv\")\n",
        "for c in [\"pvalue\",\"adj_pvalue\",\"combined_score\",\"zscore\"]:\n",
        "    df_best[c] = pd.to_numeric(df_best[c], errors=\"coerce\")\n",
        "\n",
        "df_sig = df_best[df_best[\"adj_pvalue\"] < 0.05].copy()\n",
        "df_sig = df_sig.sort_values([\"cluster_col\",\"cluster_id\",\"adj_pvalue\",\"pvalue\"])\n",
        "\n",
        "display(df_sig.head(30))\n",
        "df_sig.to_csv(\"cluster_disease_enrichment_significant.csv\", index=False)\n",
        "print(\"Saved: cluster_disease_enrichment_significant.csv\")\n",
        "print(\"Significant cluster-library pairs:\", len(df_sig), \" | clusters hit:\", df_sig[\"cluster_id\"].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zJT9uqxo1tOW",
      "metadata": {
        "id": "zJT9uqxo1tOW"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "# Διάλεξε disease keyword\n",
        "TARGET = \"breast\"   # π.χ. \"breast\", \"melanoma\", \"liver\", \"prostate\"\n",
        "\n",
        "df_best = pd.read_csv(\"cluster_disease_enrichment_best_terms.csv\")\n",
        "for c in [\"pvalue\",\"adj_pvalue\",\"combined_score\",\"zscore\"]:\n",
        "    df_best[c] = pd.to_numeric(df_best[c], errors=\"coerce\")\n",
        "\n",
        "hits = df_best[\n",
        "    (df_best[\"term\"].str.lower().str.contains(TARGET)) &\n",
        "    (df_best[\"adj_pvalue\"] < 0.05)\n",
        "].sort_values([\"adj_pvalue\",\"pvalue\"])\n",
        "\n",
        "display(hits[[\"cluster_id\",\"library\",\"term\",\"adj_pvalue\",\"overlap_genes\",\"n_genes_sent\"]].head(20))\n",
        "\n",
        "# πάρε το καλύτερο hit (cluster)\n",
        "if len(hits) > 0:\n",
        "    row = hits.iloc[0]\n",
        "    cid = int(row[\"cluster_id\"])\n",
        "    overlap = set(ast.literal_eval(row[\"overlap_genes\"]))\n",
        "    cluster_genes = set(\n",
        "        df_clusters[df_clusters[row[\"cluster_col\"]]==cid][\"gene_final\"]\n",
        "        .dropna().astype(str).str.upper().tolist()\n",
        "    )\n",
        "\n",
        "    candidates = sorted(cluster_genes - overlap)\n",
        "    known = sorted(overlap)\n",
        "\n",
        "    print(\"Chosen cluster:\", cid, \"| term:\", row[\"term\"], \"| adj_pvalue:\", row[\"adj_pvalue\"])\n",
        "    print(\"Known overlap genes:\", len(known))\n",
        "    print(\"Candidate genes (cluster minus overlap):\", len(candidates))\n",
        "    print(\"Top-30 candidates:\", candidates[:30])\n",
        "\n",
        "    pd.DataFrame({\"candidate_gene\": candidates}).to_csv(f\"candidates_{TARGET}_cluster{cid}.csv\", index=False)\n",
        "    print(f\"Saved: candidates_{TARGET}_cluster{cid}.csv\")\n",
        "else:\n",
        "    print(\"No significant hits found for TARGET =\", TARGET)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QcD_kh2j5qMI",
      "metadata": {
        "id": "QcD_kh2j5qMI"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# NEURO ANALYSIS on Enrichr results (from your saved CSVs)\n",
        "# =========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, ast, os\n",
        "\n",
        "# paths you already produced\n",
        "BEST_PATH = \"cluster_disease_enrichment_best_terms.csv\"\n",
        "ALL_PATH  = \"cluster_disease_enrichment_enrichr.csv\"\n",
        "\n",
        "assert os.path.exists(BEST_PATH), f\"Missing {BEST_PATH}\"\n",
        "assert os.path.exists(ALL_PATH),  f\"Missing {ALL_PATH}\"\n",
        "assert \"df_clusters\" in globals(), \"df_clusters not found (run clustering part first).\"\n",
        "assert \"gene_final\" in df_clusters.columns, \"df_clusters must have gene_final.\"\n",
        "\n",
        "df_all  = pd.read_csv(ALL_PATH)\n",
        "for c in [\"pvalue\",\"adj_pvalue\",\"combined_score\",\"zscore\"]:\n",
        "    if c in df_all.columns:\n",
        "        df_all[c] = pd.to_numeric(df_all[c], errors=\"coerce\")\n",
        "\n",
        "# --- neuro keywords (edit as you like) ---\n",
        "NEURO_KW = [\n",
        "    \"epilep\",\"seiz\",\"schiz\",\"autis\",\"dement\",\"alzheimer\",\"parkinson\",\"huntington\",\"ataxia\",\n",
        "    \"intellectual disability\",\"developmental delay\",\"neuropathy\",\"migraine\",\"stroke\",\"multiple sclerosis\",\n",
        "    \"glioma\",\"glioblastoma\",\"brain\"\n",
        "]\n",
        "\n",
        "EXCLUDE_GLIOMA = False   # <- βάλε True αν ΔΕΝ θες tumors/neuro-oncology\n",
        "FDR_THR = 0.05\n",
        "\n",
        "def is_neuro(term: str) -> bool:\n",
        "    t = str(term).lower()\n",
        "    return any(k in t for k in NEURO_KW)\n",
        "\n",
        "def parse_overlap(x):\n",
        "    # overlap_genes comes like \"['A','B']\" usually\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    s = str(x).strip()\n",
        "    try:\n",
        "        v = ast.literal_eval(s)\n",
        "        if isinstance(v, list):\n",
        "            return [str(g).upper().strip() for g in v]\n",
        "    except Exception:\n",
        "        pass\n",
        "    # fallback split\n",
        "    s = s.strip(\"[](){}\")\n",
        "    parts = re.split(r\"[;, \\t]+\", s)\n",
        "    return [p.upper().strip().strip(\"'\").strip('\"') for p in parts if p.strip()]\n",
        "\n",
        "# --- filter neuro + significant ---\n",
        "df_neuro = df_all[df_all[\"term\"].apply(is_neuro)].copy()\n",
        "if EXCLUDE_GLIOMA:\n",
        "    df_neuro = df_neuro[~df_neuro[\"term\"].str.lower().str.contains(\"glioma\")].copy()\n",
        "\n",
        "df_neuro_sig = df_neuro[df_neuro[\"adj_pvalue\"] < FDR_THR].copy()\n",
        "df_neuro_sig = df_neuro_sig.sort_values([\"cluster_col\",\"cluster_id\",\"library\",\"adj_pvalue\",\"pvalue\"])\n",
        "\n",
        "display(df_neuro_sig.head(30))\n",
        "df_neuro_sig.to_csv(\"neuro_enrichment_significant.csv\", index=False)\n",
        "print(\"Saved: neuro_enrichment_significant.csv | rows:\", len(df_neuro_sig), \"| clusters:\", df_neuro_sig[\"cluster_id\"].nunique())\n",
        "\n",
        "# --- best neuro term per cluster (overall) ---\n",
        "df_best_cluster = (df_neuro_sig.sort_values([\"cluster_id\",\"adj_pvalue\",\"pvalue\"])\n",
        "                   .groupby(\"cluster_id\")\n",
        "                   .head(1)\n",
        "                   .reset_index(drop=True))\n",
        "\n",
        "display(df_best_cluster[[\"cluster_id\",\"library\",\"term\",\"adj_pvalue\",\"pvalue\",\"combined_score\",\"n_genes_sent\"]])\n",
        "df_best_cluster.to_csv(\"neuro_best_term_per_cluster.csv\", index=False)\n",
        "print(\"Saved: neuro_best_term_per_cluster.csv\")\n",
        "\n",
        "# --- candidate genes per neuro hit (cluster genes minus overlap genes) ---\n",
        "# We create candidates for EACH (cluster_id, term, library) in df_neuro_sig\n",
        "# (This supports your goal (β): “new genes for a disease”.)\n",
        "\n",
        "out_rows = []\n",
        "for _, row in df_neuro_sig.iterrows():\n",
        "    cid = int(row[\"cluster_id\"])\n",
        "    term = str(row[\"term\"])\n",
        "    lib  = str(row[\"library\"])\n",
        "    overlap = set(parse_overlap(row.get(\"overlap_genes\", \"\")))\n",
        "\n",
        "    # assume kmeans_cluster for now (change if you want Louvain/Leiden)\n",
        "    if \"kmeans_cluster\" not in df_clusters.columns:\n",
        "        continue\n",
        "\n",
        "    cluster_genes = (df_clusters[df_clusters[\"kmeans_cluster\"] == cid][\"gene_final\"]\n",
        "                     .dropna().astype(str).str.upper().unique().tolist())\n",
        "    cluster_genes = [g for g in cluster_genes if g and g.lower() != \"nan\"]\n",
        "    cluster_set = set(cluster_genes)\n",
        "\n",
        "    candidates = sorted(cluster_set - overlap)\n",
        "    out_rows.append({\n",
        "        \"cluster_id\": cid,\n",
        "        \"library\": lib,\n",
        "        \"term\": term,\n",
        "        \"adj_pvalue\": row[\"adj_pvalue\"],\n",
        "        \"pvalue\": row[\"pvalue\"],\n",
        "        \"n_cluster_genes\": len(cluster_set),\n",
        "        \"n_overlap\": len(overlap),\n",
        "        \"n_candidates\": len(candidates),\n",
        "    })\n",
        "\n",
        "    safe_term = re.sub(r\"[^A-Za-z0-9]+\", \"_\", term)[:60]\n",
        "    pd.DataFrame({\"candidate_gene\": candidates}).to_csv(f\"neuro_candidates_cluster{cid}_{safe_term}.csv\", index=False)\n",
        "\n",
        "df_neuro_candidates_index = pd.DataFrame(out_rows).sort_values([\"adj_pvalue\",\"pvalue\"])\n",
        "display(df_neuro_candidates_index.head(30))\n",
        "df_neuro_candidates_index.to_csv(\"neuro_candidates_index.csv\", index=False)\n",
        "print(\"Saved: neuro_candidates_index.csv + one candidates file per significant hit\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3AcU5fDFmeP2",
      "metadata": {
        "id": "3AcU5fDFmeP2"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 17) NEURO DISEASE-CENTRIC DISCOVERY (Open Targets + your Top predicted links)  [FIXED]\n",
        "# =========================\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "assert \"df_top\" in globals(), \"Run the TOP-N prediction section first to create df_top.\"\n",
        "assert \"nodes_annot\" in globals(), \"nodes_annot is needed to map node ids to gene symbols.\"\n",
        "assert {\"node\",\"gene_final\"}.issubset(set(nodes_annot.columns)), \"nodes_annot must have columns node,gene_final\"\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "DISEASE_QUERY = \"Alzheimer's disease\"\n",
        "MIN_OT_SCORE = 0.05\n",
        "MAX_PAGES = 6\n",
        "PAGE_SIZE = 500\n",
        "TOP_K_OUTPUT = 200\n",
        "\n",
        "# OPTIONAL cluster filter\n",
        "USE_NEURO_CLUSTER_FILTER = False\n",
        "NEURO_CLUSTER_IDS = None\n",
        "CLUSTER_COL = \"kmeans_cluster\"\n",
        "\n",
        "OT_GQL = \"https://api.platform.opentargets.org/api/v4/graphql\"\n",
        "\n",
        "def ot_graphql(query, variables=None, timeout=120):\n",
        "    r = requests.post(OT_GQL, json={\"query\": query, \"variables\": variables or {}}, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    if \"errors\" in j:\n",
        "        raise RuntimeError(j[\"errors\"][:1])\n",
        "    return j[\"data\"]\n",
        "\n",
        "# 1) Find disease id\n",
        "q_search = \"\"\"\n",
        "query SearchDisease($q: String!) {\n",
        "  search(queryString: $q, entityNames: [\"disease\"], page: {index: 0, size: 5}) {\n",
        "    total\n",
        "    hits { id name entity }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "data = ot_graphql(q_search, {\"q\": DISEASE_QUERY})\n",
        "hits = data[\"search\"][\"hits\"]\n",
        "if not hits:\n",
        "    raise ValueError(\"No disease match found for query: \" + DISEASE_QUERY)\n",
        "\n",
        "disease_id = hits[0][\"id\"]\n",
        "disease_name = hits[0][\"name\"]\n",
        "print(\"Open Targets disease:\", disease_name, \"| id:\", disease_id)\n",
        "\n",
        "# 2) Fetch associated targets (pagination)\n",
        "q_assoc = \"\"\"\n",
        "query DiseaseTargets($diseaseId: String!, $index: Int!, $size: Int!) {\n",
        "  disease(efoId: $diseaseId) {\n",
        "    id\n",
        "    name\n",
        "    associatedTargets(page: {index: $index, size: $size}) {\n",
        "      count\n",
        "      rows {\n",
        "        score\n",
        "        target { id approvedSymbol }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "all_rows = []\n",
        "total_count = None\n",
        "for page in range(MAX_PAGES):\n",
        "    data = ot_graphql(q_assoc, {\"diseaseId\": disease_id, \"index\": page, \"size\": PAGE_SIZE})\n",
        "    block = data[\"disease\"][\"associatedTargets\"][\"rows\"]\n",
        "    if total_count is None:\n",
        "        total_count = data[\"disease\"][\"associatedTargets\"][\"count\"]\n",
        "        print(\"Total associated targets (OT):\", total_count)\n",
        "    if not block:\n",
        "        break\n",
        "    all_rows.extend(block)\n",
        "    print(f\"Fetched page {page} -> rows={len(block)} | total fetched={len(all_rows)}\")\n",
        "    time.sleep(0.2)\n",
        "\n",
        "seed = pd.DataFrame([{\n",
        "    \"ensg\": r[\"target\"][\"id\"],\n",
        "    \"gene\": r[\"target\"][\"approvedSymbol\"],\n",
        "    \"ot_score\": r[\"score\"],\n",
        "} for r in all_rows])\n",
        "\n",
        "seed = seed.dropna().drop_duplicates(subset=[\"gene\"]).sort_values(\"ot_score\", ascending=False)\n",
        "seed = seed[seed[\"ot_score\"] >= MIN_OT_SCORE].copy()\n",
        "seed[\"gene\"] = seed[\"gene\"].astype(str).str.upper()\n",
        "\n",
        "seed_genes = set(seed[\"gene\"])\n",
        "print(\"Seed genes kept:\", len(seed_genes), \"(score>=\", MIN_OT_SCORE, \")\")\n",
        "\n",
        "seed.to_csv(\"open_targets_seed_genes.csv\", index=False)\n",
        "print(\"Saved: open_targets_seed_genes.csv\")\n",
        "\n",
        "# 3) Ensure df_top has u,v and gene_u,gene_v\n",
        "print(\"df_top columns:\", list(df_top.columns))\n",
        "\n",
        "def pick_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "u_col = pick_col(df_top, [\"u\",\"src\",\"source\",\"node_u\",\"i\",\"row\",\"head\"])\n",
        "v_col = pick_col(df_top, [\"v\",\"dst\",\"target\",\"node_v\",\"j\",\"col\",\"tail\"])\n",
        "if u_col is None or v_col is None:\n",
        "    raise ValueError(f\"Couldn't find endpoints in df_top. cols={list(df_top.columns)}\")\n",
        "\n",
        "df_top2 = df_top.rename(columns={u_col:\"u\", v_col:\"v\"}).copy()\n",
        "\n",
        "# If gene_u/gene_v already exist -> just standardize to uppercase\n",
        "if (\"gene_u\" in df_top2.columns) and (\"gene_v\" in df_top2.columns):\n",
        "    df_top_annot = df_top2.copy()\n",
        "else:\n",
        "    # otherwise, merge from nodes_annot\n",
        "    dfu = nodes_annot[[\"node\",\"gene_final\"]].rename(columns={\"node\":\"u\",\"gene_final\":\"gene_u\"})\n",
        "    dfv = nodes_annot[[\"node\",\"gene_final\"]].rename(columns={\"node\":\"v\",\"gene_final\":\"gene_v\"})\n",
        "    df_top_annot = df_top2.merge(dfu, on=\"u\", how=\"left\").merge(dfv, on=\"v\", how=\"left\")\n",
        "\n",
        "# Clean + keep annotated\n",
        "df_top_annot[\"gene_u\"] = df_top_annot[\"gene_u\"].astype(str).str.upper()\n",
        "df_top_annot[\"gene_v\"] = df_top_annot[\"gene_v\"].astype(str).str.upper()\n",
        "df_top_annot = df_top_annot.replace({\"gene_u\":{\"NAN\":np.nan}, \"gene_v\":{\"NAN\":np.nan}})\n",
        "df_top_annot = df_top_annot.dropna(subset=[\"gene_u\",\"gene_v\"]).copy()\n",
        "\n",
        "print(\"Annotated predicted edges:\", len(df_top_annot))\n",
        "\n",
        "# OPTIONAL: Neuro cluster filter (keeps edges touching selected clusters)\n",
        "if USE_NEURO_CLUSTER_FILTER:\n",
        "    assert \"df_clusters\" in globals()\n",
        "    assert CLUSTER_COL in df_clusters.columns\n",
        "    assert NEURO_CLUSTER_IDS is not None and len(NEURO_CLUSTER_IDS) > 0\n",
        "\n",
        "    neuro_genes = set(\n",
        "        df_clusters[df_clusters[CLUSTER_COL].isin(NEURO_CLUSTER_IDS)][\"gene_final\"]\n",
        "        .dropna().astype(str).str.upper().tolist()\n",
        "    )\n",
        "    before = len(df_top_annot)\n",
        "    df_top_annot = df_top_annot[\n",
        "        df_top_annot[\"gene_u\"].isin(neuro_genes) | df_top_annot[\"gene_v\"].isin(neuro_genes)\n",
        "    ].copy()\n",
        "    print(f\"Neuro cluster filter: kept {len(df_top_annot)}/{before} predicted edges\")\n",
        "\n",
        "# 4) Candidate edges: one endpoint is seed gene, other is not\n",
        "mask = (df_top_annot[\"gene_u\"].isin(seed_genes) & ~df_top_annot[\"gene_v\"].isin(seed_genes)) | \\\n",
        "       (df_top_annot[\"gene_v\"].isin(seed_genes) & ~df_top_annot[\"gene_u\"].isin(seed_genes))\n",
        "df_candidates = df_top_annot[mask].copy()\n",
        "print(\"Candidate edges (seed ↔ non-seed):\", len(df_candidates))\n",
        "\n",
        "seed_map = dict(zip(seed[\"gene\"], seed[\"ot_score\"]))\n",
        "df_candidates[\"seed_ot_score\"] = df_candidates.apply(\n",
        "    lambda r: max(seed_map.get(r[\"gene_u\"], np.nan), seed_map.get(r[\"gene_v\"], np.nan)),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "prob_col = \"prob\" if \"prob\" in df_candidates.columns else (\"score\" if \"score\" in df_candidates.columns else None)\n",
        "if prob_col is None:\n",
        "    raise ValueError(\"df_top must contain a probability-like column (expected 'prob' or 'score').\")\n",
        "\n",
        "df_candidates[\"final_rank_score\"] = df_candidates[prob_col].astype(float) * df_candidates[\"seed_ot_score\"].astype(float)\n",
        "df_candidates = df_candidates.sort_values(\"final_rank_score\", ascending=False)\n",
        "\n",
        "display(df_candidates.head(20))\n",
        "df_candidates.head(TOP_K_OUTPUT).to_csv(\"disease_candidate_edges.csv\", index=False)\n",
        "print(\"Saved: disease_candidate_edges.csv\")\n",
        "\n",
        "# 5) Candidate genes: best score per non-seed gene\n",
        "gene_scores = {}\n",
        "for _, r in df_candidates.iterrows():\n",
        "    gu, gv = str(r[\"gene_u\"]), str(r[\"gene_v\"])\n",
        "    non_seed = gv if gu in seed_genes else gu\n",
        "    s = float(r[\"final_rank_score\"])\n",
        "    if non_seed not in gene_scores or s > gene_scores[non_seed]:\n",
        "        gene_scores[non_seed] = s\n",
        "\n",
        "df_gene_rank = pd.DataFrame({\"gene\": list(gene_scores.keys()), \"rank_score\": list(gene_scores.values())})\n",
        "df_gene_rank = df_gene_rank.sort_values(\"rank_score\", ascending=False)\n",
        "\n",
        "display(df_gene_rank.head(20))\n",
        "df_gene_rank.head(TOP_K_OUTPUT).to_csv(\"disease_candidate_genes.csv\", index=False)\n",
        "print(\"Saved: disease_candidate_genes.csv\")\n",
        "\n",
        "# Plot\n",
        "topn = min(30, len(df_gene_rank))\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(np.arange(topn), df_gene_rank[\"rank_score\"].iloc[:topn].to_numpy())\n",
        "plt.xticks(np.arange(topn), df_gene_rank[\"gene\"].iloc[:topn].tolist(), rotation=60, ha=\"right\")\n",
        "plt.ylabel(\"Candidate score = (model prob) × (OT seed score)\")\n",
        "plt.title(f\"Top candidate genes for {disease_name}\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"disease_candidate_genes_top30.png\", dpi=300)\n",
        "plt.show()\n",
        "print(\"Saved: disease_candidate_genes_top30.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5_QeHxPXmeP2",
      "metadata": {
        "id": "5_QeHxPXmeP2"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 18) OPTIONAL: ROBUSTNESS / STABILITY (multi-seed)  [WORKING + PAPER-READY]\n",
        "# =========================\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Set True only when you really want to run it (it trains multiple times).\n",
        "DO_STABILITY = RUN_HEAVY  # heavy: trains multiple times\n",
        "\n",
        "# Choose which architecture to test for stability:\n",
        "# - recommended: the best model from the comparison table (if already computed)\n",
        "MODEL_FOR_STABILITY = (BEST_MODEL_NAME if \"BEST_MODEL_NAME\" in globals() else \"appnp\")\n",
        "\n",
        "SEEDS = [0, 1, 2, 3, 4]   # paper-friendly: 3-5 seeds (e.g. [0,1,2,3,4])\n",
        "\n",
        "# Use the SAME hyperparams as the comparison (edit if you want)\n",
        "EPOCHS_STAB = 150\n",
        "PATIENCE_STAB = 20\n",
        "NEG_RATIO_STAB = 1.0\n",
        "HIDDEN_STAB = 128\n",
        "EMB_DIM_STAB = 64\n",
        "DROPOUT_STAB = 0.2\n",
        "LR_STAB = 1e-3\n",
        "WEIGHT_DECAY_STAB = 1e-4\n",
        "\n",
        "if DO_STABILITY:\n",
        "    assert \"data_train\" in globals() and \"data_val\" in globals() and \"data_test\" in globals(), \"Missing data splits.\"\n",
        "    assert \"build_model\" in globals() and \"train_linkpred\" in globals(), \"Missing build_model/train_linkpred (run GNN cells first).\"\n",
        "\n",
        "    runs = []\n",
        "    for sd in SEEDS:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"Stability run seed={sd} | model={MODEL_FOR_STABILITY.upper()}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        np.random.seed(sd)\n",
        "        torch.manual_seed(sd)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed_all(sd)\n",
        "\n",
        "        # new model instance per seed\n",
        "        m = build_model(\n",
        "            MODEL_FOR_STABILITY,\n",
        "            in_dim=data_train.num_node_features,\n",
        "            hidden=HIDDEN_STAB,\n",
        "            emb_dim=EMB_DIM_STAB,\n",
        "            dropout=DROPOUT_STAB,\n",
        "            appnp_K=(APPNP_K if \"APPNP_K\" in globals() else 10),\n",
        "            appnp_alpha=(APPNP_ALPHA if \"APPNP_ALPHA\" in globals() else 0.1),\n",
        "        )\n",
        "\n",
        "        m, z_tr, metrics, df_log = train_linkpred(\n",
        "            model_name=MODEL_FOR_STABILITY,\n",
        "            model=m,\n",
        "            data_train=data_train,\n",
        "            data_val=data_val,\n",
        "            data_test=data_test,\n",
        "            epochs=EPOCHS_STAB,\n",
        "            lr=LR_STAB,\n",
        "            weight_decay=WEIGHT_DECAY_STAB,\n",
        "            neg_ratio=NEG_RATIO_STAB,\n",
        "            patience=PATIENCE_STAB,\n",
        "            grad_clip=1.0,\n",
        "            use_amp=True,\n",
        "        )\n",
        "\n",
        "        runs.append({\n",
        "            \"seed\": sd,\n",
        "            \"model\": MODEL_FOR_STABILITY.upper(),\n",
        "            \"test_roc_auc\": float(metrics[\"test_roc_auc\"]),\n",
        "            \"test_ap\": float(metrics[\"test_ap\"]),\n",
        "            \"best_val_ap\": float(metrics[\"best_val_ap\"]),\n",
        "            \"best_epoch\": int(metrics[\"best_epoch\"]) if metrics[\"best_epoch\"] is not None else -1,\n",
        "        })\n",
        "\n",
        "        # cleanup GPU RAM\n",
        "        del m, z_tr, df_log\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    df_stab = pd.DataFrame(runs).sort_values(\"seed\").reset_index(drop=True)\n",
        "    display(df_stab)\n",
        "\n",
        "    metric_cols = [\"test_roc_auc\", \"test_ap\"]\n",
        "    summary = df_stab[metric_cols].agg([\"mean\", \"std\"]).T.reset_index().rename(columns={\"index\": \"metric\"})\n",
        "    display(summary)\n",
        "\n",
        "    df_stab.to_csv(\"stability_runs.csv\", index=False)\n",
        "    summary.to_csv(\"stability_summary_mean_std.csv\", index=False)\n",
        "    print(\"Saved: stability_runs.csv\")\n",
        "    print(\"Saved: stability_summary_mean_std.csv\")\n",
        "else:\n",
        "    print(\"DO_STABILITY=False (skip). If you want stability results, set DO_STABILITY = RUN_HEAVY  # heavy: trains multiple times and run this cell.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a6c589",
      "metadata": {
        "id": "83a6c589"
      },
      "source": [
        "## 19) PAPER TABLES: Summary + correlations (external validation vs ML validity)\n",
        "Runs only if outputs exist. Correlations are Spearman (robust)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf3e5f6",
      "metadata": {
        "id": "5bf3e5f6"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 19) PAPER TABLES: Summary + correlations  [paper add-on]\n",
        "# - Reads files created earlier if present\n",
        "# - Produces a compact \"main results\" table + correlation checks\n",
        "# Saves:\n",
        "#  - paper_main_results_table.csv\n",
        "#  - paper_cluster_external_summary.csv\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _safe_read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---- 1) Link prediction summary (if available) ----\n",
        "rows = []\n",
        "\n",
        "# stability summary (multi-seed)\n",
        "df_stab = _safe_read_csv(\"stability_summary_mean_std.csv\")\n",
        "if df_stab is not None and {\"metric\",\"mean\",\"std\"}.issubset(df_stab.columns):\n",
        "    for _, r in df_stab.iterrows():\n",
        "        rows.append({\"block\":\"linkpred_multi_seed\", \"name\":r[\"metric\"], \"value_mean\":float(r[\"mean\"]), \"value_std\":float(r[\"std\"])})\n",
        "\n",
        "# top-k summary\n",
        "df_topk = _safe_read_csv(\"topk_metrics_test.csv\")\n",
        "if df_topk is not None and {\"model\",\"K\",\"precision_at_K\",\"recall_at_K\"}.issubset(df_topk.columns):\n",
        "    # keep a few Ks (100, 1000, 10000)\n",
        "    df_keep = df_topk[df_topk[\"K\"].isin([100, 1000, 10000])].copy()\n",
        "    for _, r in df_keep.iterrows():\n",
        "        rows.append({\"block\":\"topk\", \"name\":f\"{r['model']}_P@{int(r['K'])}\", \"value_mean\":float(r[\"precision_at_K\"]), \"value_std\":np.nan})\n",
        "\n",
        "# calibration summary\n",
        "if os.path.exists(\"calibration_bins.csv\"):\n",
        "    df_bins = _safe_read_csv(\"calibration_bins.csv\")\n",
        "    if df_bins is not None:\n",
        "        rows.append({\"block\":\"calibration\", \"name\":\"calibration_bins\", \"value_mean\":len(df_bins), \"value_std\":np.nan})\n",
        "\n",
        "# ---- 2) Clustering + external validation summary ----\n",
        "# CORUM besthit (cluster-level)\n",
        "df_corum = None\n",
        "for p in [\"corum_cluster_enrichment_besthit.csv\", \"corum_cluster_enrichment_besthit (1).csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        df_corum = _safe_read_csv(p); break\n",
        "\n",
        "# disease best terms\n",
        "df_dis = None\n",
        "for p in [\"cluster_disease_enrichment_best_terms.csv\",\n",
        "          \"cluster_disease_enrichment_best_terms (1).csv\",\n",
        "          \"cluster_disease_enrichment_best_terms (2).csv\",\n",
        "          \"cluster_disease_enrichment_best_terms (3).csv\",\n",
        "          \"cluster_disease_enrichment_best_terms (4).csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        df_dis = _safe_read_csv(p); break\n",
        "\n",
        "# GO summary if exists (you may have df_go_summary already saved; try common)\n",
        "df_go_sum = None\n",
        "for p in [\"go_enrichment_cluster_summary.csv\", \"go_enrichment_summary.csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        df_go_sum = _safe_read_csv(p); break\n",
        "\n",
        "# GNN validity (per clustering)\n",
        "df_valid = _safe_read_csv(\"gnn_cluster_validity_scores.csv\")\n",
        "\n",
        "cluster_summary_rows = []\n",
        "\n",
        "if df_corum is not None and \"qval\" in df_corum.columns:\n",
        "    frac_sig = float((df_corum[\"qval\"] <= 0.05).mean())\n",
        "    cluster_summary_rows.append({\"source\":\"CORUM\", \"metric\":\"fraction_clusters_sig_FDR<=0.05\", \"value\":frac_sig})\n",
        "    cluster_summary_rows.append({\"source\":\"CORUM\", \"metric\":\"median_-log10q\", \"value\":float(np.median(-np.log10(np.maximum(df_corum[\"qval\"].values, 1e-300))))})\n",
        "\n",
        "if df_dis is not None:\n",
        "    # try to find q-value column\n",
        "    qcol = None\n",
        "    for c in df_dis.columns:\n",
        "        if c.lower() in [\"qval\",\"fdr\",\"adj_p\",\"adjusted_p\",\"fdr_p\",\"p_adj\"]:\n",
        "            qcol = c; break\n",
        "    if qcol is not None:\n",
        "        frac_sig = float((df_dis[qcol].values <= 0.05).mean())\n",
        "        cluster_summary_rows.append({\"source\":\"Disease\", \"metric\":\"fraction_clusters_sig_FDR<=0.05\", \"value\":frac_sig})\n",
        "\n",
        "if df_valid is not None and \"auc_intra_vs_inter\" in df_valid.columns:\n",
        "    best = df_valid.sort_values(\"auc_intra_vs_inter\", ascending=False).iloc[0]\n",
        "    cluster_summary_rows.append({\"source\":\"ML_validity\", \"metric\":\"best_clustering\", \"value\":best[\"clustering\"]})\n",
        "    cluster_summary_rows.append({\"source\":\"ML_validity\", \"metric\":\"best_auc_intra_vs_inter\", \"value\":float(best[\"auc_intra_vs_inter\"])})\n",
        "\n",
        "df_cluster_external = pd.DataFrame(cluster_summary_rows)\n",
        "display(df_cluster_external)\n",
        "df_cluster_external.to_csv(\"paper_cluster_external_summary.csv\", index=False)\n",
        "print(\"Saved: paper_cluster_external_summary.csv\")\n",
        "\n",
        "# ---- 3) Main results table ----\n",
        "df_main = pd.DataFrame(rows)\n",
        "display(df_main.head(20))\n",
        "df_main.to_csv(\"paper_main_results_table.csv\", index=False)\n",
        "print(\"Saved: paper_main_results_table.csv\")\n",
        "\n",
        "# ---- 4) Optional: Spearman correlations (if we have per-cluster signals) ----\n",
        "# NOTE: Requires per-cluster cohesion (Section 11C) to be computed. This is optional/heavy.\n",
        "if os.path.exists(\"cluster_cohesion_scores.csv\") and df_corum is not None:\n",
        "    from scipy.stats import spearmanr\n",
        "    df_coh = _safe_read_csv(\"cluster_cohesion_scores.csv\")\n",
        "    if df_coh is not None and {\"cluster_id\",\"cohesion_gap\"}.issubset(df_coh.columns) and \"cluster_id\" in df_corum.columns:\n",
        "        tmp = df_coh.merge(df_corum[[\"cluster_id\",\"qval\"]], on=\"cluster_id\", how=\"inner\")\n",
        "        if len(tmp) >= 5:\n",
        "            x = tmp[\"cohesion_gap\"].values\n",
        "            y = -np.log10(np.maximum(tmp[\"qval\"].values, 1e-300))\n",
        "            rho, p = spearmanr(x, y)\n",
        "            print(f\"Spearman(cohesion_gap, -log10(CORUM q)) = {rho:.3f} (p={p:.3g})  n={len(tmp)}\")\n",
        "        else:\n",
        "            print(\"Not enough overlapping clusters for correlation (need >=5).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5ffd2d",
      "metadata": {
        "id": "fd5ffd2d"
      },
      "source": [
        "# 🔬 Advanced graph clustering evaluation & deep-clustering add-ons (v23, additive)\n",
        "\n",
        "**Σημαντικό:** Δεν αφαιρείται τίποτα από το υπάρχον notebook. Τα παρακάτω είναι *επιπλέον* cells/sections για:\n",
        "- supervised + unsupervised metrics (ARI/NMI/AMI + modularity/conductance/coverage κ.λπ.)\n",
        "- baselines: Spectral, Node2Vec+KMeans, GAE/VGAE+KMeans\n",
        "- σύγκριση με plots (trade-off clustering vs link prediction)\n",
        "- προαιρετικά GO/Disease enrichment ως *βιολογικό annotation* των clusters (όχι ground truth)\n",
        "\n",
        "> Tip: Αν τρέχεις σε Colab, άφησε το environment όπως είναι. Τα «βαριά» pip installs είναι προαιρετικά και *δεν* κάνουν forced numpy/torch uninstall.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfad052",
      "metadata": {
        "id": "bdfad052"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 0) OPTIONAL ENV SETUP (safe; no forced numpy/torch uninstall)\n",
        "# =========================\n",
        "# Default: do NOTHING. Enable only if σου λείπουν βιβλιοθήκες.\n",
        "RUN_OPTIONAL_SETUP = True\n",
        "\n",
        "# Enable/disable biological annotation steps:\n",
        "RUN_GO_ENRICHMENT      = True   # GO/Pathway annotation via g:Profiler (optional internet)\n",
        "RUN_DISEASE_ENRICHMENT = True   # disease/phenotype annotation (depends on your existing pipeline/files)\n",
        "\n",
        "if RUN_OPTIONAL_SETUP:\n",
        "    import sys, subprocess\n",
        "\n",
        "    def pip_install(pkgs):\n",
        "        print(\"pip install:\", pkgs)\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-U\", *pkgs])\n",
        "\n",
        "    # Lightweight add-ons (do not touch numpy/torch):\n",
        "    pip_install([\"python-louvain\", \"gprofiler-official\", \"umap-learn\"])\n",
        "\n",
        "    # Optional: Leiden community detection\n",
        "    try:\n",
        "        pip_install([\"igraph\", \"leidenalg\"])\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Leiden optional install failed:\", e)\n",
        "\n",
        "    print(\"✅ Optional setup done. If you installed anything, restart the runtime/kernel once.\")\n",
        "else:\n",
        "    print(\"🟦 Optional setup skipped (recommended).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7797a420",
      "metadata": {
        "id": "7797a420"
      },
      "source": [
        "# 23) Supervised + Unsupervised Clustering Metrics (CORUM ως *ground truth*)\n",
        "\n",
        "Το notebook ήδη χρησιμοποιεί CORUM ως βιολογική εξωτερική «επικύρωση» (enrichment / best-hit).  \n",
        "Εδώ προσθέτουμε και **supervised** μετρικές τύπου ARI/NMI/AMI, με μια πρακτική λύση:\n",
        "\n",
        "- Κάθε κόμβος μπορεί να ανήκει σε *πολλά* CORUM complexes (overlap).\n",
        "- Για να ορίσουμε *single-label* ground truth, κρατάμε **ένα** complex ανά κόμβο με στρατηγική:\n",
        "  - `smallest_complex` (πιο «ειδικό» complex) ή\n",
        "  - `largest_complex` ή\n",
        "  - `first_seen`\n",
        "\n",
        "Οι supervised μετρικές υπολογίζονται **μόνο** για τους κόμβους που έχουν label από CORUM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dddbe081",
      "metadata": {
        "id": "dddbe081"
      },
      "outputs": [],
      "source": [
        "def compute_cluster_metrics(G, labels, name=\"\", gt_labels=None):\n",
        "    \"\"\"Compute clustering metrics on a NetworkX graph partition.\n",
        "\n",
        "    - Always returns the same keys (supervised keys are NaN if gt_labels unavailable).\n",
        "    - labels: array-like of length N (node -> cluster id). Nodes assumed 0..N-1 in G.\n",
        "    - gt_labels: array-like of length N with ground-truth community labels (optional).\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "    from networkx.algorithms.community import quality as nx_quality\n",
        "\n",
        "    # ---- normalize labels ----\n",
        "    lab = np.asarray(labels)\n",
        "    if lab.ndim != 1:\n",
        "        lab = lab.reshape(-1)\n",
        "    # allow NaNs -> -1\n",
        "    if pd.isna(lab).any():\n",
        "        lab = pd.Series(lab).fillna(-1).astype(int).values\n",
        "    else:\n",
        "        lab = lab.astype(int)\n",
        "\n",
        "    N = len(lab)\n",
        "\n",
        "    # ---- communities list ----\n",
        "    comm = {}\n",
        "    for node, c in enumerate(lab):\n",
        "        comm.setdefault(int(c), []).append(int(node))\n",
        "    communities_list = list(comm.values())\n",
        "\n",
        "    # ---- unsupervised / structural ----\n",
        "    try:\n",
        "        mod = nx_modularity(G, communities_list)\n",
        "    except Exception:\n",
        "        mod = np.nan\n",
        "\n",
        "    try:\n",
        "        cov = nx_quality.coverage(G, communities_list)\n",
        "    except Exception:\n",
        "        cov = np.nan\n",
        "\n",
        "    # conductance per community (mean, median)\n",
        "    def _conductance_one(S):\n",
        "        S = set(S)\n",
        "        if len(S) == 0 or len(S) == len(G):\n",
        "            return np.nan\n",
        "        cut = 0\n",
        "        volS = 0\n",
        "        volNot = 0\n",
        "        for u in S:\n",
        "            du = G.degree(u)\n",
        "            volS += du\n",
        "            for v in G.neighbors(u):\n",
        "                if v not in S:\n",
        "                    cut += 1\n",
        "        for u in set(G.nodes()) - S:\n",
        "            volNot += G.degree(u)\n",
        "        denom = min(volS, volNot)\n",
        "        return (cut / denom) if denom > 0 else np.nan\n",
        "\n",
        "    conds = []\n",
        "    for C in communities_list:\n",
        "        cval = _conductance_one(C)\n",
        "        if not np.isnan(cval):\n",
        "            conds.append(cval)\n",
        "    cond_mean = float(np.mean(conds)) if len(conds) else np.nan\n",
        "    cond_median = float(np.median(conds)) if len(conds) else np.nan\n",
        "\n",
        "    # simple size stats\n",
        "    sizes = np.array([len(C) for C in communities_list], dtype=float) if len(communities_list) else np.array([])\n",
        "    k = int(len(communities_list))\n",
        "\n",
        "    out = {\n",
        "        \"method\": name,\n",
        "        \"k\": k,\n",
        "        \"cluster_size_mean\": float(np.mean(sizes)) if sizes.size else np.nan,\n",
        "        \"cluster_size_std\": float(np.std(sizes)) if sizes.size else np.nan,\n",
        "        \"cluster_size_min\": float(np.min(sizes)) if sizes.size else np.nan,\n",
        "        \"cluster_size_max\": float(np.max(sizes)) if sizes.size else np.nan,\n",
        "        \"modularity\": float(mod) if mod==mod else np.nan,\n",
        "        \"coverage\": float(cov) if cov==cov else np.nan,\n",
        "        \"conductance_mean\": cond_mean,\n",
        "        \"conductance_median\": cond_median,\n",
        "    }\n",
        "\n",
        "    # ---- supervised (optional) ----\n",
        "    supervised_keys = [\"ARI\", \"NMI\", \"AMI\", \"homogeneity\", \"completeness\", \"v_measure\"]\n",
        "    for k0 in supervised_keys:\n",
        "        out[k0] = np.nan\n",
        "\n",
        "    if gt_labels is not None:\n",
        "        gt = np.asarray(gt_labels)\n",
        "        if gt.ndim != 1:\n",
        "            gt = gt.reshape(-1)\n",
        "        # Must align lengths\n",
        "        if len(gt) == N and not pd.isna(gt).all():\n",
        "            try:\n",
        "                from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, adjusted_mutual_info_score\n",
        "                from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score\n",
        "                out[\"ARI\"] = float(adjusted_rand_score(gt, lab))\n",
        "                out[\"NMI\"] = float(normalized_mutual_info_score(gt, lab))\n",
        "                out[\"AMI\"] = float(adjusted_mutual_info_score(gt, lab))\n",
        "                out[\"homogeneity\"] = float(homogeneity_score(gt, lab))\n",
        "                out[\"completeness\"] = float(completeness_score(gt, lab))\n",
        "                out[\"v_measure\"] = float(v_measure_score(gt, lab))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db30dbd",
      "metadata": {
        "id": "2db30dbd"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 23B) Build CORUM single-label ground truth (optional)\n",
        "# Requires:\n",
        "#   - `corum` dataframe loaded earlier\n",
        "#   - mapping from node -> gene/protein symbol used in graph\n",
        "# We'll try to auto-detect a node->gene mapping.\n",
        "# =========================\n",
        "GT_ASSIGN_STRATEGY = \"smallest_complex\"  # {'smallest_complex','largest_complex','first_seen'}\n",
        "\n",
        "def detect_node2gene():\n",
        "    for name in [\"node2gene\", \"node_to_gene\", \"node2name\", \"node2protein\", \"node2symbol\"]:\n",
        "        if name in globals():\n",
        "            return globals()[name], name\n",
        "    return None, None\n",
        "\n",
        "node2gene, node2gene_name = detect_node2gene()\n",
        "print(\"node2gene detected:\", node2gene_name)\n",
        "\n",
        "gt_labels_corum = None\n",
        "\n",
        "if \"corum\" in globals() and node2gene is not None:\n",
        "    cols = {c.lower(): c for c in corum.columns}\n",
        "\n",
        "    gene_col = None\n",
        "    for cand in [\"subunits(gene name)\", \"subunits_gene_name\", \"subunits\"]:\n",
        "        if cand in cols:\n",
        "            gene_col = cols[cand]\n",
        "            break\n",
        "\n",
        "    complex_id_col = None\n",
        "    for cand in [\"complexid\", \"complex_id\"]:\n",
        "        if cand in cols:\n",
        "            complex_id_col = cols[cand]\n",
        "            break\n",
        "    if complex_id_col is None:\n",
        "        for c in corum.columns:\n",
        "            if \"complex\" in c.lower() and \"id\" in c.lower():\n",
        "                complex_id_col = c\n",
        "                break\n",
        "\n",
        "    assert gene_col is not None, f\"Δεν βρήκα gene column στο CORUM. Columns={list(corum.columns)[:20]}\"\n",
        "    assert complex_id_col is not None, f\"Δεν βρήκα ComplexID column στο CORUM. Columns={list(corum.columns)[:20]}\"\n",
        "\n",
        "    # complex -> genes\n",
        "    complex2genes = {}\n",
        "    complex_sizes = {}\n",
        "    for _, row in corum[[complex_id_col, gene_col]].dropna().iterrows():\n",
        "        cid = str(row[complex_id_col])\n",
        "        genes = [g.strip() for g in str(row[gene_col]).replace(\";\", \",\").split(\",\") if g.strip()]\n",
        "        gset = set(genes)\n",
        "        if len(gset)==0:\n",
        "            continue\n",
        "        complex2genes[cid] = gset\n",
        "        complex_sizes[cid] = len(gset)\n",
        "\n",
        "    gene2complexes = defaultdict(list)\n",
        "    for cid, gset in complex2genes.items():\n",
        "        for g in gset:\n",
        "            gene2complexes[g].append(cid)\n",
        "\n",
        "    # node genes in order\n",
        "    if isinstance(node2gene, dict):\n",
        "        N = max(node2gene.keys()) + 1\n",
        "        node_genes = [node2gene.get(i, None) for i in range(N)]\n",
        "    else:\n",
        "        node_genes = list(node2gene)\n",
        "        N = len(node_genes)\n",
        "\n",
        "    gt = np.full(N, -1, dtype=int)\n",
        "    complex_id_to_int = {}\n",
        "    next_id = 0\n",
        "\n",
        "    def choose_complex(cands):\n",
        "        if len(cands)==0:\n",
        "            return None\n",
        "        if GT_ASSIGN_STRATEGY == \"first_seen\":\n",
        "            return cands[0]\n",
        "        if GT_ASSIGN_STRATEGY == \"smallest_complex\":\n",
        "            return min([(complex_sizes.get(cid, 10**9), cid) for cid in cands])[1]\n",
        "        if GT_ASSIGN_STRATEGY == \"largest_complex\":\n",
        "            return max([(complex_sizes.get(cid, -1), cid) for cid in cands])[1]\n",
        "        return cands[0]\n",
        "\n",
        "    for i, g in enumerate(node_genes):\n",
        "        if g is None or (isinstance(g, float) and np.isnan(g)):\n",
        "            continue\n",
        "        g = str(g).strip()\n",
        "        cands = gene2complexes.get(g, [])\n",
        "        cid = choose_complex(cands)\n",
        "        if cid is None:\n",
        "            continue\n",
        "        if cid not in complex_id_to_int:\n",
        "            complex_id_to_int[cid] = next_id\n",
        "            next_id += 1\n",
        "        gt[i] = complex_id_to_int[cid]\n",
        "\n",
        "    gt_labels_corum = gt\n",
        "    print(\"✅ CORUM GT labels built.\")\n",
        "    print(\"GT covered nodes:\", int((gt!=-1).sum()), \"/\", N, \"| complexes:\", next_id)\n",
        "else:\n",
        "    print(\"⚠️ Skipping CORUM GT labels. Need `corum` loaded + node2gene mapping.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4808df01",
      "metadata": {
        "id": "4808df01"
      },
      "source": [
        "# 24) Evaluate *all* clusterings in `df_clusters` (και όσα θα προσθέσουμε)\n",
        "\n",
        "Παράγει unified πίνακα:\n",
        "- Unsupervised: modularity, conductance, coverage, cut_ratio, performance  \n",
        "- Supervised (CORUM): ARI, NMI, AMI, V-measure (μόνο για nodes με CORUM label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d1cada",
      "metadata": {
        "id": "36d1cada"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 24) Bulk evaluation for all clustering columns (ROBUST)\n",
        "# - builds a NetworkX graph if missing (G/G_nx/G_eval)\n",
        "# - always saves metrics CSV\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Get / build NetworkX graph ---\n",
        "if \"G_eval\" in globals():\n",
        "    G_eval = G_eval\n",
        "elif \"G\" in globals():\n",
        "    G_eval = G\n",
        "elif \"G_nx\" in globals():\n",
        "    G_eval = G_nx\n",
        "else:\n",
        "    import networkx as nx\n",
        "    pyg_tmp = None\n",
        "    for nm in [\"data_train\", \"data\", \"data_full\", \"data_lcc\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "            pyg_tmp = globals()[nm]\n",
        "            print(f\"ℹ️ Building NetworkX graph from {nm}.edge_index\")\n",
        "            break\n",
        "    assert pyg_tmp is not None, \"No NetworkX graph (G/G_nx/G_eval) and no PyG Data found to build one.\"\n",
        "    ei = pyg_tmp.edge_index.detach().cpu().numpy()\n",
        "    G_eval = nx.Graph()\n",
        "    G_eval.add_nodes_from(range(int(pyg_tmp.num_nodes)))\n",
        "    G_eval.add_edges_from(ei.T.tolist())\n",
        "\n",
        "# --- df_clusters ---\n",
        "assert \"df_clusters\" in globals(), \"df_clusters missing. Τρέξε πρώτα το clustering section του notebook.\"\n",
        "dfc = df_clusters.copy()\n",
        "\n",
        "assert \"node\" in dfc.columns, \"df_clusters needs 'node' column.\"\n",
        "dfc = dfc.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "exclude = {\"node\", \"gene\", \"protein\", \"symbol\"}\n",
        "cluster_cols = [c for c in dfc.columns if c not in exclude and pd.api.types.is_numeric_dtype(dfc[c])]\n",
        "\n",
        "print(\"Cluster columns detected:\", cluster_cols)\n",
        "\n",
        "gt = globals().get(\"gt_labels_corum\", None)\n",
        "\n",
        "rows = []\n",
        "for col in cluster_cols:\n",
        "    labels = dfc[col].values\n",
        "    if pd.isna(labels).all():\n",
        "        continue\n",
        "    non_na = labels[~pd.isna(labels)]\n",
        "    if len(np.unique(non_na)) < 2:\n",
        "        continue\n",
        "    lab = pd.Series(labels).fillna(-1).astype(int).values\n",
        "    rows.append(compute_cluster_metrics(G_eval, lab, name=col, gt_labels=gt))\n",
        "\n",
        "df_metrics_all = pd.DataFrame(rows)\n",
        "if len(df_metrics_all) == 0:\n",
        "    print(\"⚠️ No valid clustering columns found for evaluation.\")\n",
        "else:\n",
        "    sort_cols = [c for c in [\"ARI\", \"modularity\"] if c in df_metrics_all.columns]\n",
        "    if sort_cols:\n",
        "        df_metrics_all = df_metrics_all.sort_values(sort_cols, ascending=False, na_position=\"last\")\n",
        "    display(df_metrics_all.head(30))\n",
        "\n",
        "df_metrics_all.to_csv(\"clustering_metrics_supervised_unsupervised.csv\", index=False)\n",
        "print(\"✅ Saved: clustering_metrics_supervised_unsupervised.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b9ce8d",
      "metadata": {
        "id": "a3b9ce8d"
      },
      "source": [
        "# 25) Baselines: Spectral clustering + Node2Vec+KMeans (GraphMF family)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be40c61",
      "metadata": {
        "id": "3be40c61"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25A) Choose K (clusters)\n",
        "# =========================\n",
        "if \"K\" not in globals():\n",
        "    K = 20\n",
        "print(\"K =\", K)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a659df5f",
      "metadata": {
        "id": "a659df5f"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25B) Spectral clustering baseline (sparse Laplacian -> eigsh)\n",
        "# =========================\n",
        "RUN_SPECTRAL = True\n",
        "\n",
        "if RUN_SPECTRAL:\n",
        "    import scipy.sparse as sp\n",
        "    import scipy.sparse.linalg as spla\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    n = G_eval.number_of_nodes()\n",
        "    A = nx.to_scipy_sparse_array(G_eval, nodelist=range(n), dtype=float, format=\"csr\")\n",
        "    deg = np.asarray(A.sum(axis=1)).reshape(-1)\n",
        "    deg[deg == 0] = 1.0\n",
        "    D_inv_sqrt = sp.diags(1.0 / np.sqrt(deg))\n",
        "    L = sp.eye(n, format=\"csr\") - D_inv_sqrt @ A @ D_inv_sqrt\n",
        "\n",
        "    k = int(K)\n",
        "    vals, vecs = spla.eigsh(L, k=min(k+1, n-2), which=\"SM\")\n",
        "    order = np.argsort(vals)\n",
        "    vecs = vecs[:, order]\n",
        "    emb = vecs[:, 1:k+1]\n",
        "\n",
        "    spec_labels = KMeans(n_clusters=k, n_init=10, random_state=0).fit_predict(emb)\n",
        "    df_clusters[\"spectral_kmeans\"] = spec_labels\n",
        "\n",
        "    row = compute_cluster_metrics(G_eval, spec_labels, name=\"spectral_kmeans\", gt_labels=gt_labels_corum)\n",
        "    print(\"Spectral metrics:\", row)\n",
        "else:\n",
        "    print(\"🟦 Spectral disabled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eabdbab",
      "metadata": {
        "id": "6eabdbab"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25C) Node2Vec + KMeans (PyG) baseline\n",
        "# =========================\n",
        "RUN_NODE2VEC = True\n",
        "\n",
        "if RUN_NODE2VEC:\n",
        "    try:\n",
        "        import torch\n",
        "        from torch_geometric.nn import Node2Vec\n",
        "        from sklearn.cluster import KMeans\n",
        "\n",
        "        edge_index = None\n",
        "        for name in [\"edge_index\", \"train_edge_index\", \"data_train\", \"data\"]:\n",
        "            if name in globals():\n",
        "                obj = globals()[name]\n",
        "                if hasattr(obj, \"edge_index\"):\n",
        "                    edge_index = obj.edge_index\n",
        "                    break\n",
        "                if isinstance(obj, torch.Tensor) and obj.dim()==2 and obj.size(0)==2:\n",
        "                    edge_index = obj\n",
        "                    break\n",
        "        assert edge_index is not None, \"Couldn't detect edge_index.\"\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        n2v = Node2Vec(\n",
        "            edge_index=edge_index.to(device),\n",
        "            embedding_dim=64,\n",
        "            walk_length=20,\n",
        "            context_size=10,\n",
        "            walks_per_node=5,\n",
        "            num_negative_samples=5,\n",
        "            p=1.0, q=1.0,\n",
        "            sparse=True\n",
        "        ).to(device)\n",
        "\n",
        "        loader = n2v.loader(batch_size=256, shuffle=True, num_workers=0)\n",
        "        opt = torch.optim.SparseAdam(list(n2v.parameters()), lr=0.01)\n",
        "\n",
        "        n2v.train()\n",
        "        EPOCHS = 5\n",
        "        for epoch in range(1, EPOCHS+1):\n",
        "            total_loss = 0\n",
        "            for pos_rw, neg_rw in loader:\n",
        "                opt.zero_grad()\n",
        "                loss = n2v.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                total_loss += float(loss)\n",
        "            print(f\"epoch {epoch:02d} | loss={total_loss/len(loader):.4f}\")\n",
        "\n",
        "        n2v.eval()\n",
        "        emb = n2v.embedding.weight.detach().cpu().numpy()\n",
        "        n2v_labels = KMeans(n_clusters=int(K), n_init=10, random_state=0).fit_predict(emb)\n",
        "        df_clusters[\"node2vec_kmeans\"] = n2v_labels\n",
        "\n",
        "        row = compute_cluster_metrics(G_eval, n2v_labels, name=\"node2vec_kmeans\", gt_labels=gt_labels_corum)\n",
        "        print(\"Node2Vec metrics:\", row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Node2Vec failed (skip):\", repr(e))\n",
        "else:\n",
        "    print(\"🟦 Node2Vec disabled.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd259d46",
      "metadata": {
        "id": "fd259d46"
      },
      "source": [
        "# 26) GAE/VGAE + KMeans με εναλλακτικούς encoders (GCN / GraphSAGE / GAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb1f6e7",
      "metadata": {
        "id": "2bb1f6e7"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 26A) Helpers: link prediction evaluation (inner-product decoder)\n",
        "# =========================\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "def edge_scores_from_embeddings(z, edge_index):\n",
        "    src = z[edge_index[0]]\n",
        "    dst = z[edge_index[1]]\n",
        "    return (src * dst).sum(axis=1)\n",
        "\n",
        "def eval_link_pred(z, pos_edge_index, neg_edge_index):\n",
        "    pos = edge_scores_from_embeddings(z, pos_edge_index)\n",
        "    neg = edge_scores_from_embeddings(z, neg_edge_index)\n",
        "    y_true = np.concatenate([np.ones(len(pos)), np.zeros(len(neg))])\n",
        "    y_score = np.concatenate([pos, neg])\n",
        "    auc = roc_auc_score(y_true, y_score)\n",
        "    ap = average_precision_score(y_true, y_score)\n",
        "    return float(auc), float(ap)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465760d9",
      "metadata": {
        "id": "465760d9"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 26B) Train GAE/VGAE encoders + eval LinkPred + Clustering (NO RandomLinkSplit)\n",
        "# - Fixes PyG RandomLinkSplit edge_index indexing crash\n",
        "# - STRICT: embeddings computed on TRAIN graph only\n",
        "# - Writes: deep_models_linkpred_clustering_metrics.csv\n",
        "# =========================\n",
        "\n",
        "RUN_GAE_VGAE = True\n",
        "MODEL_VARIANTS = [\"GAE_GCN\", \"VGAE_GCN\", \"VGAE_SAGE\", \"VGAE_GAT\"]\n",
        "EPOCHS = 50\n",
        "HID = 64\n",
        "LAT = 32\n",
        "LR = 0.01\n",
        "SEEDS = [0, 1, 2]\n",
        "VAL_FRAC = 0.05\n",
        "TEST_FRAC = 0.10\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "assert \"compute_cluster_metrics\" in globals(), \"compute_cluster_metrics not found. Run the metrics definition cell earlier.\"\n",
        "\n",
        "def eval_link_pred_dot(z_np, pos_edge, neg_edge):\n",
        "    \"\"\"AUC/AP using dot-product decoder. pos_edge/neg_edge numpy [2,E].\"\"\"\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "    def score(u, v):\n",
        "        return (z_np[u] * z_np[v]).sum(axis=1)\n",
        "\n",
        "    pos_s = score(pos_edge[0], pos_edge[1])\n",
        "    neg_s = score(neg_edge[0], neg_edge[1])\n",
        "    y_true = np.concatenate([np.ones_like(pos_s), np.zeros_like(neg_s)])\n",
        "    y_score = np.concatenate([pos_s, neg_s])\n",
        "    return float(roc_auc_score(y_true, y_score)), float(average_precision_score(y_true, y_score))\n",
        "\n",
        "# --- Ensure G_eval exists (NetworkX graph) ---\n",
        "if \"G_eval\" not in globals():\n",
        "    if \"G\" in globals(): G_eval = G\n",
        "    elif \"G_nx\" in globals(): G_eval = G_nx\n",
        "    else:\n",
        "        import networkx as nx\n",
        "        pyg_tmp = None\n",
        "        for nm in [\"data_train\",\"data_lcc\",\"data_full\",\"data\"]:\n",
        "            if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "                pyg_tmp = globals()[nm]\n",
        "                break\n",
        "        assert pyg_tmp is not None, \"No PyG data found to build NetworkX graph.\"\n",
        "        ei = pyg_tmp.edge_index.detach().cpu().numpy()\n",
        "        G_eval = nx.Graph()\n",
        "        G_eval.add_nodes_from(range(int(pyg_tmp.num_nodes)))\n",
        "        G_eval.add_edges_from(ei.T.tolist())\n",
        "        print(\"ℹ️ Built NetworkX graph G_eval from PyG edge_index.\")\n",
        "\n",
        "# --- df_clusters exists ---\n",
        "if \"df_clusters\" not in globals():\n",
        "    n = None\n",
        "    for nm in [\"data_train\",\"data_lcc\",\"data_full\",\"data\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"num_nodes\"):\n",
        "            n = int(globals()[nm].num_nodes)\n",
        "            break\n",
        "    assert n is not None, \"Could not infer num_nodes to create df_clusters.\"\n",
        "    df_clusters = pd.DataFrame({\"node\": np.arange(n)})\n",
        "    print(\"ℹ️ Created minimal df_clusters.\")\n",
        "\n",
        "# --- K exists ---\n",
        "if \"K\" not in globals():\n",
        "    K = 20\n",
        "    print(\"⚠️ K not found -> defaulting K=20 (change if needed).\")\n",
        "\n",
        "if RUN_GAE_VGAE:\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.utils import to_undirected, remove_self_loops, coalesce, negative_sampling\n",
        "    from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GAE, VGAE\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # pick PyG Data\n",
        "    pyg_data = None\n",
        "    for name in [\"data_train\", \"data_lcc\", \"data_full\", \"data\"]:\n",
        "        if name in globals() and hasattr(globals()[name], \"edge_index\"):\n",
        "            pyg_data = globals()[name]\n",
        "            print(f\"✅ Using PyG data: {name}\")\n",
        "            break\n",
        "    assert pyg_data is not None, \"Couldn't find a PyG Data object.\"\n",
        "\n",
        "    # clone to avoid side effects\n",
        "    pyg_data = pyg_data.clone()\n",
        "\n",
        "    # ensure node features exist\n",
        "    if getattr(pyg_data, \"x\", None) is None:\n",
        "        n = int(pyg_data.num_nodes)\n",
        "        deg = torch.bincount(pyg_data.edge_index[0], minlength=n).float().view(-1, 1)\n",
        "        pyg_data.x = deg\n",
        "        print(\"⚠️ No node features found; using degree feature (N x 1).\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"device:\", device)\n",
        "\n",
        "    # --- Build clean undirected edge set (unique edges u<v) ---\n",
        "    edge_index = pyg_data.edge_index\n",
        "    edge_index, _ = remove_self_loops(edge_index)\n",
        "    edge_index = coalesce(edge_index, None, int(pyg_data.num_nodes), int(pyg_data.num_nodes))[0]\n",
        "    edge_index = to_undirected(edge_index)\n",
        "\n",
        "    # unique undirected edges: keep only u < v\n",
        "    u, v = edge_index[0], edge_index[1]\n",
        "    mask = u < v\n",
        "    uv = torch.stack([u[mask], v[mask]], dim=0)  # [2, M_unique]\n",
        "    M = int(uv.size(1))\n",
        "    N = int(pyg_data.num_nodes)\n",
        "\n",
        "    n_test = max(1, int(TEST_FRAC * M))\n",
        "    n_val  = max(1, int(VAL_FRAC  * M))\n",
        "    n_train = M - n_test - n_val\n",
        "    assert n_train > 0, f\"Not enough edges for split: M={M}, val={n_val}, test={n_test}\"\n",
        "\n",
        "    perm = torch.randperm(M)\n",
        "    test_idx = perm[:n_test]\n",
        "    val_idx  = perm[n_test:n_test+n_val]\n",
        "    train_idx = perm[n_test+n_val:]\n",
        "\n",
        "    train_uv = uv[:, train_idx]   # [2, E_train_unique]\n",
        "    val_uv   = uv[:, val_idx]\n",
        "    test_uv  = uv[:, test_idx]\n",
        "\n",
        "    # train graph edge_index should be undirected (both directions)\n",
        "    train_edge_index = to_undirected(train_uv)\n",
        "\n",
        "    # Build train/test Data objects\n",
        "    train_data = Data(x=pyg_data.x, edge_index=train_edge_index, num_nodes=N)\n",
        "    # negatives sampled against FULL graph edges (undirected)\n",
        "    full_edge_index = to_undirected(uv)  # use unique edges expanded -> OK as constraint set\n",
        "    neg_test = negative_sampling(\n",
        "        edge_index=full_edge_index,\n",
        "        num_nodes=N,\n",
        "        num_neg_samples=int(test_uv.size(1)),\n",
        "        method=\"sparse\"\n",
        "    )\n",
        "    test_data = Data(num_nodes=N)\n",
        "    test_data.pos_edge_label_index = test_uv\n",
        "    test_data.neg_edge_label_index = neg_test\n",
        "\n",
        "    # align df_clusters\n",
        "    if \"node\" not in df_clusters.columns:\n",
        "        df_clusters[\"node\"] = np.arange(N)\n",
        "    df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "    if len(df_clusters) != N:\n",
        "        # force alignment\n",
        "        df_clusters = df_clusters.set_index(\"node\").reindex(np.arange(N)).reset_index()\n",
        "        df_clusters.rename(columns={\"index\":\"node\"}, inplace=True)\n",
        "\n",
        "    class WrapEncoder(torch.nn.Module):\n",
        "        def __init__(self, kind, variational=False):\n",
        "            super().__init__()\n",
        "            self.variational = variational\n",
        "            in_dim = int(train_data.num_features)\n",
        "\n",
        "            if kind == \"GCN\":\n",
        "                self.conv1 = GCNConv(in_dim, HID)\n",
        "                if variational:\n",
        "                    self.conv_mu = GCNConv(HID, LAT)\n",
        "                    self.conv_logstd = GCNConv(HID, LAT)\n",
        "                else:\n",
        "                    self.conv2 = GCNConv(HID, LAT)\n",
        "\n",
        "            elif kind == \"SAGE\":\n",
        "                self.conv1 = SAGEConv(in_dim, HID)\n",
        "                if variational:\n",
        "                    self.conv_mu = SAGEConv(HID, LAT)\n",
        "                    self.conv_logstd = SAGEConv(HID, LAT)\n",
        "                else:\n",
        "                    self.conv2 = SAGEConv(HID, LAT)\n",
        "\n",
        "            elif kind == \"GAT\":\n",
        "                self.conv1 = GATConv(in_dim, HID, heads=2, concat=True)\n",
        "                if variational:\n",
        "                    self.conv_mu = GATConv(HID*2, LAT, heads=1, concat=False)\n",
        "                    self.conv_logstd = GATConv(HID*2, LAT, heads=1, concat=False)\n",
        "                else:\n",
        "                    self.conv2 = GATConv(HID*2, LAT, heads=1, concat=False)\n",
        "            else:\n",
        "                raise ValueError(kind)\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index).relu()\n",
        "            if self.variational:\n",
        "                return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "            return self.conv2(x, edge_index)\n",
        "\n",
        "    gt = globals().get(\"gt_labels_corum\", None)\n",
        "    results = []\n",
        "\n",
        "    for seed in SEEDS:\n",
        "        torch.manual_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        for variant in MODEL_VARIANTS:\n",
        "            if variant.startswith(\"GAE_\"):\n",
        "                enc_kind = variant.split(\"_\")[1]\n",
        "                model = GAE(WrapEncoder(enc_kind, variational=False)).to(device)\n",
        "            elif variant.startswith(\"VGAE_\"):\n",
        "                enc_kind = variant.split(\"_\")[1]\n",
        "                model = VGAE(WrapEncoder(enc_kind, variational=True)).to(device)\n",
        "            else:\n",
        "                raise ValueError(variant)\n",
        "\n",
        "            opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "            model.train()\n",
        "            for epoch in range(1, EPOCHS + 1):\n",
        "                opt.zero_grad()\n",
        "                z = model.encode(train_data.x.to(device), train_data.edge_index.to(device))\n",
        "                loss = model.recon_loss(z, train_data.edge_index.to(device))\n",
        "                if isinstance(model, VGAE):\n",
        "                    loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                if epoch % 10 == 0:\n",
        "                    print(f\"[{variant} seed={seed}] epoch {epoch:03d} loss={float(loss):.4f}\")\n",
        "\n",
        "            # embeddings STRICTLY from TRAIN graph\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                z = model.encode(train_data.x.to(device), train_data.edge_index.to(device))\n",
        "                z_np = z.detach().cpu().numpy()\n",
        "\n",
        "            # evaluate on TEST pos/neg\n",
        "            pos = test_data.pos_edge_label_index.detach().cpu().numpy()\n",
        "            neg = test_data.neg_edge_label_index.detach().cpu().numpy()\n",
        "            auc, ap = eval_link_pred_dot(z_np, pos, neg)\n",
        "\n",
        "            # clustering on embeddings\n",
        "            km = KMeans(n_clusters=int(K), n_init=10, random_state=seed).fit(z_np)\n",
        "            cl = km.labels_\n",
        "            col_name = f\"{variant}_kmeans_seed{seed}\"\n",
        "            df_clusters[col_name] = cl\n",
        "\n",
        "            row = compute_cluster_metrics(G_eval, cl, name=col_name, gt_labels=gt)\n",
        "            # make sure AUC/AP always exist\n",
        "            row[\"AUC\"] = auc\n",
        "            row[\"AP\"] = ap\n",
        "            row[\"seed\"] = seed\n",
        "            results.append(row)\n",
        "\n",
        "    df_deep = pd.DataFrame(results)\n",
        "\n",
        "    # ensure columns exist even if gt missing\n",
        "    for col in [\"ARI\", \"NMI\", \"modularity\", \"coverage\", \"AUC\", \"AP\"]:\n",
        "        if col not in df_deep.columns:\n",
        "            df_deep[col] = np.nan\n",
        "\n",
        "    sort_cols = [c for c in [\"ARI\", \"AUC\", \"modularity\"] if c in df_deep.columns]\n",
        "    df_deep = df_deep.sort_values(sort_cols, ascending=False, na_position=\"last\")\n",
        "\n",
        "    display(df_deep.head(30))\n",
        "    df_deep.to_csv(\"deep_models_linkpred_clustering_metrics.csv\", index=False)\n",
        "    print(\"✅ Saved: deep_models_linkpred_clustering_metrics.csv\")\n",
        "else:\n",
        "    print(\"🟦 GAE/VGAE section disabled.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09bdc0a3",
      "metadata": {
        "id": "09bdc0a3"
      },
      "source": [
        "# 27) Comparative plots (trade-off clustering vs link prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d005620f",
      "metadata": {
        "id": "d005620f"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 27A) Build unified results table\n",
        "# =========================\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tables = []\n",
        "if \"df_metrics_all\" in globals():\n",
        "    tables.append(df_metrics_all.copy())\n",
        "\n",
        "if os.path.exists(\"deep_models_linkpred_clustering_metrics.csv\"):\n",
        "    tables.append(pd.read_csv(\"deep_models_linkpred_clustering_metrics.csv\"))\n",
        "\n",
        "df_all = pd.concat(tables, ignore_index=True) if len(tables)>0 else pd.DataFrame()\n",
        "print(\"rows:\", len(df_all))\n",
        "display(df_all.head())\n",
        "\n",
        "df_all.to_csv(\"ALL_methods_metrics.csv\", index=False)\n",
        "print(\"✅ Saved: ALL_methods_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d0037a7",
      "metadata": {
        "id": "6d0037a7"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 27B) Scatter plot\n",
        "# =========================\n",
        "if len(df_all) > 0 and \"AUC\" in df_all.columns:\n",
        "    x_metric = \"ARI\" if \"ARI\" in df_all.columns and df_all[\"ARI\"].notna().any() else \"modularity\"\n",
        "    y_metric = \"AUC\"\n",
        "\n",
        "    plt.figure()\n",
        "    sub = df_all.dropna(subset=[x_metric, y_metric]).copy()\n",
        "    plt.scatter(sub[x_metric].values, sub[y_metric].values)\n",
        "    for _, r in sub.iterrows():\n",
        "        plt.text(r[x_metric], r[y_metric], str(r[\"method\"])[:18], fontsize=7)\n",
        "\n",
        "    plt.xlabel(x_metric)\n",
        "    plt.ylabel(y_metric)\n",
        "    plt.title(\"Trade-off: clustering vs link prediction\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"tradeoff_scatter.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(\"✅ Saved: tradeoff_scatter.png\")\n",
        "else:\n",
        "    print(\"🟦 Scatter skipped (no link prediction metrics found).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d823909e",
      "metadata": {
        "id": "d823909e"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 27C) Bar plot (top-15)\n",
        "# =========================\n",
        "if len(df_all) > 0:\n",
        "    metric = \"ARI\" if \"ARI\" in df_all.columns and df_all[\"ARI\"].notna().any() else \"modularity\"\n",
        "    sub = df_all.dropna(subset=[metric]).sort_values(metric, ascending=False).head(15)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.bar(np.arange(len(sub)), sub[metric].values)\n",
        "    plt.xticks(np.arange(len(sub)), sub[\"method\"].values, rotation=75, ha=\"right\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.title(f\"Top-15 methods by {metric}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"top15_{metric}.png\", dpi=300)\n",
        "    plt.show()\n",
        "    print(f\"✅ Saved: top15_{metric}.png\")\n",
        "else:\n",
        "    print(\"🟦 Bar plot skipped.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a7eb92a",
      "metadata": {
        "id": "5a7eb92a"
      },
      "source": [
        "# 28) GO enrichment ως *annotation* (όχι ground truth)\n",
        "\n",
        "Minimal g:Profiler ανά cluster (προαιρετικό, χρειάζεται internet).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e8afa5",
      "metadata": {
        "id": "71e8afa5"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 28A) Minimal GO enrichment per cluster (g:Profiler) [optional]\n",
        "# =========================\n",
        "if RUN_GO_ENRICHMENT:\n",
        "    try:\n",
        "        from gprofiler import GProfiler\n",
        "        gp = GProfiler(return_dataframe=True)\n",
        "\n",
        "        CLUSTER_SOURCE_FOR_ENRICH = None\n",
        "        for cand in [\"edge_mlp_kmeans\", \"VGAE_GCN_kmeans_seed0\", \"louvain_train\", \"louvain\", \"node2vec_kmeans\", \"spectral_kmeans\"]:\n",
        "            if cand in df_clusters.columns:\n",
        "                CLUSTER_SOURCE_FOR_ENRICH = cand\n",
        "                break\n",
        "        assert CLUSTER_SOURCE_FOR_ENRICH is not None, \"No cluster column found for enrichment.\"\n",
        "\n",
        "        dfc = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "        # Determine gene names per node (prefer gene_final):\n",
        "        if \"gene_final\" in dfc.columns:\n",
        "            genes = dfc[\"gene_final\"].astype(str).values\n",
        "        elif \"gene\" in dfc.columns:\n",
        "            genes = dfc[\"gene\"].astype(str).values\n",
        "        elif \"symbol\" in dfc.columns:\n",
        "            genes = dfc[\"symbol\"].astype(str).values\n",
        "        elif node2gene is not None:\n",
        "            if isinstance(node2gene, dict):\n",
        "                N = max(node2gene.keys()) + 1\n",
        "                genes = np.array([str(node2gene.get(i, \"\")) for i in range(N)], dtype=object)\n",
        "            else:\n",
        "                genes = np.array([str(x) for x in node2gene], dtype=object)\n",
        "        else:\n",
        "            raise ValueError(\"Need gene names for enrichment (df_clusters['gene_final'/'gene'/'symbol'] or node2gene mapping).\")\n",
        "\n",
        "        labels = dfc[CLUSTER_SOURCE_FOR_ENRICH].astype(int).values\n",
        "        K_here = int(len(np.unique(labels)))\n",
        "\n",
        "        enr_rows = []\n",
        "        for c in range(K_here):\n",
        "            idx = np.where(labels == c)[0]\n",
        "            if len(idx) < 5:\n",
        "                continue\n",
        "            gene_list = [g for g in genes[idx] if g and g not in [\"nan\", \"None\", \"\"]]\n",
        "            gene_list = list(dict.fromkeys(gene_list))\n",
        "            if len(gene_list) < 5:\n",
        "                continue\n",
        "\n",
        "            res = gp.profile(\n",
        "                organism=\"hsapiens\",\n",
        "                query=gene_list,\n",
        "                sources=[\"GO:BP\", \"GO:MF\", \"GO:CC\", \"KEGG\", \"REAC\"]\n",
        "            )\n",
        "            if res is None or len(res) == 0:\n",
        "                continue\n",
        "            res = res.sort_values(\"p_value\").head(10).copy()\n",
        "            res[\"cluster_id\"] = c\n",
        "            enr_rows.append(res)\n",
        "\n",
        "        if len(enr_rows) == 0:\n",
        "            print(\"⚠️ No enrichment results.\")\n",
        "        else:\n",
        "            df_go = pd.concat(enr_rows, ignore_index=True)\n",
        "            df_go.to_csv(\"go_enrichment_top10_per_cluster.csv\", index=False)\n",
        "            display(df_go.head(30))\n",
        "            print(\"✅ Saved: go_enrichment_top10_per_cluster.csv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ GO enrichment skipped/failed:\", repr(e))\n",
        "else:\n",
        "    print(\"🟦 GO enrichment disabled.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f297e9",
      "metadata": {
        "id": "72f297e9"
      },
      "source": [
        "# =========================\n",
        "# 30) PhD-level extras (additive): Stability, Overlapping Ground Truth, Robustness, Edge-MLP\n",
        "# =========================\n",
        "This section is **fully optional** and **does not replace** any existing results.\n",
        "It adds:\n",
        "- **Stability across random seeds** (mean ± std + CI)\n",
        "- **Overlapping ground-truth evaluation** for CORUM (best-hit F1), closer to *Yang & Leskovec (2015)* settings where communities can overlap.\n",
        "- **Robustness checks** (edge dropout/noise sensitivity)\n",
        "- **Edge classifier (MLP)** on top of learned node embeddings for stronger link prediction than dot-product (optional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f4c79d",
      "metadata": {
        "id": "23f4c79d"
      },
      "outputs": [],
      "source": [
        "# ---- toggles ----\n",
        "if \"RUN_PHD_EXTRAS\" not in globals(): RUN_PHD_EXTRAS = True\n",
        "\n",
        "if \"RUN_SEED_STABILITY\" not in globals(): RUN_SEED_STABILITY = True\n",
        "if \"RUN_OVERLAP_CORUM_EVAL\" not in globals(): RUN_OVERLAP_CORUM_EVAL = True\n",
        "if \"RUN_ROBUSTNESS_CHECKS\" not in globals(): RUN_ROBUSTNESS_CHECKS = False   # can be slow\n",
        "if \"RUN_EDGE_MLP\" not in globals(): RUN_EDGE_MLP = True                    # optional\n",
        "RUN_EDGE_MLP = True\n",
        "\n",
        "# ---- seed sweep defaults ----\n",
        "if \"SEED_LIST\" not in globals(): SEED_LIST = [0, 1, 2, 3, 4]\n",
        "if \"ROBUSTNESS_DROPOUT_LIST\" not in globals(): ROBUSTNESS_DROPOUT_LIST = [0.0, 0.05, 0.10, 0.20]\n",
        "\n",
        "print(\"RUN_PHD_EXTRAS:\", RUN_PHD_EXTRAS)\n",
        "print(\"RUN_SEED_STABILITY:\", RUN_SEED_STABILITY)\n",
        "print(\"RUN_OVERLAP_CORUM_EVAL:\", RUN_OVERLAP_CORUM_EVAL)\n",
        "print(\"RUN_ROBUSTNESS_CHECKS:\", RUN_ROBUSTNESS_CHECKS)\n",
        "print(\"RUN_EDGE_MLP:\", RUN_EDGE_MLP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb14d814",
      "metadata": {
        "id": "eb14d814"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Helper utilities (safe + lightweight)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _labels_to_communities(labels):\n",
        "    comm = {}\n",
        "    for i,c in enumerate(labels):\n",
        "        if c is None or (isinstance(c, float) and np.isnan(c)):\n",
        "            continue\n",
        "        comm.setdefault(int(c), []).append(int(i))\n",
        "    return list(comm.values())\n",
        "\n",
        "def best_hit_f1_for_complex(complex_nodes, communities_list):\n",
        "    # For a CORUM complex S and predicted partition {C_k}, compute best-hit F1:\n",
        "    # F1(S, C) = 2|S∩C| / (|S|+|C|)\n",
        "    # Return best F1 and which community index.\n",
        "    S = set(complex_nodes)\n",
        "    best_f1, best_k = 0.0, None\n",
        "    for k, C in enumerate(communities_list):\n",
        "        C = set(C)\n",
        "        inter = len(S & C)\n",
        "        if inter == 0:\n",
        "            continue\n",
        "        f1 = 2.0*inter/(len(S)+len(C))\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_k = f1, k\n",
        "    return best_f1, best_k\n",
        "\n",
        "def overlap_corum_score(complexes, labels):\n",
        "    # complexes: list of iterables of node indices\n",
        "    # labels: length-N array of predicted cluster labels\n",
        "    comms = _labels_to_communities(labels)\n",
        "    f1s = []\n",
        "    sizes = []\n",
        "    for S in complexes:\n",
        "        if len(S) == 0:\n",
        "            continue\n",
        "        f1,_ = best_hit_f1_for_complex(S, comms)\n",
        "        f1s.append(f1)\n",
        "        sizes.append(len(S))\n",
        "    if len(f1s) == 0:\n",
        "        return {\"mean_bestF1\": np.nan, \"median_bestF1\": np.nan, \"size_weighted_bestF1\": np.nan, \"n_complexes\": 0}\n",
        "    f1s = np.array(f1s, dtype=float)\n",
        "    sizes = np.array(sizes, dtype=float)\n",
        "    return {\n",
        "        \"mean_bestF1\": float(np.mean(f1s)),\n",
        "        \"median_bestF1\": float(np.median(f1s)),\n",
        "        \"size_weighted_bestF1\": float(np.sum(f1s*sizes)/np.sum(sizes)),\n",
        "        \"n_complexes\": int(len(f1s))\n",
        "    }\n",
        "\n",
        "def bootstrap_ci(x, n_boot=2000, ci=0.95, seed=0):\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if len(x) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    means = []\n",
        "    for _ in range(n_boot):\n",
        "        samp = rng.choice(x, size=len(x), replace=True)\n",
        "        means.append(np.mean(samp))\n",
        "    lo = np.quantile(means, (1-ci)/2)\n",
        "    hi = np.quantile(means, 1-(1-ci)/2)\n",
        "    return float(lo), float(hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46839baa",
      "metadata": {
        "id": "46839baa"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30A) Stability across seeds (ROBUST)\n",
        "# - Works with:\n",
        "#   (a) df_metrics_all without 'seed' -> single-run summary\n",
        "#   (b) df_deep with 'seed' column\n",
        "#   (c) any DF where seed is encoded inside method like *_seed0\n",
        "# Saves:\n",
        "#   - seed_stability_summary_FIXED.csv\n",
        "# =========================\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# pick metrics df\n",
        "dfm = None\n",
        "if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame) and len(df_deep):\n",
        "    dfm = df_deep.copy()\n",
        "    print(\"✅ Using df_deep from memory\")\n",
        "elif \"df_metrics_all\" in globals() and isinstance(df_metrics_all, pd.DataFrame) and len(df_metrics_all):\n",
        "    dfm = df_metrics_all.copy()\n",
        "    print(\"✅ Using df_metrics_all from memory\")\n",
        "else:\n",
        "    print(\"⚠️ No metrics dataframe found (df_deep / df_metrics_all). Run evaluation cells first.\")\n",
        "\n",
        "if dfm is not None:\n",
        "    # normalize method column name\n",
        "    if \"method\" not in dfm.columns:\n",
        "        # try common alternatives\n",
        "        for alt in [\"name\", \"model\", \"pipeline\"]:\n",
        "            if alt in dfm.columns:\n",
        "                dfm = dfm.rename(columns={alt: \"method\"})\n",
        "                break\n",
        "    assert \"method\" in dfm.columns, \"Need a 'method' column in metrics df.\"\n",
        "\n",
        "    # if seed column missing, try parse from method string\n",
        "    if \"seed\" not in dfm.columns:\n",
        "        seeds = []\n",
        "        for m in dfm[\"method\"].astype(str).values:\n",
        "            mm = re.search(r\"seed(\\d+)\", m)\n",
        "            seeds.append(int(mm.group(1)) if mm else np.nan)\n",
        "        dfm[\"seed\"] = seeds\n",
        "\n",
        "    has_seed = dfm[\"seed\"].notna().any()\n",
        "\n",
        "    # base method: strip trailing _seedX (and keep rest)\n",
        "    dfm[\"method_base\"] = dfm[\"method\"].astype(str).str.replace(r\"_seed\\d+$\", \"\", regex=True)\n",
        "\n",
        "    metric_cols = [c for c in dfm.columns if c not in [\"method\", \"method_base\", \"seed\"] and pd.api.types.is_numeric_dtype(dfm[c])]\n",
        "    if len(metric_cols) == 0:\n",
        "        print(\"⚠️ No numeric metric columns to aggregate.\")\n",
        "    else:\n",
        "        if has_seed:\n",
        "            agg = (dfm.groupby(\"method_base\")[metric_cols]\n",
        "                     .agg([\"mean\",\"std\",\"count\"]))\n",
        "            agg.columns = [f\"{a}_{b}\" for a,b in agg.columns]\n",
        "            agg = agg.reset_index().rename(columns={\"method_base\":\"method\"})\n",
        "            display(agg.sort_values([c for c in agg.columns if c.endswith(\"_mean\")][:1] + [\"method\"], ascending=False).head(20))\n",
        "            agg.to_csv(\"seed_stability_summary_FIXED.csv\", index=False)\n",
        "            print(\"✅ Saved: seed_stability_summary_FIXED.csv\")\n",
        "        else:\n",
        "            # single run -> just reformat as summary\n",
        "            out = dfm[[\"method_base\"] + metric_cols].copy()\n",
        "            out = out.rename(columns={\"method_base\":\"method\"})\n",
        "            display(out.head(20))\n",
        "            out.to_csv(\"seed_stability_summary_FIXED.csv\", index=False)\n",
        "            print(\"✅ Saved: seed_stability_summary_FIXED.csv\")\n",
        "            print(\"⚠️ No seed info detected -> this is a single-run summary (not true seed stability).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rte4pVf3YzOC",
      "metadata": {
        "id": "Rte4pVf3YzOC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load df_deep (memory or csv)\n",
        "if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame) and len(df_deep)>0:\n",
        "    dfm = df_deep.copy()\n",
        "    print(\"✅ Using df_deep from memory\")\n",
        "else:\n",
        "    dfm = pd.read_csv(\"deep_models_linkpred_clustering_metrics.csv\")\n",
        "    print(\"✅ Loaded deep_models_linkpred_clustering_metrics.csv\")\n",
        "\n",
        "# Make sure we have a seed column OR extract it from method-like strings\n",
        "if \"seed\" not in dfm.columns:\n",
        "    # try common columns that store the run name\n",
        "    name_col = \"method\" if \"method\" in dfm.columns else (\"name\" if \"name\" in dfm.columns else None)\n",
        "    assert name_col is not None, \"No seed column and no method/name column to parse seed from.\"\n",
        "    dfm[\"seed\"] = dfm[name_col].astype(str).str.extract(r\"seed(\\d+)\").astype(float).astype(\"Int64\")\n",
        "\n",
        "# Create a base_method that removes the seed suffix (so seeds group together)\n",
        "name_col = \"method\" if \"method\" in dfm.columns else (\"name\" if \"name\" in dfm.columns else None)\n",
        "assert name_col is not None, \"Need a 'method' or 'name' column.\"\n",
        "dfm[\"base_method\"] = dfm[name_col].astype(str).str.replace(r\"_seed\\d+\", \"\", regex=True)\n",
        "\n",
        "# keep numeric metrics only\n",
        "metric_cols = [c for c in dfm.columns\n",
        "               if c not in [name_col, \"method\", \"name\", \"seed\", \"base_method\"]\n",
        "               and pd.api.types.is_numeric_dtype(dfm[c])]\n",
        "\n",
        "# group by base_method across seeds\n",
        "agg = dfm.groupby(\"base_method\")[metric_cols].agg([\"mean\",\"std\",\"count\"])\n",
        "agg.columns = [f\"{a}_{b}\" for a,b in agg.columns]\n",
        "agg = agg.reset_index().rename(columns={\"base_method\":\"method\"})\n",
        "\n",
        "# sort by key metric if exists\n",
        "for key in [\"AUC_mean\",\"AP_mean\",\"ARI_mean\",\"modularity_mean\",\"NMI_mean\"]:\n",
        "    if key in agg.columns:\n",
        "        agg = agg.sort_values(key, ascending=False, na_position=\"last\")\n",
        "        break\n",
        "\n",
        "display(agg.head(30))\n",
        "agg.to_csv(\"seed_stability_summary_FIXED.csv\", index=False)\n",
        "print(\"✅ Saved: seed_stability_summary_FIXED.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TO9865ULfweY",
      "metadata": {
        "id": "TO9865ULfweY"
      },
      "outputs": [],
      "source": [
        "print(\"gt_labels_corum exists?\", \"gt_labels_corum\" in globals())\n",
        "gt = globals().get(\"gt_labels_corum\", None)\n",
        "\n",
        "if gt is None:\n",
        "    print(\"❌ gt_labels_corum is None -> ARI/NMI can't be computed.\")\n",
        "else:\n",
        "    try:\n",
        "        print(\"✅ gt_labels_corum type:\", type(gt))\n",
        "        print(\"✅ gt_labels_corum length:\", len(gt))\n",
        "        if \"df_clusters\" in globals():\n",
        "            print(\"✅ df_clusters rows:\", len(df_clusters))\n",
        "        if \"data_train\" in globals():\n",
        "            print(\"✅ data_train.num_nodes:\", int(data_train.num_nodes))\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ issue inspecting gt_labels_corum:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91dde05",
      "metadata": {
        "id": "a91dde05"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30B) Overlapping CORUM eval (BEST-HIT F1) -- FIXED for your df_corum format\n",
        "# df_corum already contains overlap results per (cluster_col, cluster_id, corum_id)\n",
        "# Columns required: cluster_col, cluster_id, cluster_size, complex_size, overlap_k\n",
        "# Outputs:\n",
        "#  - corum_overlap_besthitF1_by_method.csv\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "if RUN_PHD_EXTRAS and RUN_OVERLAP_CORUM_EVAL:\n",
        "    if \"df_corum\" not in globals():\n",
        "        print(\"⚠️ df_corum not found. Run CORUM overlap creation section first.\")\n",
        "    else:\n",
        "        needed = {\"cluster_col\",\"cluster_id\",\"cluster_size\",\"complex_size\",\"overlap_k\"}\n",
        "        missing = needed - set(df_corum.columns)\n",
        "        if missing:\n",
        "            print(\"Available CORUM columns:\", df_corum.columns.tolist())\n",
        "            raise ValueError(f\"df_corum missing required columns for BEST-HIT F1: {missing}\")\n",
        "\n",
        "        d = df_corum.copy()\n",
        "\n",
        "        # safety: numeric\n",
        "        for c in [\"cluster_size\",\"complex_size\",\"overlap_k\"]:\n",
        "            d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
        "        d = d.dropna(subset=[\"cluster_col\",\"cluster_id\",\"cluster_size\",\"complex_size\",\"overlap_k\"]).copy()\n",
        "\n",
        "        # compute per-row F1 (cluster vs complex)\n",
        "        eps = 1e-12\n",
        "        prec = d[\"overlap_k\"] / (d[\"cluster_size\"] + eps)\n",
        "        rec  = d[\"overlap_k\"] / (d[\"complex_size\"] + eps)\n",
        "        d[\"F1\"] = 2 * prec * rec / (prec + rec + eps)\n",
        "\n",
        "        # BEST-HIT per CORUM complex within each cluster_col:\n",
        "        # For each (cluster_col, corum_id) keep the max F1 over clusters\n",
        "        if \"corum_id\" not in d.columns:\n",
        "            # fallback: use corum_name if id missing\n",
        "            if \"corum_name\" in d.columns:\n",
        "                d[\"corum_id\"] = d[\"corum_name\"].astype(str)\n",
        "            else:\n",
        "                raise ValueError(\"Need corum_id or corum_name in df_corum to group complexes.\")\n",
        "\n",
        "        best_per_complex = (\n",
        "            d.sort_values(\"F1\", ascending=False)\n",
        "             .groupby([\"cluster_col\",\"corum_id\"], as_index=False)\n",
        "             .head(1)\n",
        "        )\n",
        "\n",
        "        # aggregate per method (cluster_col)\n",
        "        summary = (best_per_complex\n",
        "                   .groupby(\"cluster_col\")\n",
        "                   .agg(\n",
        "                       mean_bestF1=(\"F1\",\"mean\"),\n",
        "                       median_bestF1=(\"F1\",\"median\"),\n",
        "                       size_weighted_bestF1=(\"F1\", lambda x: np.average(x, weights=best_per_complex.loc[x.index, \"complex_size\"])),\n",
        "                       n_complexes=(\"corum_id\",\"nunique\")\n",
        "                   )\n",
        "                   .reset_index()\n",
        "                   .sort_values(\"mean_bestF1\", ascending=False))\n",
        "\n",
        "        display(summary)\n",
        "        summary.to_csv(\"corum_overlap_besthitF1_by_method.csv\", index=False)\n",
        "        print(\"✅ Saved: corum_overlap_besthitF1_by_method.csv\")\n",
        "\n",
        "        # optional attach into df_metrics_all if exists\n",
        "        if \"df_metrics_all\" in globals() and \"method\" in df_metrics_all.columns:\n",
        "            dfm2 = df_metrics_all.merge(\n",
        "                summary.rename(columns={\"cluster_col\":\"method\"}),\n",
        "                on=\"method\", how=\"left\"\n",
        "            )\n",
        "            print(\"Attached mean_bestF1/size_weighted_bestF1 to df_metrics_all (where method matches cluster_col).\")\n",
        "            display(dfm2.head())\n",
        "else:\n",
        "    print(\"🟦 Overlap CORUM eval disabled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350752fe",
      "metadata": {
        "id": "350752fe"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30C) Robustness checks: edge dropout sensitivity (graph-only baselines)\n",
        "# =========================\n",
        "if RUN_PHD_EXTRAS and RUN_ROBUSTNESS_CHECKS:\n",
        "    import networkx as nx\n",
        "    from networkx.algorithms import community as nx_comm\n",
        "\n",
        "    if \"G\" not in globals():\n",
        "        print(\"⚠️ NetworkX graph G not found. Build G first.\")\n",
        "    else:\n",
        "        def drop_edges(G_in, p, seed=0):\n",
        "            rng = np.random.default_rng(seed)\n",
        "            edges = list(G_in.edges())\n",
        "            keep = rng.random(len(edges)) > p\n",
        "            G2 = G_in.copy()\n",
        "            G2.remove_edges_from([e for e,k in zip(edges, keep) if not k])\n",
        "            G2.remove_nodes_from(list(nx.isolates(G2)))\n",
        "            return G2\n",
        "\n",
        "        # choose baseline community detection functions available earlier in notebook\n",
        "        # We'll use networkx built-in greedy modularity as fallback if python-louvain not available\n",
        "        def run_louvain_nx(Gx, seed=0):\n",
        "            try:\n",
        "                import community as community_louvain\n",
        "                part = community_louvain.best_partition(Gx, random_state=seed)\n",
        "                labels = np.full(Gx.number_of_nodes(), -1, dtype=int)\n",
        "                node_list = list(Gx.nodes())\n",
        "                node_to_i = {n:i for i,n in enumerate(node_list)}\n",
        "                for n,c in part.items():\n",
        "                    labels[node_to_i[n]] = int(c)\n",
        "                comms = _labels_to_communities(labels)\n",
        "                return labels, comms, node_list\n",
        "            except Exception:\n",
        "                comms = list(nx_comm.greedy_modularity_communities(Gx))\n",
        "                node_list = list(Gx.nodes())\n",
        "                node_to_i = {n:i for i,n in enumerate(node_list)}\n",
        "                labels = np.full(len(node_list), -1, dtype=int)\n",
        "                for k,C in enumerate(comms):\n",
        "                    for n in C:\n",
        "                        labels[node_to_i[n]] = k\n",
        "                return labels, comms, node_list\n",
        "\n",
        "        rows=[]\n",
        "        for p in ROBUSTNESS_DROPOUT_LIST:\n",
        "            Gd = drop_edges(G, p, seed=0)\n",
        "            labels, comms, node_list = run_louvain_nx(Gd, seed=0)\n",
        "            try:\n",
        "                mod = nx_comm.quality.modularity(Gd, comms)\n",
        "            except Exception:\n",
        "                mod = np.nan\n",
        "            rows.append({\"edge_dropout\": p, \"nodes\": Gd.number_of_nodes(), \"edges\": Gd.number_of_edges(), \"modularity\": mod, \"n_comms\": len(comms)})\n",
        "        df_rob = pd.DataFrame(rows)\n",
        "        display(df_rob)\n",
        "        df_rob.to_csv(\"robustness_edge_dropout_louvain.csv\", index=False)\n",
        "        print(\"✅ Saved: robustness_edge_dropout_louvain.csv\")\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure()\n",
        "        plt.plot(df_rob[\"edge_dropout\"], df_rob[\"modularity\"], marker=\"o\")\n",
        "        plt.xlabel(\"Edge dropout probability\")\n",
        "        plt.ylabel(\"Modularity (Louvain/greedy fallback)\")\n",
        "        plt.title(\"Robustness: modularity under edge dropout\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"robustness_modularity_edge_dropout.png\", dpi=300)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249b4b8d",
      "metadata": {
        "id": "249b4b8d"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 30D) Optional: Edge-MLP on top of node embeddings (stronger link prediction)\n",
        "# =========================\n",
        "if RUN_PHD_EXTRAS and RUN_EDGE_MLP:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "    # Expect these from RandomLinkSplit pipeline:\n",
        "    # data_train, data_val, data_test and some node embeddings matrix Z (N x d).\n",
        "    # We'll try to locate an embedding in globals().\n",
        "    Z = None\n",
        "    for name in [\"z_mean\", \"z\", \"Z\", \"emb\", \"node_embeddings\"]:\n",
        "        if name in globals():\n",
        "            try:\n",
        "                cand = globals()[name]\n",
        "                if isinstance(cand, torch.Tensor) and cand.dim()==2:\n",
        "                    Z = cand.detach()\n",
        "                    print(\"Using embeddings:\", name, Z.shape)\n",
        "                    break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    if Z is None:\n",
        "        print(\"⚠️ No torch Tensor embeddings found (e.g., z_mean). Run VGAE/GAE first.\")\n",
        "    elif (\"data_train\" not in globals()) or (\"data_test\" not in globals()):\n",
        "        print(\"⚠️ data_train/data_test not found. Run RandomLinkSplit step first.\")\n",
        "    else:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        Z = Z.to(device)\n",
        "\n",
        "        def edge_features(Z, edge_index, mode=\"hadamard\"):\n",
        "            u = Z[edge_index[0]]\n",
        "            v = Z[edge_index[1]]\n",
        "            if mode==\"hadamard\":\n",
        "                return u*v\n",
        "            elif mode==\"concat\":\n",
        "                return torch.cat([u,v], dim=1)\n",
        "            elif mode==\"l1\":\n",
        "                return torch.abs(u-v)\n",
        "            else:\n",
        "                raise ValueError(\"mode\")\n",
        "\n",
        "        class EdgeMLP(nn.Module):\n",
        "            def __init__(self, in_dim, hidden=128):\n",
        "                super().__init__()\n",
        "                self.net = nn.Sequential(\n",
        "                    nn.Linear(in_dim, hidden),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(0.2),\n",
        "                    nn.Linear(hidden, 1)\n",
        "                )\n",
        "            def forward(self, x):\n",
        "                return self.net(x).view(-1)\n",
        "\n",
        "        # Build train set (pos + neg) using the split's edge labels if available\n",
        "        # PyG RandomLinkSplit usually provides edge_label_index + edge_label\n",
        "        train_ei = getattr(data_train, \"edge_label_index\", None)\n",
        "        train_y  = getattr(data_train, \"edge_label\", None)\n",
        "        test_ei  = getattr(data_test, \"edge_label_index\", None)\n",
        "        test_y   = getattr(data_test, \"edge_label\", None)\n",
        "\n",
        "        if train_ei is None or train_y is None or test_ei is None or test_y is None:\n",
        "            print(\"⚠️ edge_label_index/edge_label not found. Ensure RandomLinkSplit created edge labels.\")\n",
        "        else:\n",
        "            mode = \"hadamard\"\n",
        "            Xtr = edge_features(Z, train_ei.to(device), mode=mode)\n",
        "            ytr = train_y.float().to(device)\n",
        "            Xte = edge_features(Z, test_ei.to(device), mode=mode)\n",
        "            yte = test_y.float().to(device)\n",
        "\n",
        "            model = EdgeMLP(Xtr.shape[1]).to(device)\n",
        "            opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "            for epoch in range(1, 51):\n",
        "                model.train()\n",
        "                logits = model(Xtr)\n",
        "                loss = F.binary_cross_entropy_with_logits(logits, ytr)\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "                if epoch % 10 == 0:\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        p = torch.sigmoid(model(Xte)).detach().cpu().numpy()\n",
        "                        y = yte.detach().cpu().numpy()\n",
        "                        auc = roc_auc_score(y, p)\n",
        "                        ap  = average_precision_score(y, p)\n",
        "                    print(f\"epoch {epoch:03d} | loss {loss.item():.4f} | test AUC {auc:.4f} | AP {ap:.4f}\")\n",
        "\n",
        "            # final metrics\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                p = torch.sigmoid(model(Xte)).detach().cpu().numpy()\n",
        "                y = yte.detach().cpu().numpy()\n",
        "            auc = roc_auc_score(y, p)\n",
        "            ap  = average_precision_score(y, p)\n",
        "            print(\"✅ Edge-MLP results:\", {\"AUC\": auc, \"AP\": ap})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ba72a9",
      "metadata": {
        "id": "38ba72a9"
      },
      "source": [
        "## 25) PhD-level extra μοντέλα: (A) πιο σύνθετο Link Prediction (SEAL-like) + (B) πιο σύνθετο Deep Clustering (DEC refinement) + (C) DMoN end-to-end (προαιρετικό)\n",
        "\n",
        "Παρακάτω **δεν αφαιρείται τίποτα** από τα προηγούμενα. Προσθέτουμε 3 προαιρετικά blocks με flags:\n",
        "\n",
        "- **SEAL-like Link Prediction**: μαθαίνει edge-classifier πάνω σε *k-hop υπογράφους* γύρω από κάθε υποψήφια ακμή (πιο ισχυρό από inner-product decoders).\n",
        "- **DEC (Deep Embedded Clustering) refinement**: κάνει self-training refinement πάνω στα node embeddings (π.χ. από VGAE/Node2Vec), με KL loss σε soft assignments (συνήθως ανεβάζει ARI/NMI αν το embedding “κρύβει” δομή).\n",
        "- **DMoNPooling**: end-to-end community detection που βελτιστοποιεί modularity (αν υπάρχει η κλάση `DMoNPooling` στην έκδοση PyG σου).\n",
        "\n",
        "> ⚠️ Αυτά είναι πιο βαριά compute. Έχουν μικρά default settings για να τρέχουν σε Colab, αλλά μπορείς να αυξήσεις epochs/num_edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b14c5c0",
      "metadata": {
        "id": "0b14c5c0"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25A/B/C) EXTRA FLAGS (leave True/False όπως θες)\n",
        "# =========================\n",
        "if 'RUN_SEAL' not in globals():\n",
        "    RUN_SEAL = False        # πιο βαρύ, άνοιξέ το όταν θες πιο δυνατό link prediction\n",
        "if 'RUN_DEC_REFINEMENT' not in globals():\n",
        "    RUN_DEC_REFINEMENT = True   # ελαφρύ/μεσαίο, καλό για καλύτερο clustering\n",
        "if 'RUN_DMON' not in globals():\n",
        "    RUN_DMON = True        # απαιτεί DMoNPooling στη PyG έκδοση\n",
        "\n",
        "# Defaults (safe για Colab):\n",
        "SEAL_NUM_TRAIN_EDGES = 15000   # πόσες θετικές/αρνητικές ακμές να φτιάξει (σύνολο ~2x)\n",
        "SEAL_NUM_TEST_EDGES  = 5000\n",
        "SEAL_K_HOP = 2                 # 2-hop subgraph (συνήθως αρκετό)\n",
        "SEAL_EPOCHS = 20\n",
        "SEAL_BATCH_SIZE = 64\n",
        "\n",
        "DEC_EPOCHS = 100\n",
        "DEC_LR = 1e-3\n",
        "DEC_HIDDEN = 128\n",
        "DEC_UPDATE_INTERVAL = 10       # κάθε πόσα epochs ανανεώνουμε το target distribution\n",
        "\n",
        "DMON_EPOCHS = 100\n",
        "DMON_LR = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923cfd4e",
      "metadata": {
        "id": "923cfd4e"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25A) SEAL-like Link Prediction (k-hop subgraph GNN classifier)\n",
        "# Inspired by SEAL (Zhang & Chen 2018): κάθε υποψήφια ακμή -> k-hop υπογράφος -> GNN -> πιθανότητα ακμής\n",
        "# =========================\n",
        "if RUN_SEAL:\n",
        "    import math\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch_geometric.utils import negative_sampling, k_hop_subgraph\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.loader import DataLoader\n",
        "    from torch_geometric.nn import GCNConv, global_add_pool\n",
        "\n",
        "    # ---- DRNL node labeling (standard in SEAL) ----\n",
        "    def drnl_node_labeling(edge_index_sub, src, dst, num_nodes):\n",
        "        # Compute distances in the *subgraph* to src and dst (unweighted BFS)\n",
        "        # We use NetworkX for simplicity; for speed you can replace with sparse BFS.\n",
        "        import networkx as nx\n",
        "        Gs = nx.Graph()\n",
        "        Gs.add_nodes_from(range(num_nodes))\n",
        "        Gs.add_edges_from(edge_index_sub.t().tolist())\n",
        "\n",
        "        # shortest paths (if unreachable -> inf)\n",
        "        dist2src = {n: float('inf') for n in range(num_nodes)}\n",
        "        dist2dst = {n: float('inf') for n in range(num_nodes)}\n",
        "        for n, d in nx.single_source_shortest_path_length(Gs, src).items():\n",
        "            dist2src[n] = d\n",
        "        for n, d in nx.single_source_shortest_path_length(Gs, dst).items():\n",
        "            dist2dst[n] = d\n",
        "\n",
        "        # DRNL formula\n",
        "        z = torch.zeros(num_nodes, dtype=torch.long)\n",
        "        for i in range(num_nodes):\n",
        "            d1, d2 = dist2src[i], dist2dst[i]\n",
        "            if math.isinf(d1) or math.isinf(d2):\n",
        "                z[i] = 0\n",
        "                continue\n",
        "            if i == src or i == dst:\n",
        "                z[i] = 1\n",
        "                continue\n",
        "            d = d1 + d2\n",
        "            z[i] = 1 + int(d) + int((d*(d-1))//2) + int(min(d1, d2))\n",
        "        return z\n",
        "\n",
        "    # ---- Build a subgraph sample for an edge (u,v) ----\n",
        "    def build_seal_sample(edge_index_full, num_nodes_full, u, v, y, k=2):\n",
        "        # k-hop subgraph around {u,v}\n",
        "        nodes, edge_index_sub, mapping, edge_mask = k_hop_subgraph(\n",
        "            [u, v], k, edge_index_full, relabel_nodes=True, num_nodes=num_nodes_full\n",
        "        )\n",
        "        src = mapping[0].item()\n",
        "        dst = mapping[1].item()\n",
        "\n",
        "        # Node labels (DRNL) as features (one-hot)\n",
        "        z = drnl_node_labeling(edge_index_sub, src, dst, nodes.numel())\n",
        "        x = F.one_hot(z.clamp(max=200), num_classes=201).float()  # cap for bounded feature dim\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index_sub, y=torch.tensor([y], dtype=torch.float))\n",
        "\n",
        "    # ---- Sample edges from train/test split already in notebook ----\n",
        "    if 'data_train' not in globals() or 'data_test' not in globals():\n",
        "        raise RuntimeError(\"RUN_SEAL χρειάζεται data_train/data_test από RandomLinkSplit (υπάρχουν ήδη πιο πάνω στο notebook).\")\n",
        "\n",
        "    edge_index_full = data_train.edge_index.to('cpu')\n",
        "    N_full = int(data_train.num_nodes)\n",
        "\n",
        "    # Positive edges from train graph\n",
        "    pos_edges = edge_index_full.t().unique(dim=0)\n",
        "    if pos_edges.size(0) > SEAL_NUM_TRAIN_EDGES:\n",
        "        idx = torch.randperm(pos_edges.size(0))[:SEAL_NUM_TRAIN_EDGES]\n",
        "        pos_train = pos_edges[idx]\n",
        "    else:\n",
        "        pos_train = pos_edges\n",
        "\n",
        "    neg_train = negative_sampling(edge_index_full, num_nodes=N_full, num_neg_samples=pos_train.size(0), method='sparse').t()\n",
        "\n",
        "    # Test positives / negatives (if RandomLinkSplit provides them)\n",
        "    if hasattr(data_test, 'pos_edge_label_index'):\n",
        "        pos_test = data_test.pos_edge_label_index.t().to('cpu')\n",
        "        if pos_test.size(0) > SEAL_NUM_TEST_EDGES:\n",
        "            idx = torch.randperm(pos_test.size(0))[:SEAL_NUM_TEST_EDGES]\n",
        "            pos_test = pos_test[idx]\n",
        "    else:\n",
        "        pos_test = pos_edges[:SEAL_NUM_TEST_EDGES]\n",
        "\n",
        "    if hasattr(data_test, 'neg_edge_label_index'):\n",
        "        neg_test = data_test.neg_edge_label_index.t().to('cpu')\n",
        "        if neg_test.size(0) > SEAL_NUM_TEST_EDGES:\n",
        "            idx = torch.randperm(neg_test.size(0))[:SEAL_NUM_TEST_EDGES]\n",
        "            neg_test = neg_test[idx]\n",
        "    else:\n",
        "        neg_test = negative_sampling(edge_index_full, num_nodes=N_full, num_neg_samples=pos_test.size(0), method='sparse').t()\n",
        "\n",
        "    # ---- Build datasets (can take time) ----\n",
        "    print(\"Building SEAL subgraph samples...\")\n",
        "    train_list = [build_seal_sample(edge_index_full, N_full, u, v, 1.0, k=SEAL_K_HOP) for u, v in pos_train.tolist()] + \\\n",
        "                 [build_seal_sample(edge_index_full, N_full, u, v, 0.0, k=SEAL_K_HOP) for u, v in neg_train.tolist()]\n",
        "    test_list  = [build_seal_sample(edge_index_full, N_full, u, v, 1.0, k=SEAL_K_HOP) for u, v in pos_test.tolist()] + \\\n",
        "                 [build_seal_sample(edge_index_full, N_full, u, v, 0.0, k=SEAL_K_HOP) for u, v in neg_test.tolist()]\n",
        "\n",
        "    train_loader = DataLoader(train_list, batch_size=SEAL_BATCH_SIZE, shuffle=True)\n",
        "    test_loader  = DataLoader(test_list, batch_size=SEAL_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    class SEAL_GNN(nn.Module):\n",
        "        def __init__(self, in_dim, hidden=64):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_dim, hidden)\n",
        "            self.conv2 = GCNConv(hidden, hidden)\n",
        "            self.lin1 = nn.Linear(hidden, hidden)\n",
        "            self.lin2 = nn.Linear(hidden, 1)\n",
        "\n",
        "        def forward(self, data):\n",
        "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "            x = F.relu(self.conv1(x, edge_index))\n",
        "            x = F.relu(self.conv2(x, edge_index))\n",
        "            x = global_add_pool(x, batch)\n",
        "            x = F.relu(self.lin1(x))\n",
        "            return self.lin2(x).view(-1)\n",
        "\n",
        "    in_dim = train_list[0].x.size(1)\n",
        "    seal_model = SEAL_GNN(in_dim=in_dim, hidden=64).to(device)\n",
        "    opt = torch.optim.Adam(seal_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "    def eval_seal(loader):\n",
        "        seal_model.eval()\n",
        "        ys, ps = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                batch = batch.to(device)\n",
        "                logits = seal_model(batch)\n",
        "                prob = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "                ys.append(batch.y.view(-1).cpu().numpy())\n",
        "                ps.append(prob)\n",
        "        y = np.concatenate(ys)\n",
        "        p = np.concatenate(ps)\n",
        "        return roc_auc_score(y, p), average_precision_score(y, p)\n",
        "\n",
        "    for epoch in range(1, SEAL_EPOCHS+1):\n",
        "        seal_model.train()\n",
        "        total = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = seal_model(batch)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, batch.y.view(-1))\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += float(loss.item()) * batch.num_graphs\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == 1:\n",
        "            auc, ap = eval_seal(test_loader)\n",
        "            print(f\"[SEAL] epoch {epoch:03d} | loss {total/len(train_list):.4f} | test AUC {auc:.4f} | AP {ap:.4f}\")\n",
        "\n",
        "    seal_auc, seal_ap = eval_seal(test_loader)\n",
        "    print(f\"✅ SEAL-like final: AUC={seal_auc:.4f}, AP={seal_ap:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"🟦 RUN_SEAL=False (skipping SEAL).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8605d365",
      "metadata": {
        "id": "8605d365"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25B) DEC Refinement (Deep Embedded Clustering) πάνω στα embeddings\n",
        "# =========================\n",
        "if RUN_DEC_REFINEMENT:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
        "\n",
        "    # Choose embeddings\n",
        "    Z_src = None\n",
        "    for name in ['z_vgae_best', 'z_best', 'z_mean', 'z']:\n",
        "        if name in globals() and globals()[name] is not None:\n",
        "            try:\n",
        "                Z_src = globals()[name].detach().cpu().numpy()\n",
        "                print(f\"Using embeddings from: {name} (shape={Z_src.shape})\")\n",
        "                break\n",
        "            except Exception:\n",
        "                pass\n",
        "    if Z_src is None and 'node_embeddings' in globals():\n",
        "        Z_src = np.asarray(node_embeddings)\n",
        "        print(f\"Using embeddings from: node_embeddings (shape={Z_src.shape})\")\n",
        "    if Z_src is None:\n",
        "        raise RuntimeError(\"Δεν βρέθηκαν embeddings για DEC. Τρέξε πρώτα VGAE/Node2Vec section.\")\n",
        "\n",
        "    N, D = Z_src.shape\n",
        "\n",
        "    if 'K' in globals():\n",
        "        K_dec = int(K)\n",
        "    elif 'NUM_CLUSTERS' in globals():\n",
        "        K_dec = int(NUM_CLUSTERS)\n",
        "    else:\n",
        "        K_dec = 20\n",
        "    print(\"DEC clusters K =\", K_dec)\n",
        "\n",
        "    Z0 = torch.tensor(Z_src, dtype=torch.float, device=device)\n",
        "\n",
        "    class DECModel(nn.Module):\n",
        "        def __init__(self, in_dim, hidden, k):\n",
        "            super().__init__()\n",
        "            self.mlp = nn.Sequential(\n",
        "                nn.Linear(in_dim, hidden),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden, in_dim),\n",
        "            )\n",
        "            self.cluster_centers = nn.Parameter(torch.zeros(k, in_dim))\n",
        "\n",
        "        def soft_assign(self, z, alpha=1.0):\n",
        "            dist = torch.cdist(z, self.cluster_centers) ** 2\n",
        "            q = (1.0 + dist / alpha) ** (-(alpha + 1.0) / 2.0)\n",
        "            q = q / torch.sum(q, dim=1, keepdim=True)\n",
        "            return q\n",
        "\n",
        "        def forward(self, z):\n",
        "            zt = self.mlp(z)\n",
        "            q = self.soft_assign(zt)\n",
        "            return zt, q\n",
        "\n",
        "    dec = DECModel(in_dim=D, hidden=DEC_HIDDEN, k=K_dec).to(device)\n",
        "\n",
        "    km = KMeans(n_clusters=K_dec, n_init=20, random_state=SEED)\n",
        "    y_km = km.fit_predict(Z_src)\n",
        "    dec.cluster_centers.data = torch.tensor(km.cluster_centers_, dtype=torch.float, device=device)\n",
        "\n",
        "    def target_distribution(q):\n",
        "        weight = (q ** 2) / torch.sum(q, dim=0, keepdim=True)\n",
        "        p = (weight.t() / torch.sum(weight, dim=1)).t()\n",
        "        return p\n",
        "\n",
        "    opt = torch.optim.Adam(dec.parameters(), lr=DEC_LR, weight_decay=1e-5)\n",
        "\n",
        "    # Optional GT\n",
        "    true_labels = None\n",
        "    for name in ['corum_labels', 'true_labels', 'y_true', 'labels_true']:\n",
        "        if name in globals():\n",
        "            try:\n",
        "                arr = np.asarray(globals()[name])\n",
        "                if arr.shape[0] == N:\n",
        "                    true_labels = arr\n",
        "                    print(\"✅ Found ground-truth labels for ARI/NMI:\", name)\n",
        "                    break\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    p = None\n",
        "    for epoch in range(1, DEC_EPOCHS + 1):\n",
        "        dec.train()\n",
        "        zt, q = dec(Z0)\n",
        "        if epoch % DEC_UPDATE_INTERVAL == 1 or p is None:\n",
        "            with torch.no_grad():\n",
        "                p = target_distribution(q)\n",
        "\n",
        "        loss_kl = F.kl_div(q.log(), p, reduction='batchmean')\n",
        "        loss_reg = F.mse_loss(zt, Z0)\n",
        "        loss = loss_kl + 0.1 * loss_reg\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if epoch % 20 == 0 or epoch == 1:\n",
        "            dec.eval()\n",
        "            with torch.no_grad():\n",
        "                zt, q = dec(Z0)\n",
        "                y_pred = torch.argmax(q, dim=1).cpu().numpy()\n",
        "            msg = f\"[DEC] epoch {epoch:03d} | loss={loss.item():.4f}\"\n",
        "            if true_labels is not None:\n",
        "                msg += f\" | ARI={adjusted_rand_score(true_labels, y_pred):.4f} | NMI={normalized_mutual_info_score(true_labels, y_pred):.4f}\"\n",
        "            print(msg)\n",
        "\n",
        "    dec.eval()\n",
        "    with torch.no_grad():\n",
        "        zt, q = dec(Z0)\n",
        "        dec_labels = torch.argmax(q, dim=1).cpu().numpy()\n",
        "\n",
        "    df_dec = pd.DataFrame({\"node\": np.arange(N), \"dec_cluster\": dec_labels})\n",
        "    display(df_dec.head())\n",
        "\n",
        "    if 'df_clusters' in globals() and isinstance(df_clusters, pd.DataFrame) and 'node' in df_clusters.columns:\n",
        "        df_clusters = df_clusters.merge(df_dec, on='node', how='left')\n",
        "        print(\"✅ Added df_clusters['dec_cluster']\")\n",
        "\n",
        "else:\n",
        "    print(\"🟦 RUN_DEC_REFINEMENT=False (skipping DEC).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f55ccb9",
      "metadata": {
        "id": "8f55ccb9"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25C) Sparse-DMoN (end-to-end modularity optimization) - WORKS WITH edge_index\n",
        "# - Replaces dense DMoNPooling (which requires NxN adjacency)\n",
        "# - Optimizes soft modularity directly on sparse edges\n",
        "# Output:\n",
        "#   - df_clusters['dmon_sparse_cluster']\n",
        "# =========================\n",
        "\n",
        "RUN_DMON = True  # keep your flag\n",
        "DMON_EPOCHS = 200\n",
        "DMON_LR = 1e-2\n",
        "DMON_HID = 64\n",
        "DMON_DROPOUT = 0.2\n",
        "LAMBDA_BALANCE = 1.0      # encourages balanced clusters\n",
        "LAMBDA_ENTROPY = 0.1      # encourages confident assignments\n",
        "\n",
        "if RUN_DMON:\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch_geometric.nn import GCNConv\n",
        "    from torch_scatter import scatter_add\n",
        "\n",
        "    # ---- pick PyG graph ----\n",
        "    pyg = None\n",
        "    for nm in [\"data_train\", \"data_lcc\", \"data_full\", \"data\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "            pyg = globals()[nm]\n",
        "            print(f\"✅ Using PyG data: {nm}\")\n",
        "            break\n",
        "    assert pyg is not None, \"No PyG Data found (need data_train/data_lcc/data/etc).\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"device:\", device)\n",
        "\n",
        "    edge_index = pyg.edge_index.to(device)\n",
        "    N = int(pyg.num_nodes)\n",
        "\n",
        "    # ---- features ----\n",
        "    if getattr(pyg, \"x\", None) is None:\n",
        "        deg0 = torch.bincount(edge_index[0], minlength=N).float().view(-1, 1)\n",
        "        x_in = deg0\n",
        "        print(\"⚠️ No node features -> using degree feature (N x 1).\")\n",
        "    else:\n",
        "        x_in = pyg.x\n",
        "        if not torch.is_tensor(x_in):\n",
        "            x_in = torch.tensor(x_in)\n",
        "    x_in = x_in.to(device)\n",
        "\n",
        "    # ---- number of clusters ----\n",
        "    if \"K\" in globals():\n",
        "        K_dmon = int(K)\n",
        "    elif \"NUM_CLUSTERS\" in globals():\n",
        "        K_dmon = int(NUM_CLUSTERS)\n",
        "    else:\n",
        "        K_dmon = 20\n",
        "    print(\"Sparse-DMoN clusters K =\", K_dmon)\n",
        "\n",
        "    # ---- model: GCN -> soft assignments S (N,K) ----\n",
        "    class SparseDMoN(nn.Module):\n",
        "        def __init__(self, in_dim, hid, k, dropout=0.2):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_dim, hid)\n",
        "            self.conv2 = GCNConv(hid, hid)\n",
        "            self.lin   = nn.Linear(hid, k)\n",
        "            self.dropout = dropout\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            h = self.conv1(x, edge_index)\n",
        "            h = F.relu(h)\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "            h = self.conv2(h, edge_index)\n",
        "            h = F.relu(h)\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "            logits = self.lin(h)                 # (N,K)\n",
        "            S = F.softmax(logits, dim=1)         # soft assignment\n",
        "            return S\n",
        "\n",
        "    def modularity_soft(S, edge_index, N):\n",
        "        \"\"\"\n",
        "        Soft modularity for sparse graph:\n",
        "        Q = term1/(2m) - term2/(2m)^2\n",
        "        where:\n",
        "          term1 = sum_{(u,v) in E} <S_u, S_v>\n",
        "          term2 = || sum_i d_i S_i ||^2\n",
        "        Works with directed edge_index too (consistent scaling).\n",
        "        \"\"\"\n",
        "        src, dst = edge_index[0], edge_index[1]\n",
        "        E = src.numel()\n",
        "\n",
        "        # degree on src side (directed)\n",
        "        ones = torch.ones(E, device=S.device)\n",
        "        deg = scatter_add(ones, src, dim=0, dim_size=N)  # (N,)\n",
        "\n",
        "        two_m = deg.sum().clamp(min=1.0)  # = number of directed edges\n",
        "\n",
        "        # term1 = sum_e dot(S_u, S_v)\n",
        "        term1 = (S[src] * S[dst]).sum(dim=1).sum()\n",
        "\n",
        "        # term2 = || S^T d ||^2\n",
        "        a = (S * deg.view(-1, 1)).sum(dim=0)   # (K,)\n",
        "        term2 = (a * a).sum()\n",
        "\n",
        "        Q = term1 / two_m - term2 / (two_m * two_m)\n",
        "        return Q\n",
        "\n",
        "    model = SparseDMoN(in_dim=x_in.size(1), hid=DMON_HID, k=K_dmon, dropout=DMON_DROPOUT).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=DMON_LR, weight_decay=1e-5)\n",
        "\n",
        "    for epoch in range(1, DMON_EPOCHS + 1):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        S = model(x_in, edge_index)  # (N,K)\n",
        "\n",
        "        # maximize modularity => minimize -Q\n",
        "        Q = modularity_soft(S, edge_index, N)\n",
        "        loss_mod = -Q\n",
        "\n",
        "        # balance regularization: encourage similar cluster sizes\n",
        "        p = S.mean(dim=0)  # (K,)\n",
        "        loss_balance = ((p - (1.0 / K_dmon)) ** 2).sum()\n",
        "\n",
        "        # entropy regularization: low entropy => more confident assignments\n",
        "        ent = -(S * (S.clamp_min(1e-9).log())).sum(dim=1).mean()\n",
        "        loss_entropy = ent\n",
        "\n",
        "        loss = loss_mod + LAMBDA_BALANCE * loss_balance + LAMBDA_ENTROPY * loss_entropy\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if epoch % 20 == 0 or epoch == 1:\n",
        "            print(f\"[Sparse-DMoN] epoch {epoch:03d} | loss={loss.item():.4f} | Q={Q.item():.4f} | bal={loss_balance.item():.4f} | ent={ent.item():.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        S = model(x_in, edge_index)\n",
        "        labels = torch.argmax(S, dim=1).detach().cpu().numpy()\n",
        "\n",
        "    # ---- attach to df_clusters ----\n",
        "    if \"df_clusters\" not in globals():\n",
        "        df_clusters = pd.DataFrame({\"node\": np.arange(N)})\n",
        "\n",
        "    if \"node\" not in df_clusters.columns:\n",
        "        df_clusters[\"node\"] = np.arange(len(df_clusters))\n",
        "\n",
        "    df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "    # align length if df_clusters is bigger/smaller\n",
        "    if len(df_clusters) != N:\n",
        "        # safest: merge on node id\n",
        "        df_tmp = pd.DataFrame({\"node\": np.arange(N), \"dmon_sparse_cluster\": labels})\n",
        "        df_clusters = df_clusters.merge(df_tmp, on=\"node\", how=\"left\")\n",
        "    else:\n",
        "        df_clusters[\"dmon_sparse_cluster\"] = labels\n",
        "\n",
        "    print(\"✅ Added df_clusters['dmon_sparse_cluster']\")\n",
        "    display(df_clusters[[\"node\",\"dmon_sparse_cluster\"]].head())\n",
        "\n",
        "else:\n",
        "    print(\"🟦 RUN_DMON=False (skipping Sparse-DMoN).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c804256",
      "metadata": {
        "id": "7c804256"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 25D) Trade-off plot: clustering vs link prediction (ROBUST v2)\n",
        "# Fix: if ARI column exists but is all-NaN, fallback to modularity or mean_bestF1\n",
        "# Saves: tradeoff_scatter.png\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _pick_col_nonempty(df, candidates):\n",
        "    \"\"\"\n",
        "    Pick first candidate column that exists AND has at least one non-NaN value.\n",
        "    \"\"\"\n",
        "    # exact match\n",
        "    for c in candidates:\n",
        "        if c in df.columns and df[c].notna().any():\n",
        "            return c\n",
        "    # case-insensitive match\n",
        "    low = {str(c).lower(): c for c in df.columns}\n",
        "    for c in candidates:\n",
        "        if c.lower() in low:\n",
        "            real = low[c.lower()]\n",
        "            if df[real].notna().any():\n",
        "                return real\n",
        "    return None\n",
        "\n",
        "dfs = []\n",
        "\n",
        "# in-memory dataframes\n",
        "if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame) and len(df_deep) > 0:\n",
        "    d = df_deep.copy()\n",
        "    if \"method\" not in d.columns:\n",
        "        if \"name\" in d.columns: d = d.rename(columns={\"name\": \"method\"})\n",
        "        elif \"cluster_col\" in d.columns: d = d.rename(columns={\"cluster_col\": \"method\"})\n",
        "    dfs.append(d)\n",
        "\n",
        "if \"df_metrics_all\" in globals() and isinstance(df_metrics_all, pd.DataFrame) and len(df_metrics_all) > 0:\n",
        "    d = df_metrics_all.copy()\n",
        "    if \"method\" not in d.columns and \"name\" in d.columns:\n",
        "        d = d.rename(columns={\"name\": \"method\"})\n",
        "    dfs.append(d)\n",
        "\n",
        "# csv fallbacks\n",
        "for fn in [\"deep_models_linkpred_clustering_metrics.csv\",\n",
        "           \"clustering_metrics_supervised_unsupervised.csv\",\n",
        "           \"corum_overlap_besthitF1_by_method.csv\"]:\n",
        "    if os.path.exists(fn):\n",
        "        try:\n",
        "            d = pd.read_csv(fn)\n",
        "            if \"method\" not in d.columns and \"name\" in d.columns:\n",
        "                d = d.rename(columns={\"name\": \"method\"})\n",
        "            dfs.append(d)\n",
        "            print(f\"✅ Loaded {fn} ({d.shape[0]} rows)\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not read {fn}: {e}\")\n",
        "\n",
        "if len(dfs) == 0:\n",
        "    print(\"❌ No results found. Run deep models cell (df_deep) or metrics cell first.\")\n",
        "else:\n",
        "    df_results = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "\n",
        "    if \"method\" not in df_results.columns:\n",
        "        if \"cluster_col\" in df_results.columns:\n",
        "            df_results[\"method\"] = df_results[\"cluster_col\"].astype(str)\n",
        "        else:\n",
        "            df_results[\"method\"] = np.arange(len(df_results)).astype(str)\n",
        "\n",
        "    # y: link prediction metric (prefer AUC)\n",
        "    ycol = _pick_col_nonempty(df_results, [\"AUC\", \"auc\", \"roc_auc\", \"test_auc\", \"AP\", \"ap\", \"average_precision\"])\n",
        "    # x: clustering metric (prefer ARI if it actually has values, else modularity, else bestF1)\n",
        "    xcol = _pick_col_nonempty(df_results, [\"ARI\", \"ari\", \"modularity\", \"mod\", \"mean_bestF1\", \"size_weighted_bestF1\"])\n",
        "\n",
        "    if xcol is None or ycol is None:\n",
        "        print(\"❌ Missing required columns for plot with non-NaN values.\")\n",
        "        print(\"Columns:\", df_results.columns.tolist())\n",
        "        print(\"Need non-NaN clustering metric (ARI/modularity/mean_bestF1) AND non-NaN link metric (AUC/AP).\")\n",
        "    else:\n",
        "        dfp = df_results.loc[df_results[xcol].notna() & df_results[ycol].notna()].copy()\n",
        "\n",
        "        if len(dfp) == 0:\n",
        "            print(\"❌ Still no rows have both x and y values.\")\n",
        "            print(f\"xcol={xcol}, ycol={ycol}\")\n",
        "            print(\"Tip: usually this means you have clustering-only rows (no AUC) OR link-only rows (no modularity).\")\n",
        "        else:\n",
        "            plt.figure(figsize=(7, 5))\n",
        "            plt.scatter(dfp[xcol].values, dfp[ycol].values)\n",
        "\n",
        "            # annotate if not too many points\n",
        "            if len(dfp) <= 30:\n",
        "                for _, r in dfp.iterrows():\n",
        "                    plt.annotate(str(r[\"method\"]), (r[xcol], r[ycol]), fontsize=8, alpha=0.7)\n",
        "\n",
        "            plt.xlabel(xcol)\n",
        "            plt.ylabel(ycol)\n",
        "            plt.title(\"Trade-off: clustering quality vs link prediction\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(\"tradeoff_scatter.png\", dpi=300)\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"✅ Plot OK with x={xcol}, y={ycol}, points={len(dfp)}\")\n",
        "            print(\"✅ Saved: tradeoff_scatter.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d28751",
      "metadata": {
        "id": "35d28751"
      },
      "source": [
        "\n",
        "# =========================\n",
        "# 26) PhD-level extras (optional): Contrastive pretraining (DGI), Transformer encoder, stronger decoders,\n",
        "#     cluster stability + K selection\n",
        "# =========================\n",
        "\n",
        "This section is **fully optional** and **additive**: it does **not** modify any previous results.\n",
        "It gives you more *complex* models and *more rigorous* evaluation, aligned with your thesis topic\n",
        "(advanced evaluation & improvement of graph clustering results with ML/GNNs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb19263",
      "metadata": {
        "id": "1eb19263"
      },
      "source": [
        "\n",
        "## 26A) Helper metrics: clustering stability + variation of information (VI)\n",
        "\n",
        "Why this matters (PhD-level evaluation):\n",
        "- Two clusterings can have similar ARI vs CORUM but behave *unstably* across random seeds.\n",
        "- Stability is an extra validity dimension: **good solutions tend to be reproducible**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae69a4ed",
      "metadata": {
        "id": "ae69a4ed"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def variation_of_information(labels_a, labels_b):\n",
        "    \"\"\"VI = H(A)+H(B)-2I(A,B). Lower is better.\n",
        "    This is a standard information-theoretic distance between partitions.\n",
        "    \"\"\"\n",
        "    a = np.asarray(labels_a)\n",
        "    b = np.asarray(labels_b)\n",
        "    assert a.shape == b.shape\n",
        "    n = len(a)\n",
        "\n",
        "    # contingency\n",
        "    _, a_ids = np.unique(a, return_inverse=True)\n",
        "    _, b_ids = np.unique(b, return_inverse=True)\n",
        "    A = a_ids\n",
        "    B = b_ids\n",
        "    kA = A.max()+1\n",
        "    kB = B.max()+1\n",
        "\n",
        "    cont = np.zeros((kA, kB), dtype=np.int64)\n",
        "    np.add.at(cont, (A, B), 1)\n",
        "\n",
        "    pa = cont.sum(axis=1) / n\n",
        "    pb = cont.sum(axis=0) / n\n",
        "    pab = cont / n\n",
        "\n",
        "    # entropies (ignore zeros)\n",
        "    def H(p):\n",
        "        p = p[p>0]\n",
        "        return -np.sum(p*np.log(p))\n",
        "\n",
        "    HA = H(pa); HB = H(pb)\n",
        "\n",
        "    # mutual information\n",
        "    nz = pab>0\n",
        "    I = np.sum(pab[nz] * (np.log(pab[nz]) - np.log(pa[:,None][nz]) - np.log(pb[None,:][nz])))\n",
        "\n",
        "    return float(HA + HB - 2*I)\n",
        "\n",
        "def pairwise_stability(labels_list):\n",
        "    \"\"\"Return mean/std of pairwise ARI and VI across a list of clusterings.\"\"\"\n",
        "    from sklearn.metrics import adjusted_rand_score\n",
        "    L = labels_list\n",
        "    m = len(L)\n",
        "    if m < 2:\n",
        "        return dict(ari_mean=np.nan, ari_std=np.nan, vi_mean=np.nan, vi_std=np.nan)\n",
        "\n",
        "    aris, vis = [], []\n",
        "    for i in range(m):\n",
        "        for j in range(i+1, m):\n",
        "            aris.append(adjusted_rand_score(L[i], L[j]))\n",
        "            vis.append(variation_of_information(L[i], L[j]))\n",
        "\n",
        "    return dict(\n",
        "        ari_mean=float(np.mean(aris)), ari_std=float(np.std(aris)),\n",
        "        vi_mean=float(np.mean(vis)),   vi_std=float(np.std(vis))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c71cdd9",
      "metadata": {
        "id": "2c71cdd9"
      },
      "source": [
        "\n",
        "## 26B) Contrastive pretraining with Deep Graph Infomax (DGI)\n",
        "\n",
        "Goal: produce node embeddings that capture *global graph structure* without requiring features.\n",
        "We then:\n",
        "- cluster the DGI embeddings\n",
        "- evaluate with the same supervised & unsupervised metrics (ARI/NMI/modularity/coverage/conductance)\n",
        "- optionally compare vs VGAE embeddings\n",
        "\n",
        "Notes:\n",
        "- DGI is in PyG (`torch_geometric.nn.models.DeepGraphInfomax`).\n",
        "- Works even with your dummy/random features; it will still exploit adjacency structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0c3c9b",
      "metadata": {
        "id": "fa0c3c9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch_geometric.nn.models import DeepGraphInfomax\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn as nn\n",
        "\n",
        "def dgi_encoder_factory(in_dim, hidden_dim, out_dim):\n",
        "    class Encoder(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "            self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index).relu()\n",
        "            x = self.conv2(x, edge_index)\n",
        "            return x\n",
        "    return Encoder()\n",
        "\n",
        "def corruption(x, edge_index):\n",
        "    perm = torch.randperm(x.size(0), device=x.device)\n",
        "    return x[perm], edge_index\n",
        "\n",
        "def summary(z, *args, **kwargs):\n",
        "    return torch.sigmoid(z.mean(dim=0))\n",
        "\n",
        "def train_dgi(data, hidden_dim=128, out_dim=64, lr=1e-3, epochs=200, weight_decay=1e-4, seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    device = data.x.device\n",
        "    enc = dgi_encoder_factory(data.num_node_features, hidden_dim, out_dim).to(device)\n",
        "    model = DeepGraphInfomax(\n",
        "        hidden_channels=out_dim,\n",
        "        encoder=enc,\n",
        "        summary=summary,\n",
        "        corruption=corruption\n",
        "    ).to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    model.train()\n",
        "    for ep in range(1, epochs+1):\n",
        "        opt.zero_grad()\n",
        "        pos_z, neg_z, s = model(data.x, data.edge_index)\n",
        "        loss = model.loss(pos_z, neg_z, s)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if ep % 50 == 0:\n",
        "            print(f\"[DGI] epoch {ep:03d} | loss {loss.item():.4f}\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encoder(data.x, data.edge_index)\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a556629",
      "metadata": {
        "id": "8a556629"
      },
      "outputs": [],
      "source": [
        "\n",
        "if RUN_DGI_PRETRAIN:\n",
        "    # Expect `data_full` or `data_train` to exist from earlier cells.\n",
        "    # We'll use the *training graph* for representation learning to avoid leakage.\n",
        "    _data_for_repr = data_train if 'data_train' in globals() else data_full\n",
        "    _data_for_repr = _data_for_repr.to(device)\n",
        "\n",
        "    # ensure x exists (if earlier pipeline uses dummy/random features, that's fine)\n",
        "    if _data_for_repr.x is None:\n",
        "        _data_for_repr.x = torch.ones((_data_for_repr.num_nodes, 1), device=device)\n",
        "\n",
        "    z_dgi = train_dgi(_data_for_repr, hidden_dim=128, out_dim=64, lr=1e-3, epochs=200, seed=SEED)\n",
        "    z_dgi_np = z_dgi.detach().cpu().numpy()\n",
        "    print(\"z_dgi:\", z_dgi.shape)\n",
        "\n",
        "    # clustering on DGI embeddings\n",
        "    if 'K_CLUSTERS' in globals():\n",
        "        K_dgi = K_CLUSTERS\n",
        "    elif 'K' in globals():\n",
        "        K_dgi = K\n",
        "    else:\n",
        "        K_dgi = 50  # fallback\n",
        "\n",
        "    labels_dgi = KMeans(n_clusters=K_dgi, n_init=20, random_state=SEED).fit_predict(z_dgi_np)\n",
        "\n",
        "    # Evaluate using existing helpers if available\n",
        "    if 'evaluate_clustering_all' in globals():\n",
        "        dgi_metrics = evaluate_clustering_all(\n",
        "            G_nx=G, cluster_labels=labels_dgi,\n",
        "            true_labels=true_labels if 'true_labels' in globals() else None,\n",
        "            name=f\"DGI+KMeans(K={K_dgi})\"\n",
        "        )\n",
        "        print(dgi_metrics)\n",
        "    else:\n",
        "        print(\"ℹ️ evaluate_clustering_all not found; skipping metric summary (older notebook version).\")\n",
        "else:\n",
        "    print(\"🟦 DGI pretraining disabled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dsmoeQf5dQP1",
      "metadata": {
        "id": "dsmoeQf5dQP1"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# DGI -> KMeans : Metrics + save to df_clusters (NO evaluate_clustering_all needed)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "assert \"z_dgi\" in globals(), \"Δεν βρέθηκε z_dgi. Τρέξε πρώτα το DGI pretrain cell.\"\n",
        "assert \"compute_cluster_metrics\" in globals(), \"Δεν βρέθηκε compute_cluster_metrics. Τρέξε πρώτα το metrics definition cell.\"\n",
        "assert \"G_eval\" in globals() or \"G\" in globals() or \"G_nx\" in globals(), \"Δεν βρέθηκε NetworkX graph (G_eval/G/G_nx).\"\n",
        "\n",
        "G_tmp = globals().get(\"G_eval\", None)\n",
        "if G_tmp is None:\n",
        "    G_tmp = globals().get(\"G\", None) if \"G\" in globals() else globals().get(\"G_nx\", None)\n",
        "\n",
        "# choose K\n",
        "K_dgi = int(globals().get(\"K\", globals().get(\"K_CLUSTERS\", 50)))\n",
        "\n",
        "# embeddings -> numpy\n",
        "z_dgi_np = z_dgi.detach().cpu().numpy()\n",
        "\n",
        "# KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "labels_dgi = KMeans(n_clusters=K_dgi, n_init=20, random_state=0).fit_predict(z_dgi_np)\n",
        "\n",
        "# ensure df_clusters exists\n",
        "if \"df_clusters\" not in globals():\n",
        "    df_clusters = pd.DataFrame({\"node\": np.arange(z_dgi_np.shape[0])})\n",
        "else:\n",
        "    if \"node\" not in df_clusters.columns:\n",
        "        df_clusters[\"node\"] = np.arange(z_dgi_np.shape[0])\n",
        "    df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "col_name = f\"DGI_kmeans_K{K_dgi}\"\n",
        "df_clusters[col_name] = labels_dgi\n",
        "print(f\"✅ Added df_clusters['{col_name}']\")\n",
        "\n",
        "# compute metrics (ARI/NMI will be NaN if gt_labels_corum is None)\n",
        "gt = globals().get(\"gt_labels_corum\", None)\n",
        "row = compute_cluster_metrics(G_tmp, labels_dgi, name=col_name, gt_labels=gt)\n",
        "display(pd.DataFrame([row]))\n",
        "\n",
        "# optionally append to df_deep-like table for plotting\n",
        "if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame):\n",
        "    df_deep = pd.concat([df_deep, pd.DataFrame([row])], ignore_index=True)\n",
        "else:\n",
        "    df_deep = pd.DataFrame([row])\n",
        "\n",
        "df_deep.to_csv(\"dgi_kmeans_clustering_metrics.csv\", index=False)\n",
        "print(\"✅ Saved: dgi_kmeans_clustering_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c92fc105",
      "metadata": {
        "id": "c92fc105"
      },
      "source": [
        "\n",
        "## 26C) VGAE with TransformerConv encoder (more expressive GNN)\n",
        "\n",
        "If your earlier section already tries GCN/GraphSAGE/GAT encoders, TransformerConv can be an additional\n",
        "\"more complex\" architecture. It often helps when the graph has heterogeneous neighborhoods.\n",
        "\n",
        "We keep the same training objective (reconstruction) so comparisons stay fair.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c73562",
      "metadata": {
        "id": "87c73562"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch_geometric.nn import TransformerConv\n",
        "\n",
        "class TransformerVGAEEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = TransformerConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        # output dimension = hidden_channels * heads\n",
        "        self.conv_mu = TransformerConv(hidden_channels*heads, out_channels, heads=1, dropout=dropout)\n",
        "        self.conv_logstd = TransformerConv(hidden_channels*heads, out_channels, heads=1, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "def run_vgae_transformer(data_train, data_val=None, data_test=None, epochs=200, lr=1e-3, seed=0, hidden=64, out=32):\n",
        "    from torch_geometric.nn.models import VGAE\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "    device = data_train.x.device\n",
        "\n",
        "    enc = TransformerVGAEEncoder(data_train.num_node_features, hidden, out).to(device)\n",
        "    model = VGAE(enc).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(1, epochs+1):\n",
        "        opt.zero_grad()\n",
        "        z = model.encode(data_train.x, data_train.edge_index)\n",
        "        loss = model.recon_loss(z, data_train.edge_index)\n",
        "        # KL for variational\n",
        "        loss = loss + (1.0 / data_train.num_nodes) * model.kl_loss()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if ep % 50 == 0:\n",
        "            print(f\"[VGAE-Transformer] epoch {ep:03d} | loss {loss.item():.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(data_train.x, data_train.edge_index)\n",
        "    return model, z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabf81a7",
      "metadata": {
        "id": "eabf81a7"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# FIXED (ROBUST): Link prediction eval + clustering metrics for \"Transformer-VGAE-like\" embeddings\n",
        "# - Does NOT require z_tr name. Auto-detects embeddings tensor in globals.\n",
        "# - Reuses existing split if available, else builds manual 10% test split.\n",
        "# - Adds KMeans labels to df_clusters\n",
        "# - Computes clustering metrics via compute_cluster_metrics (must exist)\n",
        "# Saves:\n",
        "#  - transformer_like_linkpred_metrics.csv\n",
        "# =========================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ---------- 0) Pick embeddings automatically ----------\n",
        "def pick_embedding(candidates=(\"z_tr\",\"z\",\"z_mean\",\"z_mu\",\"z_vgae\",\"z_latent\",\"z_dgi\",\"Z\",\"emb\",\"embeddings\")):\n",
        "    for nm in candidates:\n",
        "        if nm in globals():\n",
        "            obj = globals()[nm]\n",
        "            if torch.is_tensor(obj) and obj.dim() == 2 and obj.size(0) > 0:\n",
        "                print(f\"✅ Using embeddings from: {nm}  shape={tuple(obj.shape)}\")\n",
        "                return obj, nm\n",
        "    # fallback: any NxD tensor in globals\n",
        "    for nm, obj in globals().items():\n",
        "        if torch.is_tensor(obj) and obj.dim() == 2 and obj.size(0) > 0:\n",
        "            print(f\"✅ Using embeddings from (fallback): {nm}  shape={tuple(obj.shape)}\")\n",
        "            return obj, nm\n",
        "    raise AssertionError(\"❌ Δεν βρέθηκαν embeddings tensor NxD. Τρέξε πρώτα το encoder cell (VGAE/GAE/Transformer/DGI) που παράγει z.\")\n",
        "\n",
        "z, z_name = pick_embedding()\n",
        "z_np = z.detach().cpu().numpy()\n",
        "N = z_np.shape[0]\n",
        "\n",
        "# ---------- 1) Pick/build test split (pos/neg edges) ----------\n",
        "split_obj = None\n",
        "for nm in [\"data_test\", \"test_data\", \"data_val\", \"val_data\"]:\n",
        "    if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "        split_obj = globals()[nm]\n",
        "        print(f\"✅ Using existing split object: {nm}\")\n",
        "        break\n",
        "\n",
        "def _get_pos_neg_edges(split_data):\n",
        "    # RandomLinkSplit style: pos_edge_label_index / neg_edge_label_index\n",
        "    if hasattr(split_data, \"pos_edge_label_index\") and hasattr(split_data, \"neg_edge_label_index\"):\n",
        "        if split_data.pos_edge_label_index is not None and split_data.neg_edge_label_index is not None:\n",
        "            pos = split_data.pos_edge_label_index.detach().cpu().numpy()\n",
        "            neg = split_data.neg_edge_label_index.detach().cpu().numpy()\n",
        "            return pos, neg\n",
        "    # Alternative style: edge_label_index + edge_label\n",
        "    if hasattr(split_data, \"edge_label_index\") and hasattr(split_data, \"edge_label\"):\n",
        "        eidx = split_data.edge_label_index.detach().cpu().numpy()\n",
        "        elab = split_data.edge_label.detach().cpu().numpy()\n",
        "        pos = eidx[:, elab == 1]\n",
        "        neg = eidx[:, elab == 0]\n",
        "        return pos, neg\n",
        "    raise AttributeError(\"❌ Δεν βρήκα pos/neg labeled edges στο split object.\")\n",
        "\n",
        "if split_obj is None:\n",
        "    pyg_base = None\n",
        "    for nm in [\"data_train\", \"data_lcc\", \"data_full\", \"data\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "            pyg_base = globals()[nm]\n",
        "            print(f\"ℹ️ Building manual split from: {nm}\")\n",
        "            break\n",
        "    assert pyg_base is not None, \"❌ Δεν βρέθηκε PyG data (data_train/data_lcc/data_full/data) για να χτιστεί split.\"\n",
        "\n",
        "    ei = pyg_base.edge_index.detach().cpu().numpy()\n",
        "    u = ei[0]; v = ei[1]\n",
        "\n",
        "    # make undirected unique edges (u<v)\n",
        "    uu = np.minimum(u, v)\n",
        "    vv = np.maximum(u, v)\n",
        "    und = np.stack([uu, vv], axis=0)\n",
        "    und = np.unique(und, axis=1)\n",
        "\n",
        "    # remove self-loops just in case\n",
        "    m = und[0] != und[1]\n",
        "    und = und[:, m]\n",
        "\n",
        "    E = und.shape[1]\n",
        "    rng = np.random.default_rng(0)\n",
        "    idx = rng.permutation(E)\n",
        "\n",
        "    test_frac = 0.10\n",
        "    n_test = max(1, int(test_frac * E))\n",
        "    pos_edge = und[:, idx[:n_test]]\n",
        "\n",
        "    # negatives: random non-edges\n",
        "    edge_set = set(map(tuple, und.T.tolist()))\n",
        "    neg_u, neg_v = [], []\n",
        "    while len(neg_u) < n_test:\n",
        "        a = int(rng.integers(0, N))\n",
        "        b = int(rng.integers(0, N))\n",
        "        if a == b:\n",
        "            continue\n",
        "        aa, bb = (a, b) if a < b else (b, a)\n",
        "        if (aa, bb) in edge_set:\n",
        "            continue\n",
        "        neg_u.append(aa); neg_v.append(bb)\n",
        "        edge_set.add((aa, bb))  # avoid duplicates among negatives\n",
        "    neg_edge = np.stack([np.array(neg_u), np.array(neg_v)], axis=0)\n",
        "\n",
        "    print(f\"✅ Manual split created: pos={pos_edge.shape[1]}, neg={neg_edge.shape[1]}\")\n",
        "else:\n",
        "    pos_edge, neg_edge = _get_pos_neg_edges(split_obj)\n",
        "    print(f\"✅ Extracted from split: pos={pos_edge.shape[1]}, neg={neg_edge.shape[1]}\")\n",
        "\n",
        "# ---------- 2) Link prediction scoring (dot product) ----------\n",
        "def _dot_score(z_np, edge_2xE):\n",
        "    uu = edge_2xE[0].astype(int)\n",
        "    vv = edge_2xE[1].astype(int)\n",
        "    return (z_np[uu] * z_np[vv]).sum(axis=1)\n",
        "\n",
        "pos_s = _dot_score(z_np, pos_edge)\n",
        "neg_s = _dot_score(z_np, neg_edge)\n",
        "\n",
        "y_true = np.concatenate([np.ones_like(pos_s), np.zeros_like(neg_s)])\n",
        "y_score = np.concatenate([pos_s, neg_s])\n",
        "\n",
        "auc = float(roc_auc_score(y_true, y_score))\n",
        "ap  = float(average_precision_score(y_true, y_score))\n",
        "print(f\"✅ Link prediction (dot decoder) from {z_name}: AUC={auc:.4f}, AP={ap:.4f}\")\n",
        "\n",
        "# ---------- 3) Clustering on embeddings ----------\n",
        "K_tr = int(globals().get(\"K\", globals().get(\"K_CLUSTERS\", 50)))\n",
        "labels_tr = KMeans(n_clusters=K_tr, n_init=20, random_state=0).fit_predict(z_np)\n",
        "\n",
        "# ensure df_clusters exists + aligned\n",
        "if \"df_clusters\" not in globals():\n",
        "    df_clusters = pd.DataFrame({\"node\": np.arange(N)})\n",
        "else:\n",
        "    if \"node\" not in df_clusters.columns:\n",
        "        df_clusters[\"node\"] = np.arange(N)\n",
        "    df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "col_name = f\"{z_name}_kmeans_K{K_tr}\"\n",
        "df_clusters[col_name] = labels_tr\n",
        "print(f\"✅ Added df_clusters['{col_name}']\")\n",
        "\n",
        "# ---------- 4) Clustering metrics (needs NetworkX graph + compute_cluster_metrics) ----------\n",
        "assert \"compute_cluster_metrics\" in globals(), \"❌ compute_cluster_metrics not found. Τρέξε πρώτα το cell που το ορίζει.\"\n",
        "G_tmp = globals().get(\"G_eval\", globals().get(\"G\", globals().get(\"G_nx\", None)))\n",
        "assert G_tmp is not None, \"❌ Need a NetworkX graph: set G_eval or G or G_nx πριν τρέξεις αυτό το cell.\"\n",
        "\n",
        "gt = globals().get(\"gt_labels_corum\", None)  # optional\n",
        "row = compute_cluster_metrics(G_tmp, labels_tr, name=col_name, gt_labels=gt)\n",
        "row[\"AUC\"] = auc\n",
        "row[\"AP\"] = ap\n",
        "row[\"seed\"] = int(globals().get(\"SEED\", 0))\n",
        "row[\"embeddings_source\"] = z_name\n",
        "\n",
        "df_one = pd.DataFrame([row])\n",
        "display(df_one)\n",
        "\n",
        "# append to df_deep (for tradeoff plot convenience)\n",
        "if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame):\n",
        "    df_deep = pd.concat([df_deep, df_one], ignore_index=True)\n",
        "else:\n",
        "    df_deep = df_one.copy()\n",
        "\n",
        "out_csv = \"transformer_like_linkpred_metrics.csv\"\n",
        "df_one.to_csv(out_csv, index=False)\n",
        "print(f\"✅ Saved: {out_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa03feab",
      "metadata": {
        "id": "fa03feab"
      },
      "source": [
        "\n",
        "## 26E) K selection by modularity + stability (optional)\n",
        "\n",
        "Instead of picking K arbitrarily, we can scan a range and choose a K where:\n",
        "- modularity is high (structure-based)\n",
        "- clustering is stable across random seeds (evaluation dimension)\n",
        "\n",
        "This is **not** ground-truth dependent and aligns with \"cluster validity\" theme.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f90b6a",
      "metadata": {
        "id": "79f90b6a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def scan_K_for_embeddings(z_np, G_nx, K_list, seeds=(0,1,2,3,4), n_init=10):\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "    out_rows = []\n",
        "    for Kc in K_list:\n",
        "        labs = []\n",
        "        for s in seeds:\n",
        "            lab = KMeans(n_clusters=Kc, n_init=n_init, random_state=s).fit_predict(z_np)\n",
        "            labs.append(lab)\n",
        "        stab = pairwise_stability(labs)\n",
        "        # compute modularity on one representative (seed0)\n",
        "        lab0 = labs[0]\n",
        "        comms = [list(np.where(lab0==c)[0]) for c in range(Kc)]\n",
        "        try:\n",
        "            mod = float(nx_modularity(G_nx, comms))\n",
        "        except Exception:\n",
        "            mod = np.nan\n",
        "        out_rows.append(dict(K=Kc, modularity=mod, **stab))\n",
        "    return pd.DataFrame(out_rows).sort_values(\"K\").reset_index(drop=True)\n",
        "\n",
        "def pick_K(df_scan, w_mod=1.0, w_stab=1.0):\n",
        "    # normalize to [0,1] (mod higher better, VI lower better, ARI higher better)\n",
        "    df = df_scan.copy()\n",
        "    def minmax(x):\n",
        "        x = x.astype(float)\n",
        "        mn, mx = np.nanmin(x), np.nanmax(x)\n",
        "        if mx-mn < 1e-12:\n",
        "            return np.zeros_like(x)\n",
        "        return (x-mn)/(mx-mn)\n",
        "\n",
        "    mod_n = minmax(df['modularity'].values)\n",
        "    ari_n = minmax(df['ari_mean'].values)\n",
        "    vi_n  = 1.0 - minmax(df['vi_mean'].values)  # invert: lower VI -> higher score\n",
        "\n",
        "    score = w_mod*mod_n + w_stab*(0.5*ari_n + 0.5*vi_n)\n",
        "    df['score'] = score\n",
        "    best = df.iloc[int(np.nanargmax(score))]\n",
        "    return int(best['K']), df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0NwI_b5eix_h",
      "metadata": {
        "id": "0NwI_b5eix_h"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Patch: robust Variation of Information (VI)\n",
        "# (fixes boolean indexing shape mismatch)\n",
        "# =========================\n",
        "import numpy as np\n",
        "\n",
        "def variation_of_information(labels_a, labels_b, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Robust VI: VI(A,B) = H(A) + H(B) - 2 I(A;B)\n",
        "    Works even if one clustering has 1 cluster or missing label ids.\n",
        "    Uses natural log.\n",
        "    \"\"\"\n",
        "    a = np.asarray(labels_a)\n",
        "    b = np.asarray(labels_b)\n",
        "    if a.shape[0] != b.shape[0]:\n",
        "        raise ValueError(\"labels_a and labels_b must have same length\")\n",
        "\n",
        "    # remap to consecutive 0..(k-1)\n",
        "    _, a = np.unique(a, return_inverse=True)\n",
        "    _, b = np.unique(b, return_inverse=True)\n",
        "\n",
        "    ka = int(a.max()) + 1\n",
        "    kb = int(b.max()) + 1\n",
        "    n = float(len(a))\n",
        "\n",
        "    # contingency counts via 1D bincount trick\n",
        "    idx = a * kb + b\n",
        "    cont = np.bincount(idx, minlength=ka * kb).reshape(ka, kb).astype(float)\n",
        "\n",
        "    pab = cont / n\n",
        "    pa = pab.sum(axis=1, keepdims=True)  # (ka,1)\n",
        "    pb = pab.sum(axis=0, keepdims=True)  # (1,kb)\n",
        "\n",
        "    # entropies (avoid log(0))\n",
        "    pa1 = pa.ravel()\n",
        "    pb1 = pb.ravel()\n",
        "    Ha = -np.sum(pa1[pa1 > 0] * np.log(pa1[pa1 > 0] + eps))\n",
        "    Hb = -np.sum(pb1[pb1 > 0] * np.log(pb1[pb1 > 0] + eps))\n",
        "\n",
        "    # mutual information on nonzero cells\n",
        "    nz = pab > 0\n",
        "    I = np.sum(pab[nz] * (np.log(pab[nz] + eps) - np.log(pa[nz.any(axis=1), :] + eps)[np.repeat(np.arange(ka), nz.sum(axis=1))[:pab[nz].shape[0]]]*0))\n",
        "    # ↑ ignore this line (we'll compute MI cleanly below)\n",
        "\n",
        "    # clean MI computation (safe & simple)\n",
        "    I = 0.0\n",
        "    for i in range(ka):\n",
        "        for j in range(kb):\n",
        "            pij = pab[i, j]\n",
        "            if pij > 0:\n",
        "                I += pij * (np.log(pij + eps) - np.log(pa[i, 0] + eps) - np.log(pb[0, j] + eps))\n",
        "\n",
        "    return float(Ha + Hb - 2.0 * I)\n",
        "\n",
        "print(\"✅ Patched variation_of_information()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72cb94a",
      "metadata": {
        "id": "c72cb94a"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# K model selection (fixed: defines G if missing)\n",
        "# =========================\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pyg_to_nx(data, undirected=True, use_weights=False):\n",
        "    \"\"\"\n",
        "    Convert a PyG Data object (with edge_index) to a NetworkX graph.\n",
        "    Keeps isolates by adding all nodes [0..num_nodes-1].\n",
        "    \"\"\"\n",
        "    ei = data.edge_index.detach().cpu().numpy()\n",
        "    src = ei[0].astype(int)\n",
        "    dst = ei[1].astype(int)\n",
        "\n",
        "    Gx = nx.Graph() if undirected else nx.DiGraph()\n",
        "\n",
        "    if use_weights and hasattr(data, \"edge_weight\") and data.edge_weight is not None:\n",
        "        w = data.edge_weight.detach().cpu().numpy().astype(float)\n",
        "        Gx.add_weighted_edges_from([(u, v, float(wi)) for u, v, wi in zip(src, dst, w)])\n",
        "    else:\n",
        "        Gx.add_edges_from(zip(src, dst))\n",
        "\n",
        "    # ensure isolates exist\n",
        "    Gx.add_nodes_from(range(int(data.num_nodes)))\n",
        "\n",
        "    # remove self-loops (usually best for modularity)\n",
        "    Gx.remove_edges_from(nx.selfloop_edges(Gx))\n",
        "\n",
        "    if undirected:\n",
        "        Gx = Gx.to_undirected()\n",
        "\n",
        "    return Gx\n",
        "\n",
        "\n",
        "if RUN_K_MODEL_SELECTION:\n",
        "    # ---- pick embeddings source ----\n",
        "    if 'z_dgi_np' in globals():\n",
        "        _z_sel = z_dgi_np\n",
        "        _z_name = \"DGI\"\n",
        "    elif 'z_tr_np' in globals():\n",
        "        _z_sel = z_tr_np\n",
        "        _z_name = \"VGAE-Transformer\"\n",
        "    elif 'z_mean' in globals():\n",
        "        _z_sel = z_mean.detach().cpu().numpy()\n",
        "        _z_name = \"VGAE(base)\"\n",
        "    else:\n",
        "        _z_sel = None\n",
        "        _z_name = None\n",
        "\n",
        "    if _z_sel is None:\n",
        "        print(\"No embeddings found for K scan.\")\n",
        "    else:\n",
        "        # ---- build/ensure NetworkX graph G ----\n",
        "        if 'G' not in globals() or G is None:\n",
        "            if 'data_train' in globals():\n",
        "                G = pyg_to_nx(data_train, undirected=True, use_weights=False)\n",
        "                print(\"✅ Built NetworkX G from data_train.\")\n",
        "            elif 'data' in globals():\n",
        "                G = pyg_to_nx(data, undirected=True, use_weights=False)\n",
        "                print(\"✅ Built NetworkX G from data.\")\n",
        "            elif 'data_full' in globals():\n",
        "                G = pyg_to_nx(data_full, undirected=True, use_weights=False)\n",
        "                print(\"✅ Built NetworkX G from data_full.\")\n",
        "            else:\n",
        "                raise NameError(\"G is not defined and no PyG object found (data_train/data/data_full).\")\n",
        "\n",
        "        # sanity check\n",
        "        print(\"G nodes:\", G.number_of_nodes(), \"G edges:\", G.number_of_edges(), \"Z shape:\", _z_sel.shape)\n",
        "        if G.number_of_nodes() != _z_sel.shape[0]:\n",
        "            raise ValueError(f\"Mismatch: G has {G.number_of_nodes()} nodes but embeddings have {_z_sel.shape[0]} rows.\")\n",
        "\n",
        "        # ---- scan K ----\n",
        "        K_list = list(range(10, 151, 10))\n",
        "        df_scan = scan_K_for_embeddings(_z_sel, G, K_list, seeds=(0,1,2,3,4))\n",
        "        K_star, df_scan_scored = pick_K(df_scan, w_mod=1.0, w_stab=1.0)\n",
        "\n",
        "        display(df_scan_scored)\n",
        "        print(f\"✅ Suggested K*={K_star} based on modularity+stability using {_z_name} embeddings\")\n",
        "\n",
        "        # ---- simple plots ----\n",
        "        plt.figure()\n",
        "        plt.plot(df_scan_scored['K'], df_scan_scored['modularity'], marker='o')\n",
        "        plt.xlabel(\"K\"); plt.ylabel(\"Modularity\")\n",
        "        plt.title(f\"Modularity vs K ({_z_name})\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(df_scan_scored['K'], df_scan_scored['ari_mean'], marker='o')\n",
        "        plt.xlabel(\"K\"); plt.ylabel(\"Stability (pairwise ARI mean)\")\n",
        "        plt.title(f\"Stability vs K ({_z_name})\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"🟦 K model selection disabled.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a57daa20",
      "metadata": {
        "id": "a57daa20"
      },
      "source": [
        "\n",
        "## 26F) Stability report for all methods already computed\n",
        "\n",
        "If earlier sections produced multiple clustering labelings per method (e.g., multi-seed),\n",
        "we summarize stability here.\n",
        "\n",
        "If your notebook stores results in a dict like `cluster_runs[method] = [labels_seed0, ...]`,\n",
        "this cell will auto-detect it. Otherwise, you can adapt it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e518bbe",
      "metadata": {
        "id": "1e518bbe"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Build `cluster_runs` automatically from df_clusters (and/or existing globals)\n",
        "# =========================\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "cluster_runs = {}  # method -> list of label arrays\n",
        "\n",
        "def _as_int_labels(x):\n",
        "    a = np.asarray(x)\n",
        "    # try to coerce to int safely\n",
        "    if np.issubdtype(a.dtype, np.number):\n",
        "        return a.astype(int)\n",
        "    return pd.Series(a).astype(\"category\").cat.codes.values.astype(int)\n",
        "\n",
        "# 1) From df_clusters columns (recommended)\n",
        "if \"df_clusters\" in globals() and isinstance(df_clusters, pd.DataFrame) and len(df_clusters) > 0:\n",
        "    dfc = df_clusters.copy()\n",
        "\n",
        "    # Ensure sorted by node if column exists\n",
        "    if \"node\" in dfc.columns:\n",
        "        dfc = dfc.sort_values(\"node\").drop_duplicates(\"node\")\n",
        "\n",
        "    # candidate label columns: numeric-ish and not metadata\n",
        "    meta_cols = {\"node\", \"protein\", \"gene\", \"name\", \"id\"}\n",
        "    cand_cols = [c for c in dfc.columns if c not in meta_cols]\n",
        "\n",
        "    # group columns by base method name (strip _seed\\d+ suffix)\n",
        "    groups = {}\n",
        "    for c in cand_cols:\n",
        "        base = re.sub(r\"_seed\\d+$\", \"\", str(c))\n",
        "        groups.setdefault(base, []).append(c)\n",
        "\n",
        "    # build runs\n",
        "    for base, cols in groups.items():\n",
        "        runs = []\n",
        "        for c in sorted(cols):\n",
        "            lab = dfc[c].values\n",
        "            # skip if all nan\n",
        "            if pd.isna(lab).all():\n",
        "                continue\n",
        "            # drop rows where label missing\n",
        "            mask = ~pd.isna(lab)\n",
        "            lab = _as_int_labels(lab[mask])\n",
        "            runs.append(lab)\n",
        "        if len(runs) > 0:\n",
        "            cluster_runs[base] = runs\n",
        "\n",
        "# 2) Also capture any explicit label lists you might already have lying around\n",
        "# e.g. labels_seed0, labels_seed1 ... (optional)\n",
        "_seed_vars = [k for k in globals().keys() if re.match(r\".*labels.*seed\\d+$\", k)]\n",
        "for k in _seed_vars:\n",
        "    base = re.sub(r\"_seed\\d+$\", \"\", k)\n",
        "    try:\n",
        "        lab = _as_int_labels(globals()[k])\n",
        "        cluster_runs.setdefault(base, []).append(lab)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "print(\"✅ Built cluster_runs with methods:\", list(cluster_runs.keys())[:20], \"...\")\n",
        "print({k: len(v) for k, v in list(cluster_runs.items())[:20]})\n",
        "if len(cluster_runs) == 0:\n",
        "    print(\"⚠️ cluster_runs is empty. Most likely df_clusters has no label columns or they are all NaN.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95751ed4",
      "metadata": {
        "id": "95751ed4"
      },
      "source": [
        "\n",
        "## 26G) Multi-task Modularity-Aware GAE/VGAE (end-to-end link prediction + community structure)\n",
        "\n",
        "This add-on trains a **single model** to optimize both:\n",
        "- **link reconstruction / link prediction** (standard GAE/VGAE objective), and\n",
        "- a **differentiable modularity surrogate** computed **sparsely** from `edge_index` (no dense `N×N` matrices).\n",
        "\n",
        "It is optional and **OFF by default** to keep runtimes reasonable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2727cbc",
      "metadata": {
        "id": "f2727cbc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 26G) Modularity-aware multi-task training (OFF by default)\n",
        "# - Learns node embeddings z AND soft cluster assignments S\n",
        "# - Optimizes: L = L_recon + beta * L_KL (optional) + lambda_mod * (-Q_sparse)\n",
        "# - Q_sparse computed from edges + degree-weighted cluster volumes (no dense matrices)\n",
        "# =========================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "RUN_MODULARITY_AWARE_GAE = True   # <-- set True to run\n",
        "USE_VARIATIONAL = True            # if True: include KL term (VGAE-like), else plain GAE\n",
        "MOD_K = 10                         # number of clusters (try 10, or match your selected K)\n",
        "LAMBDA_MOD = 1.0                   # strength of modularity term\n",
        "BETA_KL = 1.0                      # KL weight (only if USE_VARIATIONAL=True)\n",
        "EPOCHS_MOD = 150\n",
        "LR_MOD = 1e-3\n",
        "HIDDEN_MOD = 128\n",
        "Z_DIM_MOD = 64\n",
        "\n",
        "def _get_edge_index_from_data(data_obj):\n",
        "    for attr in [\"edge_index\", \"train_pos_edge_index\", \"pos_edge_index\"]:\n",
        "        if hasattr(data_obj, attr):\n",
        "            ei = getattr(data_obj, attr)\n",
        "            if ei is not None:\n",
        "                return ei\n",
        "    return None\n",
        "\n",
        "def sparse_modularity_Q(edge_index, S, num_nodes):\n",
        "    # Sparse modularity surrogate:\n",
        "    # Q = (term1 / (2m)) - (term2 / (2m)^2)\n",
        "    # term1 = sum_{(u,v) in E} <S_u, S_v>\n",
        "    # term2 = sum_k (a_k)^2, where a_k = sum_u deg(u) * S_{u,k}\n",
        "    device = S.device\n",
        "    E = edge_index.size(1)\n",
        "\n",
        "    deg = torch.zeros(num_nodes, device=device)\n",
        "    deg.scatter_add_(0, edge_index[0], torch.ones(E, device=device))\n",
        "\n",
        "    m2 = deg.sum().clamp(min=1.0)  # equals 2m if edges are doubled; otherwise proportional\n",
        "\n",
        "    Su = S[edge_index[0]]  # [E, K]\n",
        "    Sv = S[edge_index[1]]  # [E, K]\n",
        "    term1 = (Su * Sv).sum(dim=1).sum()\n",
        "\n",
        "    a = (deg.view(-1, 1) * S).sum(dim=0)  # [K]\n",
        "    term2 = (a * a).sum()\n",
        "\n",
        "    Q = (term1 / m2) - (term2 / (m2 * m2))\n",
        "    return Q\n",
        "\n",
        "class ModAwareEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, z_dim=64, encoder_type=\"GCN\"):\n",
        "        super().__init__()\n",
        "        from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "        self.encoder_type = encoder_type.upper()\n",
        "        if self.encoder_type == \"SAGE\":\n",
        "            self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "            self.conv2 = SAGEConv(hidden_dim, z_dim)\n",
        "        elif self.encoder_type == \"GAT\":\n",
        "            self.conv1 = GATConv(in_dim, hidden_dim // 2, heads=2, concat=True)\n",
        "            self.conv2 = GATConv(hidden_dim, z_dim, heads=1, concat=True)\n",
        "        else:\n",
        "            self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "            self.conv2 = GCNConv(hidden_dim, z_dim)\n",
        "\n",
        "        self.mu = nn.Linear(z_dim, z_dim)\n",
        "        self.logstd = nn.Linear(z_dim, z_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, variational=False):\n",
        "        h = F.relu(self.conv1(x, edge_index))\n",
        "        z0 = self.conv2(h, edge_index)\n",
        "        if not variational:\n",
        "            return z0, None, None\n",
        "        mu = self.mu(z0)\n",
        "        logstd = self.logstd(z0).clamp(-10, 10)\n",
        "        std = logstd.exp()\n",
        "        z = mu + torch.randn_like(std) * std\n",
        "        return z, mu, logstd\n",
        "\n",
        "class DotDecoder(nn.Module):\n",
        "    def forward(self, z, edge_index):\n",
        "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
        "\n",
        "class ModularityAwareGAE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, z_dim=64, K=10, encoder_type=\"GCN\"):\n",
        "        super().__init__()\n",
        "        self.enc = ModAwareEncoder(in_dim, hidden_dim, z_dim, encoder_type=encoder_type)\n",
        "        self.dec = DotDecoder()\n",
        "        self.assign_head = nn.Linear(z_dim, K)\n",
        "\n",
        "    def forward(self, x, edge_index, variational=False):\n",
        "        z, mu, logstd = self.enc(x, edge_index, variational=variational)\n",
        "        S = F.softmax(self.assign_head(z), dim=1)  # [N, K]\n",
        "        return z, S, mu, logstd\n",
        "\n",
        "def recon_loss_with_neg_sampling(z, pos_edge_index, num_nodes, neg_ratio=1.0):\n",
        "    pos_score = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1)\n",
        "    pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score))\n",
        "\n",
        "    num_neg = int(pos_edge_index.size(1) * neg_ratio)\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=pos_edge_index,\n",
        "        num_nodes=num_nodes,\n",
        "        num_neg_samples=num_neg,\n",
        "        method=\"sparse\",\n",
        "    )\n",
        "    neg_score = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1)\n",
        "    neg_loss = F.binary_cross_entropy_with_logits(neg_score, torch.zeros_like(neg_score))\n",
        "    return pos_loss + neg_loss\n",
        "\n",
        "def kl_loss(mu, logstd):\n",
        "    return -0.5 * torch.mean(torch.sum(1 + 2*logstd - mu**2 - (2*logstd).exp(), dim=1))\n",
        "\n",
        "if RUN_MODULARITY_AWARE_GAE:\n",
        "    assert \"data_train\" in globals(), \"Need `data_train` (PyG Data) in memory.\"\n",
        "    dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    data_tr = data_train.to(dev)\n",
        "\n",
        "    edge_index_tr = _get_edge_index_from_data(data_tr)\n",
        "    assert edge_index_tr is not None, \"Could not find train edge_index in data_train.\"\n",
        "\n",
        "    x = data_tr.x\n",
        "    if x is None:\n",
        "        x = torch.eye(int(data_tr.num_nodes), device=dev)\n",
        "\n",
        "    model_mod = ModularityAwareGAE(\n",
        "        in_dim=x.size(1),\n",
        "        hidden_dim=HIDDEN_MOD,\n",
        "        z_dim=Z_DIM_MOD,\n",
        "        K=MOD_K,\n",
        "        encoder_type=\"GCN\",\n",
        "    ).to(dev)\n",
        "\n",
        "    opt = torch.optim.Adam(model_mod.parameters(), lr=LR_MOD)\n",
        "\n",
        "    for epoch in range(1, EPOCHS_MOD + 1):\n",
        "        model_mod.train()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        z, S, mu, logstd = model_mod(x, edge_index_tr, variational=USE_VARIATIONAL)\n",
        "\n",
        "        loss_recon = recon_loss_with_neg_sampling(z, edge_index_tr, num_nodes=int(data_tr.num_nodes), neg_ratio=1.0)\n",
        "        Q = sparse_modularity_Q(edge_index_tr, S, num_nodes=int(data_tr.num_nodes))\n",
        "        loss_mod = -Q  # maximize Q\n",
        "\n",
        "        loss = loss_recon + (LAMBDA_MOD * loss_mod)\n",
        "        if USE_VARIATIONAL and (mu is not None) and (logstd is not None):\n",
        "            loss = loss + (BETA_KL * kl_loss(mu, logstd))\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if epoch % 25 == 0 or epoch == 1:\n",
        "            print(f\"[ModAware] epoch {epoch:03d} | loss={float(loss):.4f} | recon={float(loss_recon):.4f} | Q={float(Q):.5f}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_mod.eval()\n",
        "        z, S, _, _ = model_mod(x, edge_index_tr, variational=USE_VARIATIONAL)\n",
        "        hard = S.argmax(dim=1).detach().cpu().numpy()\n",
        "\n",
        "    import pandas as pd\n",
        "    if \"df_clusters\" in globals() and isinstance(df_clusters, pd.DataFrame):\n",
        "        df_clusters[\"modaware_cluster\"] = hard\n",
        "        print(\"✅ Added df_clusters['modaware_cluster']\")\n",
        "    else:\n",
        "        df_clusters = pd.DataFrame({\"node\": np.arange(len(hard)), \"modaware_cluster\": hard})\n",
        "        print(\"✅ Created df_clusters with 'modaware_cluster'\")\n",
        "\n",
        "    if \"evaluate_clustering_metrics\" in globals():\n",
        "        try:\n",
        "            _ = evaluate_clustering_metrics(\"modaware_cluster\")\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ evaluate_clustering_metrics failed:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b40fcf",
      "metadata": {
        "id": "a1b40fcf"
      },
      "source": [
        "\n",
        "## 26H) Link prediction calibration & threshold analysis (Brier score + reliability plot)\n",
        "\n",
        "AUC/AP do **not** tell you if predicted probabilities are calibrated.  \n",
        "This section adds:\n",
        "- **Brier score** (calibration quality),\n",
        "- **reliability diagram** (binning predicted probabilities),\n",
        "- optional **threshold sweep** for F1/precision/recall if you need a decision rule.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588a76cd",
      "metadata": {
        "id": "588a76cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 26H) Calibration metrics for link prediction\n",
        "# =========================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def brier_score(y_true, p):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    p = np.asarray(p).astype(float)\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    return np.mean((p - y_true)**2)\n",
        "\n",
        "def reliability_bins(y_true, p, n_bins=10):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    p = np.asarray(p).astype(float)\n",
        "    p = np.clip(p, 1e-9, 1-1e-9)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    idx = np.digitize(p, bins) - 1\n",
        "    frac_pos, conf, counts = [], [], []\n",
        "    for b in range(n_bins):\n",
        "        m = idx == b\n",
        "        counts.append(int(m.sum()))\n",
        "        if m.sum() == 0:\n",
        "            frac_pos.append(np.nan); conf.append(np.nan)\n",
        "        else:\n",
        "            frac_pos.append(float(y_true[m].mean()))\n",
        "            conf.append(float(p[m].mean()))\n",
        "    return np.array(conf), np.array(frac_pos), np.array(counts), bins\n",
        "\n",
        "def plot_reliability(y_true, p, name=\"\", n_bins=10, savepath=\"reliability.png\"):\n",
        "    conf, frac_pos, counts, _ = reliability_bins(y_true, p, n_bins=n_bins)\n",
        "    plt.figure()\n",
        "    plt.plot([0,1],[0,1])\n",
        "    plt.scatter(conf, frac_pos, s=np.maximum(counts,1))\n",
        "    plt.xlabel(\"Mean predicted probability (bin)\")\n",
        "    plt.ylabel(\"Empirical fraction positive\")\n",
        "    plt.title(f\"Reliability diagram {name}\".strip())\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(savepath, dpi=300)\n",
        "    plt.show()\n",
        "    return savepath\n",
        "\n",
        "if \"y_test\" in globals() and \"score_dict\" in globals() and isinstance(score_dict, dict) and len(score_dict)>0:\n",
        "    y_true = np.array(y_test)\n",
        "    # choose first method (or change manually)\n",
        "    best_name = list(score_dict.keys())[0]\n",
        "    s = np.asarray(score_dict[best_name])\n",
        "    p = 1/(1+np.exp(-s)) if (s.min() < 0 or s.max() > 1) else np.clip(s, 1e-9, 1-1e-9)\n",
        "\n",
        "    print(\"Method:\", best_name)\n",
        "    print(\"Brier score:\", brier_score(y_true, p))\n",
        "    plot_reliability(y_true, p, name=best_name, savepath=\"reliability_best.png\")\n",
        "else:\n",
        "    print(\"ℹ️ No (y_test, score_dict) found. Run link prediction evaluation first to populate them.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b201d746",
      "metadata": {
        "id": "b201d746"
      },
      "source": [
        "\n",
        "## 26I) Confidence intervals & significance tests (bootstrap)\n",
        "\n",
        "Paper-friendly reporting usually includes uncertainty:\n",
        "- 95% CI for AUC/AP (bootstrap on test edges),\n",
        "- CI for modularity (bootstrap on runs),\n",
        "- quick method comparison via resampling.\n",
        "\n",
        "This is lightweight and runs on saved per-seed CSVs if present.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f214a634",
      "metadata": {
        "id": "f214a634"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 26I) Bootstrap CI for AUC/AP & modularity from per-seed results\n",
        "# =========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def bootstrap_ci(values, n_boot=2000, ci=0.95, seed=0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    v = np.asarray(values, dtype=float)\n",
        "    v = v[~np.isnan(v)]\n",
        "    if len(v) == 0:\n",
        "        return np.nan, np.nan, np.nan, 0\n",
        "    boots = rng.choice(v, size=(n_boot, len(v)), replace=True).mean(axis=1)\n",
        "    lo = np.quantile(boots, (1-ci)/2)\n",
        "    hi = np.quantile(boots, 1-(1-ci)/2)\n",
        "    return float(v.mean()), float(lo), float(hi), int(len(v))\n",
        "\n",
        "if os.path.exists(\"deep_models_linkpred_clustering_metrics.csv\"):\n",
        "    df = pd.read_csv(\"deep_models_linkpred_clustering_metrics.csv\")\n",
        "    for metric in [\"AUC\", \"AP\", \"modularity\"]:\n",
        "        if metric in df.columns:\n",
        "            print(\"\\nMetric:\", metric)\n",
        "            for method in sorted(df[\"method\"].unique()):\n",
        "                vals = df.loc[df[\"method\"]==method, metric].values\n",
        "                m, lo, hi, n = bootstrap_ci(vals)\n",
        "                print(f\"{method:30s} | {m:.4f} (95% CI {lo:.4f}, {hi:.4f}) | n={n}\")\n",
        "else:\n",
        "    print(\"ℹ️ deep_models_linkpred_clustering_metrics.csv not found. Run the deep-model multi-seed section first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf701123",
      "metadata": {
        "id": "cf701123"
      },
      "source": [
        "\n",
        "## 26J) Leiden/Louvain resolution sweep (optional)\n",
        "\n",
        "A robustness check is sweeping the **resolution parameter** and plotting how **modularity** (and optionally external validation) changes.\n",
        "\n",
        "This section is optional (depends on `igraph` + `leidenalg`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cfbf32d",
      "metadata": {
        "id": "4cfbf32d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 26J) Resolution sweep for Leiden (optional)\n",
        "# =========================\n",
        "RUN_LEIDEN_RES_SWEEP = True  # <-- set True to run\n",
        "RES_LIST = [0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n",
        "\n",
        "if RUN_LEIDEN_RES_SWEEP:\n",
        "    try:\n",
        "        import igraph as ig\n",
        "        import leidenalg\n",
        "        import networkx as nx\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "        G0 = globals().get(\"G_train\", globals().get(\"G\", None))\n",
        "        assert G0 is not None, \"Need networkx graph `G_train` or `G` in memory.\"\n",
        "\n",
        "        edges = list(G0.edges())\n",
        "        N = G0.number_of_nodes()\n",
        "        gi = ig.Graph(n=N, edges=edges, directed=False)\n",
        "\n",
        "        rows=[]\n",
        "        for res in RES_LIST:\n",
        "            part = leidenalg.find_partition(gi, leidenalg.RBConfigurationVertexPartition, resolution_parameter=res)\n",
        "            labels = np.array(part.membership, dtype=int)\n",
        "            comms = {}\n",
        "            for n,l in enumerate(labels):\n",
        "                comms.setdefault(int(l), []).append(n)\n",
        "            Qnx = float(nx_modularity(G0, list(comms.values())))\n",
        "            rows.append({\"resolution\": res, \"n_clusters\": int(labels.max()+1), \"modularity_nx\": Qnx})\n",
        "\n",
        "        df_res = pd.DataFrame(rows)\n",
        "        display(df_res)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(df_res[\"resolution\"], df_res[\"modularity_nx\"], marker=\"o\")\n",
        "        plt.xlabel(\"Leiden resolution parameter\")\n",
        "        plt.ylabel(\"Modularity (networkx)\")\n",
        "        plt.title(\"Resolution sweep: Leiden modularity\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"leiden_resolution_sweep.png\", dpi=300)\n",
        "        plt.show()\n",
        "        print(\"Saved: leiden_resolution_sweep.png\")\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Leiden resolution sweep failed:\", e)\n",
        "else:\n",
        "    print(\"ℹ️ Set RUN_LEIDEN_RES_SWEEP=True to run (requires igraph + leidenalg).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zrqHUFnaIMsa",
      "metadata": {
        "id": "zrqHUFnaIMsa"
      },
      "source": [
        "# ✅ (NEW) Robust Transformer-VGAE evaluation cell (fixes missing `z_tr`)\n",
        "\n",
        "This cell evaluates **Transformer-VGAE** (AUC/AP) and performs **KMeans clustering on its embeddings**, **without hard-failing** if a variable is missing.\n",
        "It will automatically try to find embeddings in common variable names and will build a **manual test split** if no `data_test` split exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R3knmtvQIMsa",
      "metadata": {
        "id": "R3knmtvQIMsa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 26C-FIX) Robust eval for Transformer-VGAE embeddings (AUC/AP) + clustering metrics\n",
        "# - No hard assert: tries multiple embedding variable names.\n",
        "# - Builds manual pos/neg split if no data_test exists.\n",
        "# Saves:\n",
        "#  - transformer_vgae_linkpred_metrics.csv\n",
        "#  - Adds cluster labels into df_clusters (if exists) and method row into df_deep (if exists)\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ---------- 0) Find embeddings ----------\n",
        "Z = None\n",
        "for nm in [\"z_tr\", \"z_transformer\", \"z_vgae_tr\", \"z_vgae_transformer\", \"z_mean_tr\", \"z\"]:\n",
        "    if nm in globals():\n",
        "        cand = globals()[nm]\n",
        "        if torch.is_tensor(cand):\n",
        "            Z = cand\n",
        "            print(f\"✅ Using embeddings from variable: {nm} (shape={tuple(Z.shape)})\")\n",
        "            break\n",
        "\n",
        "if Z is None:\n",
        "    print(\"❌ Δεν βρέθηκαν Transformer-VGAE embeddings.\")\n",
        "    print(\"➡️ Τρέξε πρώτα το cell που εκπαιδεύει το VGAE-Transformer και δημιουργεί embeddings (π.χ. `z_tr`).\")\n",
        "else:\n",
        "    z_np = Z.detach().cpu().numpy()\n",
        "    N = z_np.shape[0]\n",
        "\n",
        "    # ---------- 1) Pick / build a test split ----------\n",
        "    split_obj = None\n",
        "    for nm in [\"data_test\", \"test_data\", \"data_val\", \"val_data\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "            split_obj = globals()[nm]\n",
        "            print(f\"✅ Using existing split object: {nm}\")\n",
        "            break\n",
        "\n",
        "    if split_obj is None:\n",
        "        pyg_base = None\n",
        "        for nm in [\"data_train\", \"data_lcc\", \"data_full\", \"data\"]:\n",
        "            if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "                pyg_base = globals()[nm]\n",
        "                print(f\"ℹ️ Building manual split from: {nm}\")\n",
        "                break\n",
        "        if pyg_base is None:\n",
        "            raise RuntimeError(\"Δεν βρέθηκε PyG data (data_train/data_lcc/data_full/data) για να χτίσω split.\")\n",
        "\n",
        "        ei = pyg_base.edge_index.detach().cpu().numpy()\n",
        "        u, v = ei[0], ei[1]\n",
        "\n",
        "        # make undirected unique edges (u<v)\n",
        "        m = u < v\n",
        "        und = np.stack([u[m], v[m]], axis=0)\n",
        "        if und.shape[1] == 0:\n",
        "            uu = np.minimum(u, v)\n",
        "            vv = np.maximum(u, v)\n",
        "            und = np.stack([uu, vv], axis=0)\n",
        "        und = np.unique(und, axis=1)\n",
        "\n",
        "        E = und.shape[1]\n",
        "        rng = np.random.default_rng(0)\n",
        "        idx = rng.permutation(E)\n",
        "\n",
        "        test_frac = 0.10\n",
        "        n_test = max(1, int(test_frac * E))\n",
        "        pos_edge = und[:, idx[:n_test]]\n",
        "\n",
        "        # negative sampling (avoid existing edges)\n",
        "        edge_set = set(map(tuple, und.T.tolist()))\n",
        "        neg_u, neg_v = [], []\n",
        "        while len(neg_u) < n_test:\n",
        "            a = int(rng.integers(0, N))\n",
        "            b = int(rng.integers(0, N))\n",
        "            if a == b:\n",
        "                continue\n",
        "            aa, bb = (a, b) if a < b else (b, a)\n",
        "            if (aa, bb) in edge_set:\n",
        "                continue\n",
        "            neg_u.append(aa); neg_v.append(bb)\n",
        "            edge_set.add((aa, bb))\n",
        "        neg_edge = np.stack([np.array(neg_u), np.array(neg_v)], axis=0)\n",
        "\n",
        "        print(f\"✅ Manual split created: pos={pos_edge.shape[1]}, neg={neg_edge.shape[1]}\")\n",
        "    else:\n",
        "        def _get_pos_neg_edges(split_data):\n",
        "            if hasattr(split_data, \"pos_edge_label_index\") and hasattr(split_data, \"neg_edge_label_index\"):\n",
        "                if split_data.pos_edge_label_index is not None and split_data.neg_edge_label_index is not None:\n",
        "                    pos = split_data.pos_edge_label_index.detach().cpu().numpy()\n",
        "                    neg = split_data.neg_edge_label_index.detach().cpu().numpy()\n",
        "                    return pos, neg\n",
        "            if hasattr(split_data, \"edge_label_index\") and hasattr(split_data, \"edge_label\"):\n",
        "                eidx = split_data.edge_label_index.detach().cpu().numpy()\n",
        "                elab = split_data.edge_label.detach().cpu().numpy()\n",
        "                pos = eidx[:, elab == 1]\n",
        "                neg = eidx[:, elab == 0]\n",
        "                return pos, neg\n",
        "            raise AttributeError(\"Δεν βρήκα pos/neg labeled edges στο split object.\")\n",
        "        pos_edge, neg_edge = _get_pos_neg_edges(split_obj)\n",
        "        print(f\"✅ Extracted from split: pos={pos_edge.shape[1]}, neg={neg_edge.shape[1]}\")\n",
        "\n",
        "    # ---------- 2) Link prediction scoring (dot-product) ----------\n",
        "    def _dot_score(z_np, edge_2xE):\n",
        "        uu = edge_2xE[0].astype(int)\n",
        "        vv = edge_2xE[1].astype(int)\n",
        "        return (z_np[uu] * z_np[vv]).sum(axis=1)\n",
        "\n",
        "    pos_s = _dot_score(z_np, pos_edge)\n",
        "    neg_s = _dot_score(z_np, neg_edge)\n",
        "    y_true = np.concatenate([np.ones_like(pos_s), np.zeros_like(neg_s)])\n",
        "    y_score = np.concatenate([pos_s, neg_s])\n",
        "\n",
        "    auc = float(roc_auc_score(y_true, y_score))\n",
        "    ap  = float(average_precision_score(y_true, y_score))\n",
        "    print(f\"✅ Transformer-VGAE link prediction: AUC={auc:.4f}, AP={ap:.4f}\")\n",
        "\n",
        "    # ---------- 3) Clustering on embeddings ----------\n",
        "    K_tr = int(globals().get(\"K\", globals().get(\"K_CLUSTERS\", 50)))\n",
        "    labels_tr = KMeans(n_clusters=K_tr, n_init=20, random_state=0).fit_predict(z_np)\n",
        "\n",
        "    # ensure df_clusters exists + aligned\n",
        "    if \"df_clusters\" not in globals():\n",
        "        df_clusters = pd.DataFrame({\"node\": np.arange(N)})\n",
        "    else:\n",
        "        if \"node\" not in df_clusters.columns:\n",
        "            df_clusters[\"node\"] = np.arange(N)\n",
        "        df_clusters = df_clusters.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "\n",
        "    col_name = f\"VGAE_Transformer_kmeans_K{K_tr}\"\n",
        "    df_clusters[col_name] = labels_tr\n",
        "    print(f\"✅ Added df_clusters['{col_name}']\")\n",
        "\n",
        "    # clustering metrics\n",
        "    if \"compute_cluster_metrics\" not in globals():\n",
        "        print(\"⚠️ compute_cluster_metrics not found. Will save only AUC/AP + labels.\")\n",
        "        row = {\"method\": col_name, \"k\": K_tr, \"AUC\": auc, \"AP\": ap}\n",
        "    else:\n",
        "        G_tmp = globals().get(\"G_eval\", globals().get(\"G\", globals().get(\"G_nx\", None)))\n",
        "        if G_tmp is None:\n",
        "            print(\"⚠️ No NetworkX graph found (G_eval/G/G_nx). Will save only AUC/AP + labels.\")\n",
        "            row = {\"method\": col_name, \"k\": K_tr, \"AUC\": auc, \"AP\": ap}\n",
        "        else:\n",
        "            gt = globals().get(\"gt_labels_corum\", None)\n",
        "            row = compute_cluster_metrics(G_tmp, labels_tr, name=col_name, gt_labels=gt)\n",
        "            row[\"AUC\"] = auc\n",
        "            row[\"AP\"]  = ap\n",
        "            row[\"seed\"] = 0\n",
        "\n",
        "    df_one = pd.DataFrame([row])\n",
        "    display(df_one)\n",
        "\n",
        "    # append to df_deep (for tradeoff plot convenience)\n",
        "    if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame):\n",
        "        df_deep = pd.concat([df_deep, df_one], ignore_index=True)\n",
        "    else:\n",
        "        df_deep = df_one.copy()\n",
        "\n",
        "    df_one.to_csv(\"transformer_vgae_linkpred_metrics.csv\", index=False)\n",
        "    print(\"✅ Saved: transformer_vgae_linkpred_metrics.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-uoJdMBJIMsa",
      "metadata": {
        "id": "-uoJdMBJIMsa"
      },
      "source": [
        "# ✅ (NEW) Improve clustering *first-pass* (cheap wins): K search + stability on embeddings\n",
        "\n",
        "This section does **not** change your pipeline — it just adds a **systematic way** to pick `K` for KMeans on any embedding matrix:\n",
        "- Try multiple K values\n",
        "- Repeat multiple random seeds\n",
        "- Score each K with **modularity + conductance** (and optional CORUM ARI/NMI if available)\n",
        "- Select a K that balances **quality + stability**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DCw-u-CZIMsa",
      "metadata": {
        "id": "DCw-u-CZIMsa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 27A) KMeans K-search + stability on any embeddings Z (cheap clustering improvements)\n",
        "# - Works for any embedding tensor/array: set EMB_VAR to your embedding variable name.\n",
        "# - Outputs:\n",
        "#   - k_search_results.csv\n",
        "#   - k_search_plots.png\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ---- choose which embeddings to cluster ----\n",
        "EMB_VAR = \"z\"  # change to: \"z_appnp\", \"z_tr\", \"z_dgi\", ...\n",
        "if EMB_VAR not in globals():\n",
        "    print(f\"❌ EMB_VAR='{EMB_VAR}' not found. Set EMB_VAR to an existing embedding variable.\")\n",
        "else:\n",
        "    Z = globals()[EMB_VAR]\n",
        "    if hasattr(Z, \"detach\"):\n",
        "        Z = Z.detach().cpu().numpy()\n",
        "    Z = np.asarray(Z)\n",
        "    N = Z.shape[0]\n",
        "\n",
        "    # ---- graph + GT (optional) ----\n",
        "    G_tmp = globals().get(\"G_eval\", globals().get(\"G\", globals().get(\"G_nx\", None)))\n",
        "    gt = globals().get(\"gt_labels_corum\", None)\n",
        "\n",
        "    assert \"compute_cluster_metrics\" in globals(), \"compute_cluster_metrics not found. Run the clustering-metrics cell first.\"\n",
        "    assert G_tmp is not None, \"Need a NetworkX graph (G_eval/G/G_nx).\"\n",
        "\n",
        "    # ---- K search settings ----\n",
        "    Ks = [5, 10, 15, 20, 30, 40, 60, 80, 100]\n",
        "    seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "    rows = []\n",
        "    for K in Ks:\n",
        "        for sd in seeds:\n",
        "            km = KMeans(n_clusters=K, n_init=20, random_state=sd)\n",
        "            lab = km.fit_predict(Z)\n",
        "            r = compute_cluster_metrics(G_tmp, lab, name=f\"{EMB_VAR}_kmeans_K{K}_seed{sd}\", gt_labels=gt)\n",
        "            r[\"K\"] = K\n",
        "            r[\"seed\"] = sd\n",
        "            r[\"emb_var\"] = EMB_VAR\n",
        "            rows.append(r)\n",
        "            print(f\"✅ {EMB_VAR}: K={K} seed={sd} | modularity={r.get('modularity', np.nan):.4f} | cond_mean={r.get('conductance_mean', np.nan):.4f}\")\n",
        "\n",
        "    df_k = pd.DataFrame(rows)\n",
        "    df_k.to_csv(\"k_search_results.csv\", index=False)\n",
        "    print(\"✅ Saved: k_search_results.csv\")\n",
        "\n",
        "    # ---- aggregate over seeds ----\n",
        "    agg_cols = []\n",
        "    for c in [\"modularity\", \"conductance_mean\", \"conductance_median\", \"ARI\", \"NMI\", \"AMI\"]:\n",
        "        if c in df_k.columns:\n",
        "            agg_cols.append(c)\n",
        "\n",
        "    df_agg = df_k.groupby(\"K\")[agg_cols].agg([\"mean\", \"std\"]).reset_index()\n",
        "    display(df_agg)\n",
        "\n",
        "    # ---- pick K by a simple score: modularity - alpha*conductance_mean ----\n",
        "    alpha = 0.5\n",
        "    if \"modularity\" in df_k.columns and \"conductance_mean\" in df_k.columns:\n",
        "        score = df_k.groupby(\"K\").apply(lambda d: float(d[\"modularity\"].mean() - alpha*d[\"conductance_mean\"].mean()))\n",
        "        bestK = int(score.idxmax())\n",
        "        print(f\"🏁 Suggested K={bestK} by score = modularity - {alpha}*conductance_mean\")\n",
        "    else:\n",
        "        bestK = None\n",
        "        print(\"⚠️ Missing modularity/conductance_mean; cannot auto-pick K.\")\n",
        "\n",
        "    # ---- plots (no seaborn) ----\n",
        "    plt.figure()\n",
        "    if \"modularity\" in df_k.columns:\n",
        "        m = df_k.groupby(\"K\")[\"modularity\"].mean()\n",
        "        plt.plot(m.index, m.values, marker=\"o\")\n",
        "        plt.xlabel(\"K\"); plt.ylabel(\"Modularity\"); plt.title(f\"Modularity vs K ({EMB_VAR})\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"ksearch_modularity.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    if \"conductance_mean\" in df_k.columns:\n",
        "        plt.figure()\n",
        "        c = df_k.groupby(\"K\")[\"conductance_mean\"].mean()\n",
        "        plt.plot(c.index, c.values, marker=\"o\")\n",
        "        plt.xlabel(\"K\"); plt.ylabel(\"Conductance (mean)\"); plt.title(f\"Conductance vs K ({EMB_VAR})\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"ksearch_conductance.png\", dpi=300)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OuSyp-aAIMsa",
      "metadata": {
        "id": "OuSyp-aAIMsa"
      },
      "source": [
        "# ✅ (NEW) Unified comparison plots: **all methods** (link prediction + clustering)\n",
        "\n",
        "This cell loads whatever results you already saved (CSV files) and produces:\n",
        "- **Link prediction bars**: AUC/AP per method (top-N)\n",
        "- **Clustering bars**: modularity & conductance per method\n",
        "- **Trade-off scatter**: modularity vs AUC (means across seeds if available)\n",
        "\n",
        "It is robust: if a file/column is missing, it will skip that plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NcqaspYTIMsa",
      "metadata": {
        "id": "NcqaspYTIMsa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# =========================\n",
        "# 27B) Unified plots for ALL methods (link prediction + clustering)\n",
        "# Uses any of these if they exist:\n",
        "#  - paper_main_results_table.csv\n",
        "#  - ALL_methods_metrics.csv\n",
        "#  - deep_models_linkpred_clustering_metrics.csv\n",
        "#  - clustering_metrics_supervised_unsupervised.csv\n",
        "#  - seed_stability_summary_FIXED.csv\n",
        "# Outputs:\n",
        "#  - all_methods_linkpred_bar.png\n",
        "#  - all_methods_clustering_bar.png\n",
        "#  - all_methods_tradeoff.png\n",
        "# =========================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_if_exists(fn):\n",
        "    if os.path.exists(fn):\n",
        "        try:\n",
        "            df = pd.read_csv(fn)\n",
        "            print(f\"✅ Loaded: {fn} ({len(df)} rows)\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed loading {fn}: {e}\")\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "dfs = []\n",
        "\n",
        "# link prediction summary (often contains test_roc_auc/test_ap or AUC/AP)\n",
        "for fn in [\"paper_main_results_table.csv\", \"deep_models_linkpred_clustering_metrics.csv\", \"transformer_vgae_linkpred_metrics.csv\"]:\n",
        "    d = load_if_exists(fn)\n",
        "    if d is not None:\n",
        "        dfs.append(d)\n",
        "\n",
        "# clustering metrics summary\n",
        "for fn in [\"ALL_methods_metrics.csv\", \"clustering_metrics_supervised_unsupervised.csv\"]:\n",
        "    d = load_if_exists(fn)\n",
        "    if d is not None:\n",
        "        dfs.append(d)\n",
        "\n",
        "if len(dfs) == 0:\n",
        "    print(\"❌ No CSVs found. Run the evaluation cells first (they should save CSVs).\")\n",
        "else:\n",
        "    df_all = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "    # standardize method name column\n",
        "    if \"method\" not in df_all.columns:\n",
        "        # try to find some column that looks like method name\n",
        "        for c in [\"name\", \"model\", \"clustering\"]:\n",
        "            if c in df_all.columns:\n",
        "                df_all[\"method\"] = df_all[c].astype(str)\n",
        "                break\n",
        "    df_all[\"method\"] = df_all[\"method\"].astype(str)\n",
        "\n",
        "    # standardize link pred columns\n",
        "    # Try multiple candidates\n",
        "    def pick_col(cands):\n",
        "        for c in cands:\n",
        "            if c in df_all.columns:\n",
        "                return c\n",
        "        return None\n",
        "\n",
        "    col_auc = pick_col([\"AUC\", \"test_roc_auc\", \"roc_auc\", \"auc\", \"value_mean\"])\n",
        "    col_ap  = pick_col([\"AP\", \"test_ap\", \"average_precision\", \"ap\"])\n",
        "\n",
        "    # For paper_main_results_table, linkpred values are in rows: block=linkpred_multi_seed\n",
        "    if col_auc == \"value_mean\" and \"block\" in df_all.columns and \"name\" in df_all.columns:\n",
        "        # extract known rows\n",
        "        sub = df_all[df_all[\"block\"].astype(str).str.contains(\"linkpred\", na=False)].copy()\n",
        "        if len(sub) > 0:\n",
        "            # pivot name->value_mean\n",
        "            piv = sub.pivot_table(index=\"name\", values=\"value_mean\", aggfunc=\"mean\").reset_index()\n",
        "            if \"test_roc_auc\" not in df_all.columns:\n",
        "                # create a linkpred df with AUC/AP if possible\n",
        "                pass\n",
        "\n",
        "    # ---------- Link prediction bar plot ----------\n",
        "    if col_auc is not None:\n",
        "        dlp = df_all.dropna(subset=[col_auc]).copy()\n",
        "        # If multiple seeds exist, average per method\n",
        "        dlp_agg = dlp.groupby(\"method\")[col_auc].mean().sort_values(ascending=False).head(20)\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.bar(dlp_agg.index, dlp_agg.values)\n",
        "        plt.xticks(rotation=60, ha=\"right\")\n",
        "        plt.ylabel(col_auc)\n",
        "        plt.title(\"Link prediction performance (AUC) - top 20 methods\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"all_methods_linkpred_auc_bar.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    if col_ap is not None:\n",
        "        dlp = df_all.dropna(subset=[col_ap]).copy()\n",
        "        dlp_agg = dlp.groupby(\"method\")[col_ap].mean().sort_values(ascending=False).head(20)\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.bar(dlp_agg.index, dlp_agg.values)\n",
        "        plt.xticks(rotation=60, ha=\"right\")\n",
        "        plt.ylabel(col_ap)\n",
        "        plt.title(\"Link prediction performance (AP) - top 20 methods\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"all_methods_linkpred_ap_bar.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    # ---------- Clustering bar plots ----------\n",
        "    if \"modularity\" in df_all.columns:\n",
        "        dc = df_all.dropna(subset=[\"modularity\"]).copy()\n",
        "        dc_agg = dc.groupby(\"method\")[\"modularity\"].mean().sort_values(ascending=False).head(20)\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.bar(dc_agg.index, dc_agg.values)\n",
        "        plt.xticks(rotation=60, ha=\"right\")\n",
        "        plt.ylabel(\"modularity\")\n",
        "        plt.title(\"Clustering quality (modularity) - top 20 methods\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"all_methods_clustering_modularity_bar.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    if \"conductance_mean\" in df_all.columns:\n",
        "        dc = df_all.dropna(subset=[\"conductance_mean\"]).copy()\n",
        "        dc_agg = dc.groupby(\"method\")[\"conductance_mean\"].mean().sort_values(ascending=True).head(20)\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.bar(dc_agg.index, dc_agg.values)\n",
        "        plt.xticks(rotation=60, ha=\"right\")\n",
        "        plt.ylabel(\"conductance_mean (lower is better)\")\n",
        "        plt.title(\"Clustering quality (conductance) - best 20 methods\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"all_methods_clustering_conductance_bar.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    # ---------- Trade-off scatter (modularity vs AUC) ----------\n",
        "    if (\"modularity\" in df_all.columns) and (col_auc is not None):\n",
        "        dtr = df_all.dropna(subset=[\"modularity\", col_auc]).copy()\n",
        "        dtr_agg = dtr.groupby(\"method\")[[\"modularity\", col_auc]].mean().reset_index()\n",
        "        plt.figure(figsize=(6,5))\n",
        "        plt.scatter(dtr_agg[\"modularity\"], dtr_agg[col_auc])\n",
        "        for _, r in dtr_agg.iterrows():\n",
        "            plt.text(r[\"modularity\"], r[col_auc], str(r[\"method\"])[:22], fontsize=8)\n",
        "        plt.xlabel(\"modularity\")\n",
        "        plt.ylabel(col_auc)\n",
        "        plt.title(\"Trade-off: clustering quality vs link prediction\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"all_methods_tradeoff.png\", dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "    print(\"✅ Saved plots: all_methods_linkpred_*_bar.png, all_methods_clustering_*_bar.png, all_methods_tradeoff.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RV7oXvNUIMsb",
      "metadata": {
        "id": "RV7oXvNUIMsb"
      },
      "source": [
        "# =========================\n",
        "# 31) Improvements: Embedding clustering tuning (K-scan + stability + normalization) + Deep clustering tuning (DEC + Sparse-DMoN)\n",
        "# =========================\n",
        "**New additions (no deletions):**\n",
        "- Embedding preprocessing (L2 / Standardize / PCA-Whiten)\n",
        "- K-scan + stability (ARI/AMI) for KMeans and GaussianMixture\n",
        "- Optional HDBSCAN baseline (if installed)\n",
        "- DEC refinement with early stopping on modularity (proxy)\n",
        "- Sparse-DMoN end-to-end modularity optimization on sparse edges (proxy early stopping)\n",
        "- Saves CSVs + plots, and writes best labels into `df_clusters`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yrp54EMxIMsb",
      "metadata": {
        "id": "yrp54EMxIMsb"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 31A) Utilities: embedding preprocessing + stability + safe graph getter\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _get_nx_graph():\n",
        "    # Prefer eval graph if defined, else any G variable\n",
        "    G_tmp = globals().get(\"G_eval\", globals().get(\"G\", globals().get(\"G_nx\", None)))\n",
        "    if G_tmp is None:\n",
        "        raise RuntimeError(\"Need a NetworkX graph in G_eval or G or G_nx before running tuning.\")\n",
        "    return G_tmp\n",
        "\n",
        "def _pairwise_metric_mean(label_list, metric_fn):\n",
        "    vals = []\n",
        "    for i in range(len(label_list)):\n",
        "        for j in range(i+1, len(label_list)):\n",
        "            vals.append(metric_fn(label_list[i], label_list[j]))\n",
        "    return float(np.mean(vals)) if len(vals) else np.nan\n",
        "\n",
        "def embedding_preprocess(Z, mode=\"raw\", pca_dim=None, random_state=0):\n",
        "    \"\"\"\n",
        "    Z: np.ndarray (N,D)\n",
        "    mode:\n",
        "      - raw\n",
        "      - l2\n",
        "      - standardize\n",
        "      - standardize_l2\n",
        "      - whiten  (PCA whitening; optionally reduce to pca_dim)\n",
        "      - whiten_l2\n",
        "    \"\"\"\n",
        "    Z = np.asarray(Z).astype(np.float32)\n",
        "    N, D = Z.shape\n",
        "\n",
        "    if mode == \"raw\":\n",
        "        return Z\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler, normalize\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    if mode == \"l2\":\n",
        "        return normalize(Z, norm=\"l2\", axis=1)\n",
        "\n",
        "    if mode == \"standardize\":\n",
        "        Zs = StandardScaler(with_mean=True, with_std=True).fit_transform(Z)\n",
        "        return Zs.astype(np.float32)\n",
        "\n",
        "    if mode == \"standardize_l2\":\n",
        "        Zs = StandardScaler(with_mean=True, with_std=True).fit_transform(Z)\n",
        "        return normalize(Zs, norm=\"l2\", axis=1).astype(np.float32)\n",
        "\n",
        "    if mode in [\"whiten\", \"whiten_l2\"]:\n",
        "        if pca_dim is None:\n",
        "            pca_dim = min(D, 64)\n",
        "        pca_dim = int(min(pca_dim, D, N-1)) if N > 1 else int(min(pca_dim, D))\n",
        "        pca = PCA(n_components=pca_dim, whiten=True, random_state=random_state)\n",
        "        Zw = pca.fit_transform(Z).astype(np.float32)\n",
        "        if mode == \"whiten\":\n",
        "            return Zw\n",
        "        return normalize(Zw, norm=\"l2\", axis=1).astype(np.float32)\n",
        "\n",
        "    raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "def ensure_df_clusters(N):\n",
        "    if \"df_clusters\" not in globals() or globals()[\"df_clusters\"] is None:\n",
        "        globals()[\"df_clusters\"] = pd.DataFrame({\"node\": np.arange(N)})\n",
        "    dfc = globals()[\"df_clusters\"]\n",
        "    if \"node\" not in dfc.columns:\n",
        "        dfc[\"node\"] = np.arange(N)\n",
        "    dfc = dfc.sort_values(\"node\").drop_duplicates(\"node\").reset_index(drop=True)\n",
        "    globals()[\"df_clusters\"] = dfc\n",
        "    return dfc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EtWWmI5_IMsb",
      "metadata": {
        "id": "EtWWmI5_IMsb"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 31B) Embedding clustering tuning:\n",
        "# - KMeans K-scan + stability (ARI/AMI) + optional preprocessing\n",
        "# - GaussianMixture K-scan + stability\n",
        "# - Optional HDBSCAN baseline (no K), if installed\n",
        "# Output:\n",
        "#  - df_embed_tuning (long format)\n",
        "#  - best labels written into df_clusters (columns like <source>_<algo>_<prep>_best)\n",
        "#  - CSV + plots saved\n",
        "# =========================\n",
        "\n",
        "RUN_EMBED_TUNING = True\n",
        "EMBED_SOURCES = None   # None => auto-detect common embedding arrays\n",
        "PREP_MODES = [\"raw\", \"standardize_l2\", \"whiten_l2\"]  # safe defaults\n",
        "PCA_DIM = 64\n",
        "K_LIST = list(range(10, 151, 10))\n",
        "SEEDS = (0,1,2,3,4)\n",
        "N_INIT = 20\n",
        "W_MOD = 1.0\n",
        "W_STAB = 1.0\n",
        "\n",
        "if RUN_EMBED_TUNING:\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.cluster import KMeans\n",
        "    from sklearn.mixture import GaussianMixture\n",
        "    from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "    G_nx = _get_nx_graph()\n",
        "\n",
        "    # -------- collect embedding sources --------\n",
        "    if EMBED_SOURCES is None:\n",
        "        EMBED_SOURCES = {}\n",
        "        cand = [\n",
        "            (\"VGAE_base\", \"z_mean\"),\n",
        "            (\"VGAE_transformer\", \"z_tr\"),\n",
        "            (\"VGAE_transformer_np\", \"z_tr_np\"),\n",
        "            (\"DGI\", \"z_dgi\"),\n",
        "            (\"DGI_np\", \"z_dgi_np\"),\n",
        "            (\"Node2Vec\", \"node_embeddings\"),\n",
        "            (\"Spectral\", \"spectral_emb\"),\n",
        "        ]\n",
        "        for pretty, nm in cand:\n",
        "            if nm in globals() and globals()[nm] is not None:\n",
        "                obj = globals()[nm]\n",
        "                try:\n",
        "                    if hasattr(obj, \"detach\"):\n",
        "                        Z = obj.detach().cpu().numpy()\n",
        "                    else:\n",
        "                        Z = np.asarray(obj)\n",
        "                    if Z.ndim == 2 and Z.shape[0] > 10:\n",
        "                        EMBED_SOURCES[pretty] = Z\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        if len(EMBED_SOURCES) == 0:\n",
        "            for nm, obj in globals().items():\n",
        "                try:\n",
        "                    if nm.startswith(\"z\") and hasattr(obj, \"detach\"):\n",
        "                        Z = obj.detach().cpu().numpy()\n",
        "                        if Z.ndim == 2 and Z.shape[0] > 10:\n",
        "                            EMBED_SOURCES[nm] = Z\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    assert len(EMBED_SOURCES) > 0, \"No embeddings found. Run at least one representation learning cell first.\"\n",
        "\n",
        "    all_rows = []\n",
        "    for src_name, Z0 in EMBED_SOURCES.items():\n",
        "        Z0 = np.asarray(Z0)\n",
        "        N, D = Z0.shape\n",
        "        ensure_df_clusters(N)\n",
        "\n",
        "        for prep in PREP_MODES:\n",
        "            Z = embedding_preprocess(Z0, mode=prep, pca_dim=PCA_DIM, random_state=0)\n",
        "\n",
        "            # ========== KMeans scan ==========\n",
        "            for K in K_LIST:\n",
        "                labs = []\n",
        "                for s in SEEDS:\n",
        "                    lab = KMeans(n_clusters=K, n_init=N_INIT, random_state=s).fit_predict(Z)\n",
        "                    labs.append(lab)\n",
        "\n",
        "                ari_stab = _pairwise_metric_mean(labs, adjusted_rand_score)\n",
        "                ami_stab = _pairwise_metric_mean(labs, adjusted_mutual_info_score)\n",
        "\n",
        "                lab0 = labs[0]\n",
        "                comms = [list(np.where(lab0 == c)[0]) for c in range(K)]\n",
        "                try:\n",
        "                    mod = float(nx_modularity(G_nx, comms))\n",
        "                except Exception:\n",
        "                    mod = np.nan\n",
        "\n",
        "                all_rows.append({\n",
        "                    \"source\": src_name,\n",
        "                    \"prep\": prep,\n",
        "                    \"algo\": \"kmeans\",\n",
        "                    \"K\": int(K),\n",
        "                    \"modularity\": mod,\n",
        "                    \"stability_ARI\": ari_stab,\n",
        "                    \"stability_AMI\": ami_stab,\n",
        "                })\n",
        "\n",
        "            # ========== GMM scan ==========\n",
        "            for K in K_LIST:\n",
        "                labs = []\n",
        "                for s in SEEDS:\n",
        "                    gmm = GaussianMixture(n_components=K, covariance_type=\"diag\", random_state=s, max_iter=300)\n",
        "                    lab = gmm.fit_predict(Z)\n",
        "                    labs.append(lab)\n",
        "\n",
        "                ari_stab = _pairwise_metric_mean(labs, adjusted_rand_score)\n",
        "                ami_stab = _pairwise_metric_mean(labs, adjusted_mutual_info_score)\n",
        "\n",
        "                lab0 = labs[0]\n",
        "                comms = [list(np.where(lab0 == c)[0]) for c in range(K)]\n",
        "                try:\n",
        "                    mod = float(nx_modularity(G_nx, comms))\n",
        "                except Exception:\n",
        "                    mod = np.nan\n",
        "\n",
        "                all_rows.append({\n",
        "                    \"source\": src_name,\n",
        "                    \"prep\": prep,\n",
        "                    \"algo\": \"gmm_diag\",\n",
        "                    \"K\": int(K),\n",
        "                    \"modularity\": mod,\n",
        "                    \"stability_ARI\": ari_stab,\n",
        "                    \"stability_AMI\": ami_stab,\n",
        "                })\n",
        "\n",
        "        # ===== Optional HDBSCAN (if installed) =====\n",
        "        try:\n",
        "            import hdbscan\n",
        "            Z = embedding_preprocess(Z0, mode=\"whiten_l2\", pca_dim=PCA_DIM, random_state=0)\n",
        "            clusterer = hdbscan.HDBSCAN(min_cluster_size=20, min_samples=5)\n",
        "            lab = clusterer.fit_predict(Z)\n",
        "            if np.any(lab == -1):\n",
        "                lab = lab.copy()\n",
        "                lab[lab == -1] = lab.max() + 1\n",
        "            K_eff = int(lab.max() + 1)\n",
        "            comms = [list(np.where(lab == c)[0]) for c in range(K_eff)]\n",
        "            try:\n",
        "                mod = float(nx_modularity(G_nx, comms))\n",
        "            except Exception:\n",
        "                mod = np.nan\n",
        "\n",
        "            all_rows.append({\n",
        "                \"source\": src_name,\n",
        "                \"prep\": \"whiten_l2\",\n",
        "                \"algo\": \"hdbscan\",\n",
        "                \"K\": K_eff,\n",
        "                \"modularity\": mod,\n",
        "                \"stability_ARI\": np.nan,\n",
        "                \"stability_AMI\": np.nan,\n",
        "            })\n",
        "            print(f\"✅ HDBSCAN done for {src_name}: K_eff={K_eff}, modularity={mod:.4f}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    df_embed_tuning = pd.DataFrame(all_rows)\n",
        "    display(df_embed_tuning.head())\n",
        "\n",
        "    # ---------- scoring & picking best per (source,algo,prep) ----------\n",
        "    def _minmax(x):\n",
        "        x = np.asarray(x, dtype=float)\n",
        "        mn, mx = np.nanmin(x), np.nanmax(x)\n",
        "        if not np.isfinite(mn) or not np.isfinite(mx) or (mx - mn) < 1e-12:\n",
        "            return np.zeros_like(x)\n",
        "        return (x - mn) / (mx - mn)\n",
        "\n",
        "    df_embed_tuning[\"score\"] = np.nan\n",
        "    for (src, algo, prep), g in df_embed_tuning.groupby([\"source\", \"algo\", \"prep\"]):\n",
        "        mod_n = _minmax(g[\"modularity\"].values)\n",
        "        stab = 0.5 * _minmax(g[\"stability_ARI\"].values) + 0.5 * _minmax(g[\"stability_AMI\"].values)\n",
        "        score = W_MOD * mod_n + W_STAB * stab\n",
        "        df_embed_tuning.loc[g.index, \"score\"] = score\n",
        "\n",
        "    best_rows = (\n",
        "        df_embed_tuning.sort_values([\"source\", \"algo\", \"prep\", \"score\"], ascending=[True, True, True, False])\n",
        "        .groupby([\"source\", \"algo\", \"prep\"], as_index=False)\n",
        "        .head(1)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    display(best_rows)\n",
        "\n",
        "    df_embed_tuning.to_csv(\"embed_clustering_tuning_all.csv\", index=False)\n",
        "    best_rows.to_csv(\"embed_clustering_tuning_best.csv\", index=False)\n",
        "    print(\"✅ Saved: embed_clustering_tuning_all.csv, embed_clustering_tuning_best.csv\")\n",
        "\n",
        "    # ---------- write best labels into df_clusters (KMeans only by default) ----------\n",
        "    for _, r in best_rows.iterrows():\n",
        "        if r[\"algo\"] != \"kmeans\":\n",
        "            continue\n",
        "        src = r[\"source\"]; prep = r[\"prep\"]; K = int(r[\"K\"])\n",
        "        Z0 = EMBED_SOURCES[src]\n",
        "        Z = embedding_preprocess(Z0, mode=prep, pca_dim=PCA_DIM, random_state=0)\n",
        "        lab = KMeans(n_clusters=K, n_init=N_INIT, random_state=0).fit_predict(Z)\n",
        "\n",
        "        dfc = globals()[\"df_clusters\"]\n",
        "        col = f\"{src}_kmeans_{prep}_K{K}_best\"\n",
        "        dfc[col] = lab\n",
        "        globals()[\"df_clusters\"] = dfc\n",
        "        print(\"✅ Wrote df_clusters:\", col)\n",
        "\n",
        "    # ---------- plots: score curves per source (KMeans) ----------\n",
        "    for src in df_embed_tuning[\"source\"].unique():\n",
        "        sub = df_embed_tuning[(df_embed_tuning[\"source\"] == src) & (df_embed_tuning[\"algo\"] == \"kmeans\")]\n",
        "        if len(sub) == 0:\n",
        "            continue\n",
        "        plt.figure(figsize=(8,4))\n",
        "        for prep in PREP_MODES:\n",
        "            s2 = sub[sub[\"prep\"] == prep].sort_values(\"K\")\n",
        "            if len(s2) == 0:\n",
        "                continue\n",
        "            plt.plot(s2[\"K\"], s2[\"score\"], marker=\"o\", label=prep)\n",
        "        plt.title(f\"K-scan score (modularity+stability) — {src} (KMeans)\")\n",
        "        plt.xlabel(\"K\"); plt.ylabel(\"score\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        out = f\"embed_tuning_kmeans_score_{src}.png\".replace(\" \", \"_\")\n",
        "        plt.savefig(out, dpi=300)\n",
        "        plt.show()\n",
        "        print(\"✅ Saved:\", out)\n",
        "else:\n",
        "    print(\"🟦 RUN_EMBED_TUNING disabled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nIcdVP5IIMsb",
      "metadata": {
        "id": "nIcdVP5IIMsb"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 31C) DEC refinement (flagship deep clustering) with early stopping on modularity (proxy)\n",
        "# - Works on a chosen embedding source\n",
        "# - Optimizes cluster centers with DEC KL loss\n",
        "# - Saves: dec_refinement_metrics.csv, dec_refinement_labels.csv\n",
        "# - Adds df_clusters['DEC_<source>_<prep>_K...']\n",
        "# =========================\n",
        "RUN_DEC_TUNING = True\n",
        "\n",
        "DEC_SOURCE = None     # None => auto-pick (Transformer-VGAE > DGI > VGAE(base) > any z*)\n",
        "DEC_PREP   = \"whiten_l2\"\n",
        "DEC_K_LIST = [20, 30, 40, 50]\n",
        "DEC_LR_LIST = [1e-2, 5e-3]\n",
        "DEC_ALPHA_LIST = [1.0]\n",
        "DEC_EPOCHS = 300\n",
        "DEC_EVAL_EVERY = 20\n",
        "DEC_PATIENCE = 5\n",
        "DEC_SEEDS = (0,1,2)\n",
        "\n",
        "if RUN_DEC_TUNING:\n",
        "    import torch\n",
        "    from sklearn.cluster import KMeans\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "    G_nx = _get_nx_graph()\n",
        "\n",
        "    # pick embeddings\n",
        "    Z0 = None\n",
        "    src_name = None\n",
        "    if DEC_SOURCE is None:\n",
        "        order = [(\"VGAE_transformer\", \"z_tr\"),\n",
        "                 (\"DGI\", \"z_dgi\"),\n",
        "                 (\"VGAE_base\", \"z_mean\"),\n",
        "                 (\"any_z\", None)]\n",
        "        for pretty, nm in order:\n",
        "            if nm is not None and nm in globals() and globals()[nm] is not None:\n",
        "                try:\n",
        "                    Z0 = globals()[nm].detach().cpu().numpy()\n",
        "                    src_name = pretty\n",
        "                    break\n",
        "                except Exception:\n",
        "                    pass\n",
        "        if Z0 is None:\n",
        "            for nm, obj in globals().items():\n",
        "                if nm.startswith(\"z\") and hasattr(obj, \"detach\"):\n",
        "                    try:\n",
        "                        Z0 = obj.detach().cpu().numpy()\n",
        "                        src_name = nm\n",
        "                        break\n",
        "                    except Exception:\n",
        "                        pass\n",
        "    else:\n",
        "        if DEC_SOURCE in globals() and hasattr(globals()[DEC_SOURCE], \"detach\"):\n",
        "            Z0 = globals()[DEC_SOURCE].detach().cpu().numpy()\n",
        "            src_name = DEC_SOURCE\n",
        "        else:\n",
        "            raise RuntimeError(\"DEC_SOURCE provided but not found in globals or not a tensor.\")\n",
        "\n",
        "    assert Z0 is not None, \"No embeddings found for DEC.\"\n",
        "    Z0 = np.asarray(Z0)\n",
        "    N, D = Z0.shape\n",
        "    ensure_df_clusters(N)\n",
        "\n",
        "    def dec_q(Zt, mu, alpha=1.0):\n",
        "        dist = torch.cdist(Zt, mu, p=2) ** 2\n",
        "        q = 1.0 / (1.0 + dist / alpha)\n",
        "        q = q ** ((alpha + 1.0) / 2.0)\n",
        "        q = q / torch.sum(q, dim=1, keepdim=True)\n",
        "        return q\n",
        "\n",
        "    def target_p(q):\n",
        "        f = torch.sum(q, dim=0)\n",
        "        p = (q ** 2) / f\n",
        "        p = p / torch.sum(p, dim=1, keepdim=True)\n",
        "        return p\n",
        "\n",
        "    all_rows = []\n",
        "    best_global = None\n",
        "\n",
        "    for K in DEC_K_LIST:\n",
        "        for lr in DEC_LR_LIST:\n",
        "            for alpha in DEC_ALPHA_LIST:\n",
        "                for seed in DEC_SEEDS:\n",
        "                    Zp = embedding_preprocess(Z0, mode=DEC_PREP, pca_dim=64, random_state=seed)\n",
        "                    Zt = torch.tensor(Zp, dtype=torch.float32)\n",
        "\n",
        "                    km = KMeans(n_clusters=K, n_init=20, random_state=seed).fit(Zp)\n",
        "                    mu = torch.tensor(km.cluster_centers_, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "                    opt = torch.optim.Adam([mu], lr=lr)\n",
        "\n",
        "                    best_mod = -1e9\n",
        "                    best_mu = None\n",
        "                    bad = 0\n",
        "\n",
        "                    for epoch in range(1, DEC_EPOCHS+1):\n",
        "                        q = dec_q(Zt, mu, alpha=alpha)\n",
        "                        p = target_p(q).detach()\n",
        "                        loss = torch.sum(p * (torch.log(p + 1e-10) - torch.log(q + 1e-10)))\n",
        "\n",
        "                        opt.zero_grad()\n",
        "                        loss.backward()\n",
        "                        opt.step()\n",
        "\n",
        "                        if epoch % DEC_EVAL_EVERY == 0 or epoch == DEC_EPOCHS:\n",
        "                            with torch.no_grad():\n",
        "                                q_eval = dec_q(Zt, mu, alpha=alpha)\n",
        "                                labels = torch.argmax(q_eval, dim=1).cpu().numpy()\n",
        "\n",
        "                            comms = [list(np.where(labels == c)[0]) for c in range(K)]\n",
        "                            try:\n",
        "                                mod = float(nx_modularity(G_nx, comms))\n",
        "                            except Exception:\n",
        "                                mod = np.nan\n",
        "\n",
        "                            if np.isfinite(mod) and mod > best_mod + 1e-6:\n",
        "                                best_mod = mod\n",
        "                                best_mu = mu.detach().clone()\n",
        "                                bad = 0\n",
        "                            else:\n",
        "                                bad += 1\n",
        "                                if bad >= DEC_PATIENCE:\n",
        "                                    break\n",
        "\n",
        "                    if best_mu is None:\n",
        "                        best_mu = mu.detach().clone()\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        q_eval = dec_q(Zt, best_mu, alpha=alpha)\n",
        "                        labels = torch.argmax(q_eval, dim=1).cpu().numpy()\n",
        "\n",
        "                    if \"compute_cluster_metrics\" in globals():\n",
        "                        row = compute_cluster_metrics(G_nx, labels, name=f\"DEC_{src_name}_{DEC_PREP}_K{K}\", gt_labels=globals().get(\"gt_labels_corum\", None))\n",
        "                    else:\n",
        "                        row = {\"name\": f\"DEC_{src_name}_{DEC_PREP}_K{K}\", \"modularity\": best_mod}\n",
        "\n",
        "                    row.update({\"algo\":\"DEC\", \"source\":src_name, \"prep\":DEC_PREP, \"K\":K, \"lr\":lr, \"alpha\":alpha, \"seed\":seed, \"best_modularity_proxy\":best_mod})\n",
        "                    all_rows.append(row)\n",
        "\n",
        "                    if best_global is None or (np.isfinite(best_mod) and best_mod > best_global[\"best_modularity_proxy\"]):\n",
        "                        best_global = row.copy()\n",
        "                        best_global[\"_labels\"] = labels.copy()\n",
        "\n",
        "                    print(f\"✅ DEC done: K={K} lr={lr} seed={seed} best_mod={best_mod:.4f}\")\n",
        "\n",
        "    df_dec = pd.DataFrame(all_rows)\n",
        "    display(df_dec.sort_values(\"best_modularity_proxy\", ascending=False).head(10))\n",
        "    df_dec.to_csv(\"dec_refinement_metrics.csv\", index=False)\n",
        "    print(\"✅ Saved: dec_refinement_metrics.csv\")\n",
        "\n",
        "    if best_global is not None:\n",
        "        col = f\"DEC_{src_name}_{DEC_PREP}_K{int(best_global['K'])}_best\"\n",
        "        globals()[\"df_clusters\"][col] = best_global[\"_labels\"]\n",
        "        globals()[\"df_clusters\"].to_csv(\"dec_refinement_labels.csv\", index=False)\n",
        "        print(\"✅ Wrote df_clusters and saved dec_refinement_labels.csv with column:\", col)\n",
        "\n",
        "        if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame):\n",
        "            df_deep = pd.concat([df_deep, pd.DataFrame([{k:v for k,v in best_global.items() if not k.startswith('_')}])], ignore_index=True)\n",
        "else:\n",
        "    print(\"🟦 RUN_DEC_TUNING disabled.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7u6m_ETIIMsc",
      "metadata": {
        "id": "7u6m_ETIIMsc"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# 31D) Sparse-DMoN tuning (flagship deep clustering) with early stopping on modularity (proxy)\n",
        "# - End-to-end on sparse edges (edge_index)\n",
        "# - Uses a small GCN to output soft assignments S (N,K)\n",
        "# - Loss = -Q_soft + lambda_balance*balance + lambda_entropy*entropy\n",
        "# - Saves: sparse_dmon_tuning_metrics.csv\n",
        "# - Adds df_clusters['SparseDMoN_K..._best']\n",
        "# =========================\n",
        "RUN_SPARSE_DMON_TUNING = True\n",
        "\n",
        "DMON_K_LIST = [20, 30, 40]\n",
        "DMON_LR_LIST = [1e-2, 5e-3]\n",
        "DMON_LAMBDA_BAL_LIST = [0.5, 1.0]\n",
        "DMON_LAMBDA_ENT_LIST = [0.05, 0.1]\n",
        "DMON_EPOCHS = 250\n",
        "DMON_EVAL_EVERY = 25\n",
        "DMON_PATIENCE = 5\n",
        "DMON_SEEDS = (0,1,2)\n",
        "\n",
        "if RUN_SPARSE_DMON_TUNING:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    from networkx.algorithms.community.quality import modularity as nx_modularity\n",
        "\n",
        "    # --- get PyG data for edges + x ---\n",
        "    pyg_base = None\n",
        "    for nm in [\"data_train\", \"data_lcc\", \"data_full\", \"data\"]:\n",
        "        if nm in globals() and hasattr(globals()[nm], \"edge_index\"):\n",
        "            pyg_base = globals()[nm]\n",
        "            break\n",
        "    assert pyg_base is not None, \"No PyG data with edge_index found (data_train/data_lcc/data_full/data).\"\n",
        "\n",
        "    edge_index = pyg_base.edge_index\n",
        "    N = int(pyg_base.num_nodes)\n",
        "\n",
        "    x = getattr(pyg_base, \"x\", None)\n",
        "    if x is None:\n",
        "        Z0 = None\n",
        "        for nm in [\"z_tr\", \"z_dgi\", \"z_mean\", \"z\"]:\n",
        "            if nm in globals() and globals()[nm] is not None:\n",
        "                try:\n",
        "                    Z0 = globals()[nm].detach()\n",
        "                    break\n",
        "                except Exception:\n",
        "                    pass\n",
        "        if Z0 is not None:\n",
        "            x = Z0\n",
        "            print(\"ℹ️ Using embeddings as node features for Sparse-DMoN.\")\n",
        "        else:\n",
        "            x = torch.ones((N, 16), dtype=torch.float32)\n",
        "            print(\"ℹ️ data.x missing -> using x=ones(N,16)\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    x = x.to(device)\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "    # build undirected unique edges\n",
        "    ei = edge_index.detach().cpu().numpy()\n",
        "    uu = np.minimum(ei[0], ei[1]); vv = np.maximum(ei[0], ei[1])\n",
        "    und = np.unique(np.stack([uu, vv], axis=0), axis=1)\n",
        "    m = und.shape[1]\n",
        "\n",
        "    deg = np.zeros(N, dtype=np.float32)\n",
        "    for u,v in und.T:\n",
        "        deg[u] += 1.0\n",
        "        deg[v] += 1.0\n",
        "\n",
        "    deg_t = torch.tensor(deg, device=device)\n",
        "    und_u = torch.tensor(und[0].astype(np.int64), device=device)\n",
        "    und_v = torch.tensor(und[1].astype(np.int64), device=device)\n",
        "    m_t = float(m)\n",
        "\n",
        "    G_nx = _get_nx_graph()\n",
        "\n",
        "    from torch_geometric.nn import GCNConv\n",
        "\n",
        "    class AssignGCN(nn.Module):\n",
        "        def __init__(self, in_dim, hid, K, dropout=0.2):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_dim, hid)\n",
        "            self.conv2 = GCNConv(hid, K)\n",
        "            self.dropout = dropout\n",
        "        def forward(self, x, edge_index):\n",
        "            h = self.conv1(x, edge_index)\n",
        "            h = F.relu(h)\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "            logits = self.conv2(h, edge_index)\n",
        "            return F.softmax(logits, dim=1)\n",
        "\n",
        "    def soft_modularity_loss(S):\n",
        "        Su = S[und_u]\n",
        "        Sv = S[und_v]\n",
        "        same = torch.sum(Su * Sv, dim=1)\n",
        "\n",
        "        expected = (deg_t[und_u] * deg_t[und_v]) / (2.0 * m_t + 1e-12)\n",
        "        contrib = (1.0 - expected) * same\n",
        "        Q = torch.sum(contrib) / (m_t + 1e-12)\n",
        "        return -Q, Q\n",
        "\n",
        "    def balance_loss(S):\n",
        "        mass = torch.mean(S, dim=0)\n",
        "        K = S.size(1)\n",
        "        target = torch.full_like(mass, 1.0 / K)\n",
        "        return torch.mean((mass - target) ** 2)\n",
        "\n",
        "    def entropy_loss(S):\n",
        "        ent = -torch.sum(S * torch.log(S + 1e-12), dim=1)\n",
        "        return torch.mean(ent)\n",
        "\n",
        "    all_rows = []\n",
        "    best_global = None\n",
        "\n",
        "    in_dim = int(x.size(1))\n",
        "    hid = 64\n",
        "\n",
        "    for K in DMON_K_LIST:\n",
        "        for lr in DMON_LR_LIST:\n",
        "            for lam_bal in DMON_LAMBDA_BAL_LIST:\n",
        "                for lam_ent in DMON_LAMBDA_ENT_LIST:\n",
        "                    for seed in DMON_SEEDS:\n",
        "                        torch.manual_seed(seed)\n",
        "                        np.random.seed(seed)\n",
        "\n",
        "                        model = AssignGCN(in_dim, hid, K, dropout=0.2).to(device)\n",
        "                        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                        best_mod = -1e9\n",
        "                        best_labels = None\n",
        "                        bad = 0\n",
        "\n",
        "                        for epoch in range(1, DMON_EPOCHS+1):\n",
        "                            model.train()\n",
        "                            S = model(x, edge_index)\n",
        "                            loss_mod, Q = soft_modularity_loss(S)\n",
        "                            loss = loss_mod + lam_bal * balance_loss(S) + lam_ent * entropy_loss(S)\n",
        "\n",
        "                            opt.zero_grad()\n",
        "                            loss.backward()\n",
        "                            opt.step()\n",
        "\n",
        "                            if epoch % DMON_EVAL_EVERY == 0 or epoch == DMON_EPOCHS:\n",
        "                                model.eval()\n",
        "                                with torch.no_grad():\n",
        "                                    labels = torch.argmax(model(x, edge_index), dim=1).cpu().numpy()\n",
        "                                comms = [list(np.where(labels == c)[0]) for c in range(K)]\n",
        "                                try:\n",
        "                                    mod_proxy = float(nx_modularity(G_nx, comms))\n",
        "                                except Exception:\n",
        "                                    mod_proxy = np.nan\n",
        "\n",
        "                                if np.isfinite(mod_proxy) and mod_proxy > best_mod + 1e-6:\n",
        "                                    best_mod = mod_proxy\n",
        "                                    best_labels = labels.copy()\n",
        "                                    bad = 0\n",
        "                                else:\n",
        "                                    bad += 1\n",
        "                                    if bad >= DMON_PATIENCE:\n",
        "                                        break\n",
        "\n",
        "                        if best_labels is None:\n",
        "                            best_labels = labels.copy()\n",
        "\n",
        "                        if \"compute_cluster_metrics\" in globals():\n",
        "                            row = compute_cluster_metrics(G_nx, best_labels, name=f\"SparseDMoN_K{K}\", gt_labels=globals().get(\"gt_labels_corum\", None))\n",
        "                        else:\n",
        "                            row = {\"name\": f\"SparseDMoN_K{K}\", \"modularity\": best_mod}\n",
        "\n",
        "                        row.update({\n",
        "                            \"algo\":\"SparseDMoN\", \"K\":K, \"lr\":lr,\n",
        "                            \"lambda_balance\":lam_bal, \"lambda_entropy\":lam_ent,\n",
        "                            \"seed\":seed, \"best_modularity_proxy\":best_mod\n",
        "                        })\n",
        "                        all_rows.append(row)\n",
        "\n",
        "                        if best_global is None or (np.isfinite(best_mod) and best_mod > best_global[\"best_modularity_proxy\"]):\n",
        "                            best_global = row.copy()\n",
        "                            best_global[\"_labels\"] = best_labels.copy()\n",
        "\n",
        "                        print(f\"✅ SparseDMoN done: K={K} lr={lr} bal={lam_bal} ent={lam_ent} seed={seed} best_mod={best_mod:.4f}\")\n",
        "\n",
        "    df_dmon = pd.DataFrame(all_rows)\n",
        "    display(df_dmon.sort_values(\"best_modularity_proxy\", ascending=False).head(10))\n",
        "    df_dmon.to_csv(\"sparse_dmon_tuning_metrics.csv\", index=False)\n",
        "    print(\"✅ Saved: sparse_dmon_tuning_metrics.csv\")\n",
        "\n",
        "    if best_global is not None:\n",
        "        ensure_df_clusters(N)\n",
        "        col = f\"SparseDMoN_K{int(best_global['K'])}_best\"\n",
        "        globals()[\"df_clusters\"][col] = best_global[\"_labels\"]\n",
        "        print(\"✅ Wrote df_clusters column:\", col)\n",
        "\n",
        "        if \"df_deep\" in globals() and isinstance(df_deep, pd.DataFrame):\n",
        "            df_deep = pd.concat([df_deep, pd.DataFrame([{k:v for k,v in best_global.items() if not k.startswith('_')}])], ignore_index=True)\n",
        "\n",
        "else:\n",
        "    print(\"🟦 RUN_SPARSE_DMON_TUNING disabled.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4tqxv-TtIMsc",
      "metadata": {
        "id": "4tqxv-TtIMsc"
      },
      "source": [
        "## 31E) After tuning: rerun your existing \"bulk evaluation\" + \"paper plots\"\n",
        "Now that `df_clusters` has extra tuned columns (best KMeans, DEC, Sparse-DMoN),\n",
        "rerun:\n",
        "- **24) Bulk evaluation for all clustering columns**\n",
        "- **Paper plots** (bars + trade-off)\n",
        "so the new methods appear automatically in the global comparisons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eytDVEcbTQ_F"
      },
      "source": [
        "# =========================\n",
        "# 19B) PAPER SUMMARY TABLE: link prediction + clustering + CORUM/GO/Disease (auto-merge)\n",
        "# - Reads outputs if they exist and merges them to one table for the paper.\n",
        "# - Saves: paper_model_summary.csv\n",
        "# =========================\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _safe_read_csv(path):\n",
        "    try:\n",
        "        return pd.read_csv(path)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# ---- Link prediction summaries ----\n",
        "lp_summary = _safe_read_csv(\"gnn_linkpred_multiseed_summary.csv\")  # from cell 4B (multi-seed)\n",
        "if lp_summary is not None:\n",
        "    # expected cols: model, model_key, val_ap_mean, ..., test_ap_mean, ...\n",
        "    lp_summary = lp_summary.rename(columns={\n",
        "        \"val_ap_mean\": \"lp_val_ap_mean\",\n",
        "        \"val_ap_std\": \"lp_val_ap_std\",\n",
        "        \"test_ap_mean\": \"lp_test_ap_mean\",\n",
        "        \"test_ap_std\": \"lp_test_ap_std\",\n",
        "        \"test_roc_mean\": \"lp_test_roc_mean\",\n",
        "        \"test_roc_std\": \"lp_test_roc_std\",\n",
        "    })\n",
        "else:\n",
        "    lp_summary = pd.DataFrame(columns=[\"model_key\"])\n",
        "\n",
        "# tuned GCN+EdgeMLP confirm (optional)\n",
        "tuned_confirm = _safe_read_csv(\"gcn_edgemlp_confirm_multiseed.csv\")\n",
        "if tuned_confirm is not None and len(tuned_confirm) > 0:\n",
        "    tuned_row = {\n",
        "        \"model\": \"GCN + EdgeMLP (tuned)\",\n",
        "        \"model_key\": \"gcn_edgemlp_tuned\",\n",
        "        \"lp_val_ap_mean\": float(tuned_confirm[\"val_ap\"].mean()),\n",
        "        \"lp_val_ap_std\": float(tuned_confirm[\"val_ap\"].std(ddof=1)) if len(tuned_confirm) > 1 else 0.0,\n",
        "        \"lp_test_ap_mean\": float(tuned_confirm[\"test_ap\"].mean()),\n",
        "        \"lp_test_ap_std\": float(tuned_confirm[\"test_ap\"].std(ddof=1)) if len(tuned_confirm) > 1 else 0.0,\n",
        "        \"lp_test_roc_mean\": float(tuned_confirm[\"test_roc_auc\"].mean()),\n",
        "        \"lp_test_roc_std\": float(tuned_confirm[\"test_roc_auc\"].std(ddof=1)) if len(tuned_confirm) > 1 else 0.0,\n",
        "    }\n",
        "    lp_summary = pd.concat([lp_summary, pd.DataFrame([tuned_row])], ignore_index=True)\n",
        "\n",
        "# ---- Clustering quality table (if you produced it) ----\n",
        "# We try several common filenames used in this notebook.\n",
        "clust_paths = [\n",
        "    \"paper_main_results_table.csv\",\n",
        "    \"clustering_metrics_all.csv\",\n",
        "    \"clustering_quality_table.csv\",\n",
        "]\n",
        "clust_df = None\n",
        "for p in clust_paths:\n",
        "    if os.path.exists(p):\n",
        "        clust_df = _safe_read_csv(p)\n",
        "        if clust_df is not None and len(clust_df) > 0:\n",
        "            break\n",
        "\n",
        "# ---- External enrichment outputs (optional) ----\n",
        "# These cells often save one CSV per method. We merge by cluster_col if possible.\n",
        "corum_df = None\n",
        "for p in [\"corum_validation_results.csv\", \"corum_results.csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        corum_df = _safe_read_csv(p)\n",
        "        break\n",
        "\n",
        "disease_df = None\n",
        "for p in [\"disease_enrichment_results.csv\", \"disgenet_disease_enrichment.csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        disease_df = _safe_read_csv(p)\n",
        "        break\n",
        "\n",
        "go_df = None\n",
        "for p in [\"go_enrichment_results.csv\", \"gprofiler_go_enrichment.csv\"]:\n",
        "    if os.path.exists(p):\n",
        "        go_df = _safe_read_csv(p)\n",
        "        break\n",
        "\n",
        "# ---- Build model_key ↔ cluster_col mapping (from df_clusters column names) ----\n",
        "# We assume clustering columns created by 4B.1 look like lp_<model_key>_kmeans, etc.\n",
        "cluster_cols = []\n",
        "if \"df_clusters\" in globals() and isinstance(df_clusters, pd.DataFrame):\n",
        "    cluster_cols = [c for c in df_clusters.columns if isinstance(c,str) and c.startswith(\"lp_\") and (\"kmeans\" in c or \"louvain\" in c or \"leiden\" in c)]\n",
        "    # also include classic columns\n",
        "    for c in [\"edge_mlp_kmeans\", \"kmeans_cluster\", \"louvain_cluster\", \"leiden_cluster\"]:\n",
        "        if c in df_clusters.columns:\n",
        "            cluster_cols.append(c)\n",
        "\n",
        "# create a table of cluster cols\n",
        "cc = pd.DataFrame({\"cluster_col\": sorted(set(cluster_cols))})\n",
        "# model_key inferred from lp_<key>_...\n",
        "def _infer_model_key(c):\n",
        "    if c.startswith(\"lp_\"):\n",
        "        # lp_<key>_<method>\n",
        "        parts = c.split(\"_\")\n",
        "        if len(parts) >= 3:\n",
        "            return \"_\".join(parts[1:-1])\n",
        "    if c == \"edge_mlp_kmeans\":\n",
        "        return \"gcn_edgemlp\"\n",
        "    return c\n",
        "cc[\"model_key\"] = cc[\"cluster_col\"].apply(_infer_model_key)\n",
        "\n",
        "# ---- Merge everything ----\n",
        "out = cc.merge(lp_summary, on=\"model_key\", how=\"left\")\n",
        "\n",
        "# clustering quality merge: try to detect keys\n",
        "if clust_df is not None and len(clust_df) > 0:\n",
        "    # accept either cluster_col column or method column\n",
        "    if \"cluster_col\" in clust_df.columns:\n",
        "        out = out.merge(clust_df, on=\"cluster_col\", how=\"left\", suffixes=(\"\",\"_clust\"))\n",
        "    elif \"method\" in clust_df.columns:\n",
        "        out = out.merge(clust_df.rename(columns={\"method\":\"cluster_col\"}), on=\"cluster_col\", how=\"left\", suffixes=(\"\",\"_clust\"))\n",
        "\n",
        "# external merges (best-effort)\n",
        "for ext, name in [(corum_df, \"corum\"), (disease_df, \"disease\"), (go_df, \"go\")]:\n",
        "    if ext is None or len(ext)==0:\n",
        "        continue\n",
        "    # try to find a column that corresponds to cluster method\n",
        "    join_col = None\n",
        "    for cand in [\"cluster_col\", \"method\", \"clustering\", \"label_col\"]:\n",
        "        if cand in ext.columns:\n",
        "            join_col = cand\n",
        "            break\n",
        "    if join_col is not None:\n",
        "        tmp = ext.rename(columns={join_col:\"cluster_col\"})\n",
        "        out = out.merge(tmp, on=\"cluster_col\", how=\"left\", suffixes=(\"\",\"_\"+name))\n",
        "\n",
        "# finalize\n",
        "out = out.sort_values([\"lp_val_ap_mean\",\"lp_test_ap_mean\"], ascending=False, na_position=\"last\").reset_index(drop=True)\n",
        "display(out.head(30))\n",
        "\n",
        "out.to_csv(\"paper_model_summary.csv\", index=False)\n",
        "print(\"Saved: paper_model_summary.csv\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "eytDVEcbTQ_F"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}